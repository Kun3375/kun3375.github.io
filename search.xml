<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ZK 的主机选举与数据同步</title>
    <url>/2021/02/ZK-%E7%9A%84%E4%B8%BB%E6%9C%BA%E9%80%89%E4%B8%BE%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
    <content><![CDATA[<h4 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h4><h5 id="Leader"><a href="#Leader" class="headerlink" title="Leader"></a>Leader</h5><ul>
<li>集群内只有一个 Leader，负责调度处理事务请求，保证事务顺序性</li>
<li>和 Follower 一样可以处理客户端的读请求</li>
<li>Leader 也是集群内部服务的调度者</li>
</ul>
<h5 id="Follower"><a href="#Follower" class="headerlink" title="Follower"></a>Follower</h5><ul>
<li>处理客户端的读请求；事务请求会转发给 Leader 处理</li>
<li>参与投票，包括事务 Proposal、Leader 选举</li>
</ul>
<h5 id="Observer-3-3-0"><a href="#Observer-3-3-0" class="headerlink" title="Observer(3.3.0+)"></a>Observer(3.3.0+)</h5><ul>
<li>处理客户端的读请求；事务请求会转发给 Leader 处理</li>
<li>不参与任何投票，无论是选举还是事务写过半成功；也会不作为 Leader 候选者</li>
<li>因为不会成为 Leader， 所以不需要对数据进行持久化，故障恢复时会从 Leader 同步整个命名空间</li>
<li>添加 Observer 可以在不降低事务能力的同时增加读请求的吞吐量</li>
</ul>
<h4 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h4><p>ZK 保证各服务端同步的核心是他的 Zookeeper Atomic Broadcast 协议。ZAB 被使用在 ZK 的选举过程和同步过程中。</p>
<h5 id="主机选举"><a href="#主机选举" class="headerlink" title="主机选举"></a>主机选举</h5><ol>
<li>Server 进入 Looking 状态，每个 Server 发出投票给其他通信的 Server，主要内容包含<ul>
<li>id(sid) 被推举的 Server 标识，初始情况下是本机 sid</li>
<li>zxid 被推举的 Server 的 zxid，初始情况下是本机的 zxid</li>
<li>electionEpoch 选举纪元，判断收到的投票是否是本轮选票</li>
</ul>
</li>
<li>Server 接收他人投票，验证本机状态和选票有效性<a id="more"></a></li>
<li>处理投票，优先选择 zxid 大者，其次选择 sid 大者。如果投票被更新，则再次广播</li>
<li>统计投票，一单某 Server 得票超过一半，则被视为 Leader，对应 Server 从 Looking 状态变更为 Leading，其他从 Looking 变更为 Following</li>
</ol>
<h5 id="恢复阶段"><a href="#恢复阶段" class="headerlink" title="恢复阶段"></a>恢复阶段</h5><ol>
<li>Leader 为每个 Follower 准备一个 LearnerHandler 线程服务</li>
<li>Follower 向 Leader 发送自己的信息，其中包含 peerEpoch</li>
<li>Leader 接受 Follower 信息，选择最大 peerEpoch + 1 确定为本届的 epoch，将 epoch 与本机信息发送给 Follower</li>
<li>Follower 接受新的 peerEpoch，并组合新的 zxid 发送给 Leader</li>
<li>Leader 接受 Follower 的 zxid，与自己相比较来确定数据差异，进行数据同步<ul>
<li>如果两者 zxid 一致，说明同步完成。否则判断 Follower 的 zxid 是否在 minCommittedLog 与 maxCommittedLog 之间</li>
<li>如果 Follower zxid 小于 minCommittedLog，直接让 Follower 采用快照恢复</li>
<li>如果 Follower zxid 大于 maxCommittedLog，此时取信与 Leader，删除 Follower 超出的事务日志</li>
<li>如果 Follower zxid 介于中间，Leader 会传输 zxid 至 maxCommittedLog 之间的事务</li>
</ul>
</li>
</ol>
<h5 id="数据广播"><a href="#数据广播" class="headerlink" title="数据广播"></a>数据广播</h5><p>Server 端的几个重要数据结构：</p>
<ul>
<li><code>long lastProcessedZxid</code> 记录最新的事务编号</li>
<li><code>LinkedList&lt;Proposal&gt; committedLog</code> 最近一段时间内的提案队列，默认大小是 500</li>
<li><code>long minCommittedLog</code> 提案队列中最小的事务编号</li>
<li><code>long maxCommittedLog</code> 提案队列中最大的事务编号</li>
<li><code>ConcurrentMap&lt;Long, Proposal&gt; outstandingProposals</code> 保存等待表决的提案，Leader 独占的数据结构</li>
<li><code>ConcurrentLinkedQueue&lt;Proposal&gt; toBeApplied</code> 保存准备提交的提案，Leader 独占的数据结构<br>事务生效的过程核心在于 Leader</li>
</ul>
<ol>
<li>Leader 接受到客户端写请求，创建提案，保存在 <code>outstandingProposals</code> 当中</li>
<li>Leader 向 Follower 广播提案，如果获得半数以上通过，则从 <code>outstandingProposals</code> 中删除，转移到 <code>toBeApplied</code></li>
<li>Leader 想 Follower 广播提交，同时自己也开始提交过程。数据保存进内存树，更新 <code>lastProcessedZxid</code> 以及 <em>Log</em> 相关数据</li>
<li>Leader 响应客户端并将之前的提案从 <code>toBeApplied</code> 删除。</li>
</ol>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>修改系统对应用的限制</title>
    <url>/2020/12/%E4%BF%AE%E6%94%B9%E7%B3%BB%E7%BB%9F%E5%AF%B9%E5%BA%94%E7%94%A8%E7%9A%84%E9%99%90%E5%88%B6/</url>
    <content><![CDATA[<h2 id="应用限制的修改"><a href="#应用限制的修改" class="headerlink" title="应用限制的修改"></a>应用限制的修改</h2><p>在调优过程中，在修改应用程序本身参数之前，需要确认系统环境的配置是否满足要求。涉及到内存、文件描述符、文件大小等一系列的限制。而由于系统的保守，一般服务端应用的需求会大于系统的默认限制。那么如何查看和修改，就是首先要解决的问题了。</p>
<p>在 Linux 中，对应用程序的限制，首先可以从 ulimit 着手。</p>
<h3 id="查看用户程序系统限制"><a href="#查看用户程序系统限制" class="headerlink" title="查看用户程序系统限制"></a>查看用户程序系统限制</h3><p>使用 <code>ulimit -{op}</code> 来查看对应的变量限制。<code>ulimit</code> 是基于 PAM 的用户限制模块，一般除了一些系统的程序，一般用户都受此限制。先罗列几个常用的：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -a # 查看全部</span><br><span class="line">ulimit -n # 文件描述符上限</span><br><span class="line">ulimit -l # 应用程序允许锁定的内存量</span><br><span class="line">ulimit -m # 应用程序允许占用的内存大小</span><br><span class="line">ulimit -s # 应用程序线程栈大小</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<h3 id="修改用户程序系统限制"><a href="#修改用户程序系统限制" class="headerlink" title="修改用户程序系统限制"></a>修改用户程序系统限制</h3><h4 id="会话级修改"><a href="#会话级修改" class="headerlink" title="会话级修改"></a>会话级修改</h4><p>如果要修改该值也很简单，只需要在命令之后跟上需要修改的上限值就可以了：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -n 65535 # 修改当前的文件描述符限制为 65535</span><br></pre></td></tr></table></figure>

<p>但是这种的好处是可以立即生效，但是仅影响本次会话。之后启动的程序都会应用当前的修改，但是重启之后就会失效。</p>
<h4 id="永久修改"><a href="#永久修改" class="headerlink" title="永久修改"></a>永久修改</h4><p>对用户程序的这些限制，都是由 <code>/etc/security/limits.conf</code> 所影响。修改这个文件即可达到修改限制的目的了。看一下这个文件长什么样：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># example</span><br><span class="line">root           hard    core           100000</span><br><span class="line">*              hard    rss            10000</span><br><span class="line">@student       hard    nproc           20</span><br></pre></td></tr></table></figure>

<p>这里每一行是一个四元表达式：<code>&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;</code>，说一下四个元素的意义：</p>
<ul>
<li><em>domain</em>: 指定控制的<strong>用户</strong>或者<strong>组</strong>，可以使用 <code>%</code>/<code>*</code> 这样的通配符，<em>root</em> 用户不受通配符影响，需要显示指定。</li>
<li><em>type</em>：可选项有三个<ul>
<li><em>soft*：控制对应用户该项目的默认的上限（用户可以手动上调至 *hard</em> ）</li>
<li><em>hard*：控制对应用户该项目的最大上限，需要大于等于 *soft</em></li>
<li>-：设置 <code>-</code> 可以表示 <em>soft<em>、</em>hard</em> 值统一</li>
</ul>
</li>
<li><em>item</em>：指定不同的条目，如进程数、fd数量、栈大小等等，可以在 <code>limits.conf</code> 的注释和手册中找到详细说明。下面是摘要：<blockquote>
<ul>
<li>core - limits the core file size (KB)</li>
<li>data - max data size (KB)</li>
<li>fsize - maximum filesize (KB)</li>
<li>memlock - max locked-in-memory address space (KB)</li>
<li>nofile - max number of open files</li>
<li>rss - max resident set size (KB)</li>
<li>stack - max stack size (KB)</li>
<li>cpu - max CPU time (MIN)</li>
<li>nproc - max number of processes</li>
<li>as - address space limit (KB)</li>
<li>maxlogins - max number of logins for this user</li>
<li>maxsyslogins - max number of logins on the system</li>
<li>priority - the priority to run user process with</li>
<li>locks - max number of file locks the user can hold</li>
<li>sigpending - max number of pending signals</li>
<li>msgqueue - max memory used by POSIX message queues (bytes)</li>
<li>nice - max nice priority allowed to raise to values: [-20, 19]</li>
<li>rtprio - max realtime priority</li>
<li>chroot - change root to directory (Debian-specific)</li>
</ul>
</blockquote>
</li>
<li><em>value</em>：设定的值</li>
</ul>
<p><code>limits.conf</code> 的配置十分简单。但是自定义配置的时候并不建议直接修改该文件，可以把需要的配置写入 <code>/etc/security/limits.conf/&lt;file_name&gt;.conf</code>（文件名随意，conf 后缀）这样有利于后期维护和查阅改动点。</p>
<h2 id="系统限制修改"><a href="#系统限制修改" class="headerlink" title="系统限制修改"></a>系统限制修改</h2><p>可能会出现这样的情况，即使设置了较大的限制，但是应用最终依然被限制在了较低的阈值。这时候需要确认系统全局的限制。当然一般情况下，系统全局的限制并不容易触及，但是实际需要的话，我们依然可以进行调整。</p>
<h3 id="关于-proc-sys"><a href="#关于-proc-sys" class="headerlink" title="关于 /proc/sys"></a>关于 <code>/proc/sys</code></h3><p>系统内核的具体设定值都在 <code>/proc/sys</code> 之下，从网络到文件系统等等方方面面，比如关于网络的就在 <code>/proc/sys/net</code> 之下。不同的文件名对应了不同的配置参数，所以只需要直接查看对应文件就能知道设定值了。比如我们可以查看系统全局能打开的文件描述符数量：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">cat /proc/sys/fs/file-max</span></span><br><span class="line">93975</span><br></pre></td></tr></table></figure>

<p>如果要暂时修改，直接更改文件值就可以。影响全局而且不仅仅是当次会话哦。但是一旦重启就会还原回原来的状态。如果想要恒定修改，那么就需要 <code>/etc/sysctl.conf</code> 了。</p>
<h3 id="关于-etc-sysctl-conf-及-etc-sysctl-d"><a href="#关于-etc-sysctl-conf-及-etc-sysctl-d" class="headerlink" title="关于 /etc/sysctl.conf 及 /etc/sysctl.d/"></a>关于 <code>/etc/sysctl.conf</code> 及 <code>/etc/sysctl.d/</code></h3><p>修改 <code>/etc/sysctl.conf</code> 可以达到保存的效果。例如需要修改文件描述符限制更大，可以在文件末尾添加上：<code>fs.file-max=1024000</code>。同样的，做为自定的配置，我们可以将文件放置到 <code>/etc/sysctl.d/</code> 之下。但是可以和 <code>limits.d</code> 略有不同，可以参考文件夹下的 README，<code>10-&lt;name&gt;.conf</code> 是系统的配置，<code>30-&lt;name&gt;.conf</code> 是其他程序的设定，而一般用户自定义的可以使用 <code>60-&lt;name&gt;.conf</code> 这样的文件。最终会从 10/30/60/sysctl.conf 这样的顺序生效。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是关于如何修改应用级别的限制和系统全局限制的方式了。在调优的时候，需要先看一下关于网络、内存、文件等方面的限制。</p>
]]></content>
      <categories>
        <category>System</category>
      </categories>
      <tags>
        <tag>System</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 常用诊断工具小抄</title>
    <url>/2020/03/JVM-%E5%B8%B8%E7%94%A8%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7%E5%B0%8F%E6%8A%84/</url>
    <content><![CDATA[<h3 id="jps"><a href="#jps" class="headerlink" title="jps"></a>jps</h3><p>查看 Java 进程及其相关信息。<br>常用用法：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jps # 所有 java 进程</span><br><span class="line">jps -mv # 所有 java 进程及启动参数</span><br></pre></td></tr></table></figure>

<p>常用参数：</p>
<ul>
<li><strong>l</strong>：输出启动类全类名</li>
<li><strong>m</strong>：显示 main 方法接收到的参数</li>
<li><strong>v</strong>：显示 JVM 进程及其接收的参数，通常配合 <strong>m</strong> 得到进程的启动命令</li>
</ul>
<a id="more"></a>

<h3 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h3><p>查看或修改 Java 进程其虚拟机的配置项。<br>常用用法：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jinfo -flag &lt;config&gt; &lt;pid&gt; # 查看指定进程的指定配置值</span><br></pre></td></tr></table></figure>

<p>常用参数：</p>
<ul>
<li><strong>flags</strong> 主要用来查看对应进程的 <strong><em>非默认</em></strong> 配置项，和 <strong><em>通过命令行</em></strong> 配置的配置项</li>
<li><strong>flag [+|-<name>]</name></strong> 针对性查阅指定配置项具体值。在使用 <strong>+</strong> 或 <strong>-</strong> 时候可以启用或者禁用对应的布尔配置项</li>
<li><strong>sysprops</strong> 输出系统变量</li>
</ul>
<h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h3><p>用来导出 Java 程序当前的线程情况。不仅有所有的线程，还有各个线程的优先级、是否守护、线程状态等。通常在服务卡顿时候可能有死循环，通过 jstack 找出在特定方法上大量 RUNABLE 的线程<br>用法最为简单，只需要：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jstack &lt;pid&gt;</span><br></pre></td></tr></table></figure>

<h3 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h3><p>统计 JVM 运行的情况和各项指标，一般在分析问题中十分常用。<br>基本用法：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jstat &lt;-op&gt; [-t] &lt;pid&gt; [interval [count]] # op指定输出类别，t输出JVM启动时间，同时可以指定采样间隔和次数</span><br></pre></td></tr></table></figure>

<h4 id="jstat-常用输出选项"><a href="#jstat-常用输出选项" class="headerlink" title="jstat 常用输出选项"></a>jstat 常用输出选项</h4><p>jstat 功能强大几乎面面俱到，这里罗列部分常用的统计信息，详情可以参考 <a href="https://docs.oracle.com/en/java/javase/11/tools/jstat.html" target="_blank" rel="external nofollow noopener noreferrer">Java11-jstat</a>。</p>
<ul>
<li><strong>class</strong> 类加载卸载的数量及耗时等</li>
<li><strong>compiler</strong> JIT 编译器的统计信息</li>
<li><strong>gcutil</strong> 输出 GC 统计信息以及各区使用量占比<ul>
<li>S0/S1/E/O/M/CCS: 各区使用量占比（这个可能还是 jmap 更直观）</li>
<li>YGC: Young GC 次数</li>
<li>YGCT: Young GC 耗时</li>
<li>FGC: Full GC 次数</li>
<li>FGCT: Full GC 耗时</li>
<li>GCT: 全部 GC 累计时间</li>
</ul>
</li>
<li><strong>gccause</strong> 在 <em>gcutil</em> 基础上增加上一次和当次的 GC 原因</li>
</ul>
<h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h3><p>jmap 用来检查分析 Java 程序的内存状态，比如定位一些内存泄露、内存溢出的情况。<br>基本用法：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">jmap &lt;-op&gt; &lt;pid&gt;</span><br></pre></td></tr></table></figure>

<h4 id="jmap-常用输出选项"><a href="#jmap-常用输出选项" class="headerlink" title="jmap 常用输出选项"></a>jmap 常用输出选项</h4><ul>
<li><strong>clstats</strong> 打印类加载器统计的情况，巨慢，尝试一直未成功…对生产指导意义似乎不大，不太常用</li>
<li><strong>heap</strong> 输出堆内存的信息，有使用的垃圾回收器、各区大小、当前使用占比以及包括 <em>SurvivorRatio</em> 之类的一些配置信息，十分直观</li>
<li><strong>dump</strong> 导出内存信息文件，下面会展开。导出文件用来给 MAT 等内存分析工具进行分析，用命令行直接使用 hprof 会稍复杂一些</li>
<li><strong>histo:[live]</strong> 打印各 Class 的实例数量和占用大小，加上 <code>:live</code> 可以只统计存活对象，可用来确认内存泄露问题，但不如 MAT 强大</li>
</ul>
<h4 id="内存信息文件"><a href="#内存信息文件" class="headerlink" title="内存信息文件"></a>内存信息文件</h4><p>一般生产环境出现内存溢出和泄露都是比较严重的问题。出现了必须即可解决，而如何保留内存溢出时候的案发现场？需要配合两个虚拟机参数了：</p>
<ul>
<li><code>-XX:+HeapDumpOnOutOfMemoryError</code> 在发生内存溢出时候导入内存镜像</li>
<li><code>-XX:HeapDumpPath=&lt;PATH&gt;</code> 指定导出的内存文件位置</li>
</ul>
<p>另一个方案就是通过 jmap 来导出了。<code>jmap -dump[:&lt;item&gt;]</code> 有几个子选项（多个间用逗号分开）：</p>
<ul>
<li><code>live</code> 只输出存活对象</li>
<li><code>format=b</code> 保存会 hprof 格式，通常都会指定上</li>
<li><code>file=&lt;fileName&gt;</code> 指定导出的文件名</li>
</ul>
<h3 id="问题和解决"><a href="#问题和解决" class="headerlink" title="问题和解决"></a>问题和解决</h3><ol>
<li>关于 jinfo/jmap 出现 <code>Can&#39;t attach symbolicator to the process</code> 问题。原因为 Linux 默认不允许使用 ptrace 方位运行的程序内存状态可以：<ol>
<li>[建议] 修改 echo 0 &gt; /proc/sys/kernel/yama/ptrace_scope</li>
<li>[永久] 修改 /etc/sysctl.d/10-ptrace.conf 中  kernel.yama.ptrace_scope = 0</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>对 Netty ByteBuf 的探究</title>
    <url>/2020/02/%E5%AF%B9-Netty-ByteBuf-%E7%9A%84%E6%8E%A2%E7%A9%B6/</url>
    <content><![CDATA[<h2 id="对-Netty-ByteBuf-的探究"><a href="#对-Netty-ByteBuf-的探究" class="headerlink" title="对 Netty ByteBuf 的探究"></a>对 Netty ByteBuf 的探究</h2><p><code>ByteBuf</code> 是 Netty 在通信过程中数据传递的容器，类似于 Java NIO 中的 <code>ByteBuffer</code>，是通道 <code>Channel</code> 传输过程中的介质。</p>
<h3 id="ByteBuf-类型"><a href="#ByteBuf-类型" class="headerlink" title="ByteBuf 类型"></a>ByteBuf 类型</h3><p>从池化与否上看，分为池化的 <code>PooledByteBuf</code> 和非池化的 <code>UnpooledByteBuf</code>，</p>
<p>而从内存属性上看 <code>ByteBuf</code> 有着使用<strong>堆内存</strong>的 <code>HeapByteBuf</code> 以及<strong>基于直接内存映射</strong>的 <code>DirectByteBuf</code>。Netty 的高效也体现在 <code>ByteBuf</code> 的使用上，以 <code>NIOEventLoop</code> 来举例，在通道读写是后使用了 <code>PooledDirectByteBuf</code> 将字节缓冲的高效发挥到了极致。</p>
<a id="more"></a>

<h4 id="ByteBuf-分配方式"><a href="#ByteBuf-分配方式" class="headerlink" title="ByteBuf 分配方式"></a>ByteBuf 分配方式</h4><ul>
<li><strong><code>UnPooledHeapByteBuf</code></strong> 即在堆中新建对应大小的数组并初始化容量大小、读写索引等</li>
<li><strong><code>UnPooledDirectByteBuf</code></strong> 对应的使用 <code>java.nio.ByteBuffer.allocateDirect(capacity)</code> 进行初始化。由于使用堆外内存，可能因为使用不当产生内存泄露，建议在调试时打开最高等级的泄露探测：<code>-Dio.netty.leakDetection.level=PARANOID</code>。<blockquote>
<p>Enables paranoid resource leak detection which reports where the leaked object was accessed recently, at the cost of the highest possible overhead (for testing purposes only).</p>
</blockquote>
</li>
<li><strong><code>PooledByteBuf</code></strong> 其实和非池化的 <code>ByteBuf</code> 分配方式类似，不过 Netty 特别定制了一套池化管理方案来提高分配的效率，但是稍显复杂。</li>
</ul>
<p>对于 <code>PooledByteBuf</code>，Netty 使用了对象池、Unsafe 操作、ThreadLocal 等技术来优化，以期提升 <code>ByteBuf</code> 的申请效率和垃圾回收效率。从 <code>PoolByteBufAllocator</code> 开始，主要关注一下 <code>ByteBuf</code> 的缓存机制和内存方案。</p>
<h3 id="ByteBuf-分配流程"><a href="#ByteBuf-分配流程" class="headerlink" title="ByteBuf 分配流程"></a>ByteBuf 分配流程</h3><p>首先 Netty 在不同线程进行 <code>allocate()</code> 时候，会采用类 ThreadLocal 技术进行优化，以 <code>HeapBuffer</code> 为例看下 <code>PooledByteBufAllocator.newHeapBuffer(int,int)</code>，<strong>先关注第一步</strong>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> ByteBuf <span class="title">newHeapBuffer</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">int</span> maxCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1.PoolThreadLocalCache.get() 获取线程本地的 PoolThreadCache</span></span><br><span class="line">    PoolThreadCache cache = threadCache.get();</span><br><span class="line">    PoolArena&lt;<span class="keyword">byte</span>[]&gt; heapArena = cache.heapArena;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> ByteBuf buf;</span><br><span class="line">    <span class="keyword">if</span> (heapArena != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 2.PoolArena.allocate() 来分配内存</span></span><br><span class="line">        buf = heapArena.allocate(cache, initialCapacity, maxCapacity);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 如果没有 Arena 转而使用使用 UnpooledByteBuf</span></span><br><span class="line">        buf = PlatformDependent.hasUnsafe() ?</span><br><span class="line">                <span class="keyword">new</span> UnpooledUnsafeHeapByteBuf(<span class="keyword">this</span>, initialCapacity, maxCapacity) :</span><br><span class="line">                <span class="keyword">new</span> UnpooledHeapByteBuf(<span class="keyword">this</span>, initialCapacity, maxCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 包装一下，监听泄露</span></span><br><span class="line">    <span class="keyword">return</span> toLeakAwareBuffer(buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>threadCache</code> 是在构造器中初始化了的一个 <code>PoolThreadLocalCache</code> 内部类。该对象继承自 <code>FastThreadLocal&lt;PoolThreadCache&gt;</code>。这里的 <code>FastThreadLocal</code> 是 Netty 不满足于 JDK 方案而单独实现的线程本地缓存，从 API 角度来看使用方式基本一致。<br><code>PoolThreadLocalCache.get()</code> 首先进行缓存获取，未命中的情况下也会通过 <code>initialValue()</code> 初始化一个 <code>PoolThreadCache</code>。</p>
<p>以 <code>HeapByteBuf</code> 为例，看下 <code>PoolThreadCache</code> 几个重要的变量（省略 direct 相关）。保存了两个相关联的 <code>PoolArena</code> 和几个 <code>MemoryRegionCache</code>，是最核心实现内存分配的组件。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 保存了该 cache 属于哪个 arena，这是 Allocator 中多个 arena 中的一个（线程均分）</span></span><br><span class="line"><span class="keyword">final</span> PoolArena&lt;<span class="keyword">byte</span>[]&gt; heapArena;</span><br><span class="line"><span class="comment">// 不同大小的 MemoryReginCache（tiny/samll/normal）</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> MemoryRegionCache&lt;<span class="keyword">byte</span>[]&gt;[] tinySubPageHeapCaches;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> MemoryRegionCache&lt;<span class="keyword">byte</span>[]&gt;[] smallSubPageHeapCaches;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> MemoryRegionCache&lt;<span class="keyword">byte</span>[]&gt;[] normalHeapCaches;</span><br></pre></td></tr></table></figure>

<p>这里先回头看分配器的 <code>newHeapBuffer(int,int)</code>，<strong>关注第二步</strong>：<code>ByteBuf</code> 是由 <code>PoolArena</code> 分配，方法参数中的 <code>cache</code> 也就是持有 <code>arena</code> 的 <code>PoolThreadCache</code>。那么来看一下 <code>PoolArena.allocate()</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">PooledByteBuf&lt;T&gt; <span class="title">allocate</span><span class="params">(PoolThreadCache cache, <span class="keyword">int</span> reqCapacity, <span class="keyword">int</span> maxCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取 ByteBuf 的对象重用</span></span><br><span class="line">    PooledByteBuf&lt;T&gt; buf = newByteBuf(maxCapacity);</span><br><span class="line">    <span class="comment">// 分配内存空间</span></span><br><span class="line">    allocate(cache, buf, reqCapacity);</span><br><span class="line">    <span class="keyword">return</span> buf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="ByteBuf-对象复用"><a href="#ByteBuf-对象复用" class="headerlink" title="ByteBuf 对象复用"></a>ByteBuf 对象复用</h4><p>这里 <code>newBytebuf(int)</code> 实现取决于 heap/direct 以及 unsafe 是否可用，但是本质依然大同小异，以 <code>PoolHeapByteBuf</code> 为例，追踪到：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> PooledHeapByteBuf <span class="title">newInstance</span><span class="params">(<span class="keyword">int</span> maxCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 通过 Recycler 复用对象</span></span><br><span class="line">    PooledHeapByteBuf buf = RECYCLER.get();</span><br><span class="line">    <span class="comment">// reuse 即重置各个标志位，不再展开</span></span><br><span class="line">    buf.reuse(maxCapacity);</span><br><span class="line">    <span class="keyword">return</span> buf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>ByteBuf</code> 引用的获取依托于 <code>RECYCLER</code>, 这个 <code>RECYCLER</code> 是 <code>ObjectPool</code> 对象池的实现，并将对象的创建委托给 <code>Recycler</code> 实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里泛型 T 为 PoolByteBuf</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> T <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 不进行重用</span></span><br><span class="line">    <span class="keyword">if</span> (maxCapacityPerThread == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> newObject((Handle&lt;T&gt;) NOOP_HANDLE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 获取一个本线程的栈</span></span><br><span class="line">    Stack&lt;T&gt; stack = threadLocal.get();</span><br><span class="line">    <span class="comment">// pop 出一个 handle，对应 ByteBuf.deallocate() 时候 recycler 会进行 push</span></span><br><span class="line">    DefaultHandle&lt;T&gt; handle = stack.pop();</span><br><span class="line">    <span class="keyword">if</span> (handle == <span class="keyword">null</span>) &#123;</span><br><span class="line">        handle = stack.newHandle();</span><br><span class="line">        <span class="comment">// handle 为空则委托 handle 新建 ByteBuf</span></span><br><span class="line">        handle.value = newObject(handle);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果有使用过的 handle，直接复用之前的 ByteBuf 对象（解构时会 push 进栈）</span></span><br><span class="line">    <span class="keyword">return</span> (T) handle.value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>到此为止，<code>ByteBuf</code> 对象复用的过程已经完成。</p>
<h4 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h4><p>分配内存空间的步骤在 <code>allocate(cache, buf, reqCapacity);</code>，由于篇幅较长省略了相关代码，简单来说，</p>
<ol>
<li>首先对需要申请的空间进行标准化。<ul>
<li>capacity &lt;= 512B，计算一个大于等于申请容量的 16B 倍数的大小</li>
<li>512 &lt; capacity &lt;= pageSzie，计算一个大于等于申请容量的 512B 倍数的大小</li>
<li>capacity &gt; pageSize，计算一个相应的 pageSize 倍数的大小</li>
</ul>
</li>
<li>再看 <em>normCapacity</em> 大小来执行不同 allocate 逻辑：<ul>
<li><strong><em>tiny</em></strong>：小于 512 Bytes</li>
<li><strong><em>small</em></strong>：大于等于 512 Bytes，而小于 <em>pageSize</em></li>
<li><strong><em>normal</em></strong>：大于等于 <em>pageSize</em> 而小于等于 <em>chunkSize</em></li>
<li><strong><em>huge</em></strong>：超过 <em>chunkSize</em></li>
</ul>
</li>
</ol>
<h5 id="缓存命中"><a href="#缓存命中" class="headerlink" title="缓存命中"></a>缓存命中</h5><p>说一下之所以需要标准化并区分申请大小，是因为 <code>PoolThreadCache</code> 中的 <code>MemoryRegionCahce[]</code> 是按着需要划分的内存大小依次排列的，以 <code>tinySubPageHeapCaches</code> 为例，默认大小为 512/16=32，[0] 是 16B 大小的 <code>ByteBuf</code> 的引用队列，[1] 是 32B 大小的 ByteBuf 的引用队列… 依次到 496B，总共 32 个。</p>
<p align="center">
    <img src="https://blog-1258216698.cos.ap-hongkong.myqcloud.com/Netty/MemoryRegionCaches.png" alt="MemoryMap" width="600">
    <em>MemoryRegionCaches</em>
</p>

<p>small、normal 也是类似划分，只不过每个 Region 负责缓存的 <code>ByteBuf</code> 大小不同。在 <code>PoolArena</code> 中有对应的 <code>tinyIdx(int)</code> / <code>smallIdx(int)</code> / <code>normalIdx(int)</code> 来确定相应大小的 <code>ByteBuf</code> 需要的 Region 位置。</p>
<p>以分配一个 <em>tinyCapacity</em> 为例，<code>PoolArena</code> 需要委托 <code>PoolThreadCache</code> 执行 <code>cache.allocateTiny(this, buf, reqCapacity, normCapacity)</code> 判断缓存命中：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">allocateTiny</span><span class="params">(PoolArena&lt;?&gt; area, PooledByteBuf&lt;?&gt; buf, <span class="keyword">int</span> reqCapacity, <span class="keyword">int</span> normCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> allocate(cacheForTiny(area, normCapacity), buf, reqCapacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 先用这个 cacheForTiny 用来定位 MemoryRegionCache</span></span><br><span class="line"><span class="keyword">private</span> MemoryRegionCache&lt;?&gt; cacheForTiny(PoolArena&lt;?&gt; area, <span class="keyword">int</span> normCapacity) &#123;</span><br><span class="line">    <span class="comment">// int idx = PoolArena.tinyIdx(normCapacity);</span></span><br><span class="line">    <span class="comment">// 这里手动内联下 PoolArena.tinyIdx(int)</span></span><br><span class="line">    <span class="comment">// 大小除以 16，因为 tinyRegion 每个都差了 16B</span></span><br><span class="line">    <span class="keyword">int</span> idx = normCapacity &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">if</span> (area.isDirect()) &#123;</span><br><span class="line">        <span class="keyword">return</span> cache(tinySubPageDirectCaches, idx);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> cache(tinySubPageHeapCaches, idx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">allocate</span><span class="params">(PooledByteBuf&lt;T&gt; buf, <span class="keyword">int</span> reqCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Entry 队列，queue 的大小即不同类型的 cacheSize，默认分别为 512,256,64</span></span><br><span class="line">    Entry&lt;T&gt; entry = queue.poll();</span><br><span class="line">    <span class="keyword">if</span> (entry == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 初始化 ByteBuf</span></span><br><span class="line">    initBuf(entry.chunk, entry.nioBuffer, entry.handle, buf, reqCapacity);</span><br><span class="line">    <span class="comment">// 不再引用时交给 Recycler 减少 GC</span></span><br><span class="line">    entry.recycle();</span><br><span class="line">    ++ allocations;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="缓存命中失败"><a href="#缓存命中失败" class="headerlink" title="缓存命中失败"></a>缓存命中失败</h5><p>在 <code>PoolArena.allocate(cache, buf, reqCapacity)</code> 方法中，如果缓存命中，直接返回;如果未命中，<code>PoolArena</code> 会尝试开辟新的 <code>ByteBuf</code>。先看一下 <code>PoolArena</code> 中的一些重要成员：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolSubpage&lt;T&gt;[] tinySubpagePools;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolSubpage&lt;T&gt;[] smallSubpagePools;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolChunkList&lt;T&gt; q050;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolChunkList&lt;T&gt; q025;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolChunkList&lt;T&gt; q000;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolChunkList&lt;T&gt; qInit;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolChunkList&lt;T&gt; q075;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolChunkList&lt;T&gt; q100;</span><br></pre></td></tr></table></figure>

<h6 id="PoolSubpage-分配"><a href="#PoolSubpage-分配" class="headerlink" title="PoolSubpage 分配"></a>PoolSubpage 分配</h6><p>对于小于 <em>pageSize</em> 的 tiny/small 类型，交给 <code>PoolSubpage</code> 执行分配。</p>
<h6 id="PoolChunkList-分配"><a href="#PoolChunkList-分配" class="headerlink" title="PoolChunkList 分配"></a>PoolChunkList 分配</h6><p>大于 <em>pageSize</em> 的空间分配交给 <code>PoolChunkList</code> 完成。<code>PoolChunkList</code> 本身是一个双向列表，<code>PoolArena</code> 中的 6 个 <code>PoolChunkList</code> 分别存储不同剩余空间的 <code>PoolChunk</code> 并依次连接。不同 <code>ChunnkList</code> 的初始化：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">q100 = <span class="keyword">new</span> PoolChunkList&lt;T&gt;(<span class="keyword">this</span>, <span class="keyword">null</span>, <span class="number">100</span>, Integer.MAX_VALUE, chunkSize);</span><br><span class="line">q075 = <span class="keyword">new</span> PoolChunkList&lt;T&gt;(<span class="keyword">this</span>, q100, <span class="number">75</span>, <span class="number">100</span>, chunkSize);</span><br><span class="line">q050 = <span class="keyword">new</span> PoolChunkList&lt;T&gt;(<span class="keyword">this</span>, q075, <span class="number">50</span>, <span class="number">100</span>, chunkSize);</span><br><span class="line">q025 = <span class="keyword">new</span> PoolChunkList&lt;T&gt;(<span class="keyword">this</span>, q050, <span class="number">25</span>, <span class="number">75</span>, chunkSize);</span><br><span class="line">q000 = <span class="keyword">new</span> PoolChunkList&lt;T&gt;(<span class="keyword">this</span>, q025, <span class="number">1</span>, <span class="number">50</span>, chunkSize);</span><br><span class="line">qInit = <span class="keyword">new</span> PoolChunkList&lt;T&gt;(<span class="keyword">this</span>, q000, Integer.MIN_VALUE, <span class="number">25</span>, chunkSize);</span><br><span class="line"></span><br><span class="line">q100.prevList(q075);</span><br><span class="line">q075.prevList(q050);</span><br><span class="line">q050.prevList(q025);</span><br><span class="line">q025.prevList(q000);</span><br><span class="line">q000.prevList(<span class="keyword">null</span>);</span><br><span class="line">qInit.prevList(qInit);</span><br></pre></td></tr></table></figure>

<p>而 <code>PoolChunkList</code> 内部的 <code>PoolChunk</code> 同时也是一个双向列表，正好形成了这个样子：</p>
<p align="center">
    <img src="https://blog-1258216698.cos.ap-hongkong.myqcloud.com/Netty/ChunkList.png" alt="MemoryMap" width="500">
    <em>PoolChunkList</em>
</p>

<p>看一下超过 <em>pageSize</em> 时候的分配方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">allocateNormal</span><span class="params">(PooledByteBuf&lt;T&gt; buf, <span class="keyword">int</span> reqCapacity, <span class="keyword">int</span> normCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 在不同 chunkList 中尝试分配</span></span><br><span class="line">    <span class="comment">// 当然地，分配成功后会检查占用率，超过上限会被转移到下个 chunkList</span></span><br><span class="line">    <span class="keyword">if</span> (q050.allocate(buf, reqCapacity, normCapacity) || q025.allocate(buf, reqCapacity, normCapacity) ||</span><br><span class="line">        q000.allocate(buf, reqCapacity, normCapacity) || qInit.allocate(buf, reqCapacity, normCapacity) ||</span><br><span class="line">        q075.allocate(buf, reqCapacity, normCapacity)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 最初的时候偶总是要新开 chunk</span></span><br><span class="line">    PoolChunk&lt;T&gt; c = newChunk(pageSize, maxOrder, pageShifts, chunkSize);</span><br><span class="line">    <span class="comment">// PoolChunk 进行 allocate</span></span><br><span class="line">    <span class="keyword">boolean</span> success = c.allocate(buf, reqCapacity, normCapacity);</span><br><span class="line">    <span class="keyword">assert</span> success;</span><br><span class="line">    <span class="comment">// 最初被添加到 qInit 这个 chunkList 中</span></span><br><span class="line">    qInit.add(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>超过 <em>pageSize</em> 时候需要 <code>PoolChunk</code> 来进行分配，<code>PoolChunk</code> 也是内存这块儿重要的一个部分</p>
<hr>
<h4 id="PoolChunk"><a href="#PoolChunk" class="headerlink" title="PoolChunk"></a>PoolChunk</h4><p>简单看一下 <code>PoolChunk</code> 的构造：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 省略了部分</span></span><br><span class="line"><span class="comment">// 在这里对 memoryMap 进行初始化</span></span><br><span class="line"><span class="comment">// memoryMap/depthMap 大小为 1 &lt;&lt; maxOrder 默认 2048</span></span><br><span class="line">memoryMap = <span class="keyword">new</span> <span class="keyword">byte</span>[maxSubpageAllocs &lt;&lt; <span class="number">1</span>];</span><br><span class="line">depthMap = <span class="keyword">new</span> <span class="keyword">byte</span>[memoryMap.length];</span><br><span class="line"><span class="comment">// memoryMap 有效索引从 1 开始</span></span><br><span class="line"><span class="keyword">int</span> memoryMapIndex = <span class="number">1</span>;</span><br><span class="line"><span class="comment">// d 标识 memoryMap 树状结构的深度</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> d = <span class="number">0</span>; d &lt;= maxOrder; ++ d) &#123;</span><br><span class="line">    <span class="comment">// 这里 depth 标识树的每层有多少个节点</span></span><br><span class="line">    <span class="comment">// d:depth =&gt; 0:1,1:2,2:4,3:8,4:16...</span></span><br><span class="line">    <span class="keyword">int</span> depth = <span class="number">1</span> &lt;&lt; d;</span><br><span class="line">    <span class="comment">// 每个节点赋值为 d 深度</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> p = <span class="number">0</span>; p &lt; depth; ++ p) &#123;</span><br><span class="line">        <span class="comment">// in each level traverse left to right and set value to the depth of subtree</span></span><br><span class="line">        memoryMap[memoryMapIndex] = (<span class="keyword">byte</span>) d;</span><br><span class="line">        depthMap[memoryMapIndex] = (<span class="keyword">byte</span>) d;</span><br><span class="line">        memoryMapIndex ++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 初始化 subPages 的大小</span></span><br><span class="line">subpages = newSubpageArray(maxSubpageAllocs);</span><br><span class="line">cachedNioBuffers = <span class="keyword">new</span> ArrayDeque&lt;ByteBuffer&gt;(<span class="number">8</span>);</span><br></pre></td></tr></table></figure>

<h5 id="如果超过-pageSize-的分配"><a href="#如果超过-pageSize-的分配" class="headerlink" title="如果超过 pageSize 的分配"></a>如果超过 <em>pageSize</em> 的分配</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">allocateRun</span><span class="params">(<span class="keyword">int</span> normCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// normCapacity 为大于申请容量的最小 2 次幂（类似 HashMap.capacity）</span></span><br><span class="line">    <span class="comment">// 默认 pageSize = 8192 则 pageShifts = 13</span></span><br><span class="line">    <span class="comment">// 默认 maxOrder = 11</span></span><br><span class="line">    <span class="comment">// 若 normCapacity = 8192，d = 11，normCapacity = 16384，d = 10</span></span><br><span class="line">    <span class="comment">// d 为二叉树的深度，申请的越少，就寻找越深的层数，当申请一个 pageSize 时定位到树底层</span></span><br><span class="line">    <span class="keyword">int</span> d = maxOrder - (log2(normCapacity) - pageShifts);</span><br><span class="line">    <span class="comment">// 转下一步</span></span><br><span class="line">    <span class="keyword">int</span> id = allocateNode(d);</span><br><span class="line">    <span class="keyword">if</span> (id &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// runLength 获得改节点占用的内存大小，用来更新空闲内存大小</span></span><br><span class="line">    freeBytes -= runLength(id);</span><br><span class="line">    <span class="keyword">return</span> id;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过 <em>capacity</em> 得到 <em>d(depth)</em> ，然后就可以通过 <em>d</em> 深度来找到 memoryMap 中的 index 了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">allocateNode</span><span class="params">(<span class="keyword">int</span> d)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> id = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> initial = - (<span class="number">1</span> &lt;&lt; d); <span class="comment">// has last d bits = 0 and rest all = 1</span></span><br><span class="line">    <span class="comment">// value(id) 即 memoryMap[id]</span></span><br><span class="line">    <span class="keyword">byte</span> val = value(id);</span><br><span class="line">    <span class="comment">// 根节点作为边界值单独判定了一次</span></span><br><span class="line">    <span class="comment">// memoryMap 有效元素从 1 开始，长度为 1 &lt;&lt; maxOrder &lt;&lt; 1 默认 4096</span></span><br><span class="line">    <span class="comment">// 根节点判断失败，意味着空间不够</span></span><br><span class="line">    <span class="keyword">if</span> (val &gt; d) &#123; <span class="comment">// unusable</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// val &lt; d 意味着该层（包含子层）空间充裕，尝试在继续往下一层</span></span><br><span class="line">    <span class="keyword">while</span> (val &lt; d || (id &amp; initial) == <span class="number">0</span>) &#123; <span class="comment">// id &amp; initial == 1 &lt;&lt; d for all ids at depth d, for &lt; d it is 0</span></span><br><span class="line">        id &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">        val = value(id);</span><br><span class="line">        <span class="comment">// 判断同层余量</span></span><br><span class="line">        <span class="keyword">if</span> (val &gt; d) &#123;</span><br><span class="line">            id ^= <span class="number">1</span>;</span><br><span class="line">            val = value(id);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">byte</span> value = value(id);</span><br><span class="line">    <span class="keyword">assert</span> value == d &amp;&amp; (id &amp; initial) == <span class="number">1</span> &lt;&lt; d : String.format(<span class="string">"val = %d, id &amp; initial = %d, d = %d"</span>,</span><br><span class="line">            value, id &amp; initial, d);</span><br><span class="line">    <span class="comment">// 设置 memoryMap 该位置不可用</span></span><br><span class="line">    <span class="comment">// unusable 在构造器中被初始化为 maxOrder + 1，默认即为 12</span></span><br><span class="line">    setValue(id, unusable); <span class="comment">// mark as unusable</span></span><br><span class="line">    <span class="comment">// 更新树上祖先节点的值，用来之后判断子节点的可用情况</span></span><br><span class="line">    updateParentsAlloc(id);</span><br><span class="line">    <span class="comment">// 即 index of memoryMap</span></span><br><span class="line">    <span class="keyword">return</span> id;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>用图形来展示的话 <code>memoryMap</code> 就如下所示。每个方格是其中一个元素，<code>allocateNode(int d)</code> 就是通过申请的大小确定了深度 d 之后，来寻找可用的一个内存位置，反映在 <code>memoryMap</code> 的索引号上。虽然是看上去是树形的层级关系，但是下层本质是上层的一部分。</p>
<p align="center">
    <img src="https://blog-1258216698.cos.ap-hongkong.myqcloud.com/Netty/MemoryMap.png" alt="MemoryMap" width="500">
    <em>MemoryMap</em>
</p>

<h5 id="小于-pageSize-的分配"><a href="#小于-pageSize-的分配" class="headerlink" title="小于 pageSize 的分配"></a>小于 <em>pageSize</em> 的分配</h5><p>看需要看下 <code>PoolChunk</code> 中 <code>PoolSubPage[]</code> 的结构，每个 <code>PoolChunk</code> 都是 N 个 page，memoryMap 的叶子节点所维护的内存就是各个 page 的内存。Netty 对于小于 <em>pageSize</em> 的内存申请，首先会定位通过 <code>allocateNode(int)</code> 找到对应的一个页的内存，然后该页就被切分成若干块作为 <code>SubPage</code> 单元来使用。 </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">allocateSubpage</span><span class="params">(<span class="keyword">int</span> normCapacity)</span> </span>&#123;</span><br><span class="line">    PoolSubpage&lt;T&gt; head = arena.findSubpagePoolHead(normCapacity);</span><br><span class="line">    <span class="comment">// memoryMap 的最底层节点都是 pageSize，所以 subPage 的分配都在这一层</span></span><br><span class="line">    <span class="keyword">int</span> d = maxOrder;</span><br><span class="line">    <span class="keyword">synchronized</span> (head) &#123;</span><br><span class="line">        <span class="comment">// 这里上面已经分析了，获取 memoryMap 索引号</span></span><br><span class="line">        <span class="keyword">int</span> id = allocateNode(d);</span><br><span class="line">        <span class="keyword">if</span> (id &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> id;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> PoolSubpage&lt;T&gt;[] subpages = <span class="keyword">this</span>.subpages;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> pageSize = <span class="keyword">this</span>.pageSize;</span><br><span class="line">        freeBytes -= pageSize;</span><br><span class="line">        <span class="comment">// 定位 subPage，在 PoolChunk 中维护的 subPages[] 其实是叶子上对应的 page（如果对应位置作为了 subPage 的话）</span></span><br><span class="line">        <span class="keyword">int</span> subpageIdx = subpageIdx(id);</span><br><span class="line">        PoolSubpage&lt;T&gt; subpage = subpages[subpageIdx];</span><br><span class="line">        <span class="comment">// 有可能为空，PoolChunk 中的 subPage 是接着 head 的 subPage</span></span><br><span class="line">        <span class="comment">// head 是 PoolArena 中 subpages 的头节点</span></span><br><span class="line">        <span class="keyword">if</span> (subpage == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 包含了 init() </span></span><br><span class="line">            subpage = <span class="keyword">new</span> PoolSubpage&lt;T&gt;(head, <span class="keyword">this</span>, id, runOffset(id), pageSize, normCapacity);</span><br><span class="line">            subpages[subpageIdx] = subpage;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 重新初始化</span></span><br><span class="line">            subpage.init(head, normCapacity);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> subpage.allocate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如何构建 <code>PoolSubPage</code>:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(PoolSubpage&lt;T&gt; head, <span class="keyword">int</span> elemSize)</span> </span>&#123;</span><br><span class="line">    doNotDestroy = <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">// 一份 subPage 的大小</span></span><br><span class="line">    <span class="keyword">this</span>.elemSize = elemSize;</span><br><span class="line">    <span class="keyword">if</span> (elemSize != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 最大/当前 可以使用的 subPage 个数</span></span><br><span class="line">        <span class="comment">// 如要开辟 16B 的子页，默认 pageSize = 8K，则为 512；如果开辟 4K 则为 2</span></span><br><span class="line">        maxNumElems = numAvail = pageSize / elemSize;</span><br><span class="line">        nextAvail = <span class="number">0</span>;</span><br><span class="line">        bitmapLength = maxNumElems &gt;&gt;&gt; <span class="number">6</span>;</span><br><span class="line">        <span class="comment">// 如果申请太大，切分数也最少为 2 (bitmapLength = 1)</span></span><br><span class="line">        <span class="keyword">if</span> ((maxNumElems &amp; <span class="number">63</span>) != <span class="number">0</span>) &#123;</span><br><span class="line">            bitmapLength ++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 初始化 bitmap，标志着 page 的占用</span></span><br><span class="line">        <span class="comment">// bitMap 长度为 pageSize / 1024 默认 8，但不是所有位都有实际意义，有效位同 bitmapLength</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; bitmapLength; i ++) &#123;</span><br><span class="line">            bitmap[i] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 加入队列，之后可以在 Arena 中进行引用了</span></span><br><span class="line">    addToPool(head);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 <code>PollArena</code> 中申请 <code>subPage</code> 内存空间，同样是 allocate 过程，简化一下上下文：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 简化，以 tiny 为例</span></span><br><span class="line"><span class="keyword">if</span> (tiny) &#123; <span class="comment">// &lt; 512</span></span><br><span class="line">    <span class="comment">// 尝试缓存</span></span><br><span class="line">    <span class="keyword">if</span> (cache.allocateTiny(<span class="keyword">this</span>, buf, reqCapacity, normCapacity)) &#123;</span><br><span class="line">        <span class="comment">// was able to allocate out of the cache so move on</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    tableIdx = tinyIdx(normCapacity);</span><br><span class="line">    table = tinySubpagePools;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// tinyPool 为 512 &gt;&gt;&gt; 4 = 32，smallPool 为 log2PageSize - 9 默认 4</span></span><br><span class="line"><span class="comment">// 这里省略 tinyIdx/smallIdx 的算法，tinyPool 被固定分成了 16/32/48...496 大小</span></span><br><span class="line"><span class="comment">// smallPool 则按指数形式 512/1024/2048/4096，8192 就不用 subPage 啦</span></span><br><span class="line"><span class="keyword">final</span> PoolSubpage&lt;T&gt; head = table[tableIdx];</span><br><span class="line"><span class="keyword">synchronized</span> (head) &#123;</span><br><span class="line">    <span class="keyword">final</span> PoolSubpage&lt;T&gt; s = head.next;</span><br><span class="line">    <span class="keyword">if</span> (s != head) &#123;</span><br><span class="line">        <span class="keyword">assert</span> s.doNotDestroy &amp;&amp; s.elemSize == normCapacity;</span><br><span class="line">        <span class="comment">// 使用 subPage 进行内存申请</span></span><br><span class="line">        <span class="keyword">long</span> handle = s.allocate();</span><br><span class="line">        <span class="keyword">assert</span> handle &gt;= <span class="number">0</span>;</span><br><span class="line">        s.chunk.initBufWithSubpage(buf, <span class="keyword">null</span>, handle, reqCapacity);</span><br><span class="line">        incTinySmallAllocation(tiny);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><code>PooledByteBuf</code> 分配通过 <code>PooledByteBufAllocator</code> 执行。通过 <code>PoolThreadLocalCache</code> 做线程本地缓存，缓存 <code>PoolThreadCache</code> 对象。其中有不同大小的 <code>MemoryRegionCache[]</code>，内部通过 <code>Recycler</code> 进行对象回收利用。在缓存未命中的情况下，交给 <code>PoolArena</code> 进行内存申请。<code>PoolArena</code> 对不同大小的申请有两种策略，如果大于等于 <em>pageSize</em> 的交给 <code>PoolChunk</code> 进行分配，并由 <code>PollChunkList</code> 进行关联调整；如果小于 <em>pageSize</em>，在由 <code>PoolChunk</code> 初始化 <code>PoolSubPage</code> 之后，同过 <code>PoolSubPage</code> 来做小内存的分配。</p>
<ul>
<li><code>PooledByteBufAllocator</code><ul>
<li><code>PoolThreadLocalCache&lt;PoolThreadCache&gt;</code><ul>
<li><code>MemoryRegionCache[]</code></li>
<li><code>PoolArena</code><ul>
<li><code>PoolSubPage[]</code></li>
<li><code>PoolChunkList</code><ul>
<li><code>PoolChunk</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty ByteBuf 相关参数意义</title>
    <url>/2020/02/Netty-ByteBuf-%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0%E6%84%8F%E4%B9%89/</url>
    <content><![CDATA[<p>这里仅记录一下 <code>ByteBuf</code> 相关的一下内存配置参数和默认情况，分析一下 Allocator 的组成，为分析 <code>ByteBuf</code> 做一些概念上的铺垫。</p>
<p>首先看几个 <code>PooledByteBifAllocator</code> 中的静态变量，挑了几个说明一下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 默认的 arena 数量，一个对应 HeapBuf 一个对应 DirectBuf</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_NUM_HEAP_ARENA;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_NUM_DIRECT_ARENA;</span><br><span class="line"><span class="comment">// 默认 pageSzie、order 默认的 chunk = pageSize &lt;&lt; order</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PAGE_SIZE;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_MAX_ORDER;</span><br><span class="line"><span class="comment">// 三个不同大小的 cacheSize</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_TINY_CACHE_SIZE;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_SMALL_CACHE_SIZE;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_NORMAL_CACHE_SIZE;</span><br></pre></td></tr></table></figure>

<a id="more"></a>
<p>再来看一下 <code>PooledByteBufAllocator</code> 的静态代码块，主要是为了结合机器环境和设置值对上面的静态变量进行初始化：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="comment">// 设置页大小，默认 8KB</span></span><br><span class="line">    <span class="keyword">int</span> defaultPageSize = SystemPropertyUtil.getInt(<span class="string">"io.netty.allocator.pageSize"</span>, <span class="number">8192</span>);</span><br><span class="line">    Throwable pageSizeFallbackCause = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 校验页大小是否是 2 的幂，且大于最小值</span></span><br><span class="line">        validateAndCalculatePageShifts(defaultPageSize);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        <span class="comment">// 如果设置的页大小有问题则重新设置为 8KB</span></span><br><span class="line">        pageSizeFallbackCause = t;</span><br><span class="line">        defaultPageSize = <span class="number">8192</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    DEFAULT_PAGE_SIZE = defaultPageSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 同样的设置 MaxOrder，默认 11。chunk = page &lt;&lt; order 即要申请的内存空间</span></span><br><span class="line">    <span class="keyword">int</span> defaultMaxOrder = SystemPropertyUtil.getInt(<span class="string">"io.netty.allocator.maxOrder"</span>, <span class="number">11</span>);</span><br><span class="line">    Throwable maxOrderFallbackCause = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 校验 MaxOrder 在 0~14 间，并且块大小不超过最大限制</span></span><br><span class="line">        validateAndCalculateChunkSize(DEFAULT_PAGE_SIZE, defaultMaxOrder);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        <span class="comment">// 检验失败则重置为默认的 11</span></span><br><span class="line">        maxOrderFallbackCause = t;</span><br><span class="line">        defaultMaxOrder = <span class="number">11</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    DEFAULT_MAX_ORDER = defaultMaxOrder;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Runtime runtime = Runtime.getRuntime();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 有一段官方说明，默认使用处理器数量两倍的 Arena（这和 Epoll/Nio EventLoop 的数量一致来避免争用）所以一般如果需要修改 EventLoop 的线程数量，需要同时定制好 ByteBuf 的分配器。</span></span><br><span class="line">    <span class="comment">// 默认 Arena 最小数量为处理器核心数两倍</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> defaultMinNumArena = NettyRuntime.availableProcessors() * <span class="number">2</span>;</span><br><span class="line">    <span class="comment">// 默认 Chunk = PageSize &lt;&lt; MaxOrder 按默认配置就是 16MB</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> defaultChunkSize = DEFAULT_PAGE_SIZE &lt;&lt; DEFAULT_MAX_ORDER;</span><br><span class="line">    <span class="comment">// 默认 Arena 数量取决于以下两者的最小值</span></span><br><span class="line">    <span class="comment">// - 处理器核心数两倍</span></span><br><span class="line">    <span class="comment">// - 对内存占用不超过 50% 且保证每个 Arena 拥有 3 个 Chunk</span></span><br><span class="line">    <span class="comment">// 默认的一个 Arena 16*3=48MB </span></span><br><span class="line">    DEFAULT_NUM_HEAP_ARENA = Math.max(<span class="number">0</span>,</span><br><span class="line">            SystemPropertyUtil.getInt(</span><br><span class="line">                    <span class="string">"io.netty.allocator.numHeapArenas"</span>,</span><br><span class="line">                    (<span class="keyword">int</span>) Math.min(</span><br><span class="line">                            defaultMinNumArena,</span><br><span class="line">                            runtime.maxMemory() / defaultChunkSize / <span class="number">2</span> / <span class="number">3</span>)));</span><br><span class="line">    <span class="comment">// 对直接内存也类似处理</span></span><br><span class="line">    DEFAULT_NUM_DIRECT_ARENA = Math.max(<span class="number">0</span>,</span><br><span class="line">            SystemPropertyUtil.getInt(</span><br><span class="line">                    <span class="string">"io.netty.allocator.numDirectArenas"</span>,</span><br><span class="line">                    (<span class="keyword">int</span>) Math.min(</span><br><span class="line">                            defaultMinNumArena,</span><br><span class="line">                            PlatformDependent.maxDirectMemory() / defaultChunkSize / <span class="number">2</span> / <span class="number">3</span>)));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化三个 size </span></span><br><span class="line">    DEFAULT_TINY_CACHE_SIZE = SystemPropertyUtil.getInt(<span class="string">"io.netty.allocator.tinyCacheSize"</span>, <span class="number">512</span>);</span><br><span class="line">    DEFAULT_SMALL_CACHE_SIZE = SystemPropertyUtil.getInt(<span class="string">"io.netty.allocator.smallCacheSize"</span>, <span class="number">256</span>);</span><br><span class="line">    DEFAULT_NORMAL_CACHE_SIZE = SystemPropertyUtil.getInt(<span class="string">"io.netty.allocator.normalCacheSize"</span>, <span class="number">64</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 缓存 Buffer 的默认最大大小</span></span><br><span class="line">    DEFAULT_MAX_CACHED_BUFFER_CAPACITY = SystemPropertyUtil.getInt(</span><br><span class="line">            <span class="string">"io.netty.allocator.maxCachedBufferCapacity"</span>, <span class="number">32</span> * <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设定超过多少大小进行缓存释放</span></span><br><span class="line">    DEFAULT_CACHE_TRIM_INTERVAL = SystemPropertyUtil.getInt(</span><br><span class="line">            <span class="string">"io.netty.allocator.cacheTrimInterval"</span>, <span class="number">8192</span>);</span><br><span class="line">    <span class="comment">// 设定超过多少时间进行缓存释放，默认仅依靠数量阈值释放缓存</span></span><br><span class="line">    DEFAULT_CACHE_TRIM_INTERVAL_MILLIS = SystemPropertyUtil.getLong(</span><br><span class="line">            <span class="string">"io.netty.allocation.cacheTrimIntervalMillis"</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 是否允许所有线程访问缓存内容</span></span><br><span class="line">    DEFAULT_USE_CACHE_FOR_ALL_THREADS = SystemPropertyUtil.getBoolean(</span><br><span class="line">            <span class="string">"io.netty.allocator.useCacheForAllThreads"</span>, <span class="keyword">true</span>);</span><br><span class="line">    <span class="comment">// 是否内存对齐，默认关闭</span></span><br><span class="line">    DEFAULT_DIRECT_MEMORY_CACHE_ALIGNMENT = SystemPropertyUtil.getInt(</span><br><span class="line">            <span class="string">"io.netty.allocator.directMemoryCacheAlignment"</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置每个 Chunk 可以缓存多少 ByteBuffer</span></span><br><span class="line">    DEFAULT_MAX_CACHED_BYTEBUFFERS_PER_CHUNK = SystemPropertyUtil.getInt(</span><br><span class="line">            <span class="string">"io.netty.allocator.maxCachedByteBuffersPerChunk"</span>, <span class="number">1023</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 省略 Debug Log</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p>静态变量作为分配器的一些阈值、默认值，那么这些成员变量控制着分配器实际状态</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里的成员变量都会在下面的全参构造器中进行初始化</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolArena&lt;<span class="keyword">byte</span>[]&gt;[] heapArenas;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolArena&lt;ByteBuffer&gt;[] directArenas;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> tinyCacheSize;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> smallCacheSize;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> normalCacheSize;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> List&lt;PoolArenaMetric&gt; heapArenaMetrics;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> List&lt;PoolArenaMetric&gt; directArenaMetrics;</span><br><span class="line"><span class="comment">// 这是分配器的核心，缓存池。在完成分配器的初始化后会分析</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PoolThreadLocalCache threadCache;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> chunkSize;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PooledByteBufAllocatorMetric metric;</span><br></pre></td></tr></table></figure>

<p>再看 <code>PooledByteBufAllocator</code> 的全参构造器，包含了缓存池的初始化：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">PooledByteBufAllocator</span><span class="params">(<span class="keyword">boolean</span> preferDirect, <span class="keyword">int</span> nHeapArena, <span class="keyword">int</span> nDirectArena, <span class="keyword">int</span> pageSize, <span class="keyword">int</span> maxOrder,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="keyword">int</span> tinyCacheSize, <span class="keyword">int</span> smallCacheSize, <span class="keyword">int</span> normalCacheSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                                  <span class="keyword">boolean</span> useCacheForAllThreads, <span class="keyword">int</span> directMemoryCacheAlignment)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 确认了是否直接内存优先</span></span><br><span class="line">    <span class="keyword">super</span>(preferDirect);</span><br><span class="line">    <span class="comment">// PoolThreadLocalCache 是 Netty FastThreadLocal 子类，Java ThreadLocal 更快</span></span><br><span class="line">    threadCache = <span class="keyword">new</span> PoolThreadLocalCache(useCacheForAllThreads);</span><br><span class="line">    <span class="comment">// 三个 cacheSize 大小赋值、chunkSize 赋值</span></span><br><span class="line">    <span class="keyword">this</span>.tinyCacheSize = tinyCacheSize;</span><br><span class="line">    <span class="keyword">this</span>.smallCacheSize = smallCacheSize;</span><br><span class="line">    <span class="keyword">this</span>.normalCacheSize = normalCacheSize;</span><br><span class="line">    chunkSize = validateAndCalculateChunkSize(pageSize, maxOrder);</span><br><span class="line">    <span class="comment">// 验证 Arena 数量</span></span><br><span class="line">    checkPositiveOrZero(nHeapArena, <span class="string">"nHeapArena"</span>);</span><br><span class="line">    checkPositiveOrZero(nDirectArena, <span class="string">"nDirectArena"</span>);</span><br><span class="line">    <span class="comment">// Alignment 对齐参数验证</span></span><br><span class="line">    checkPositiveOrZero(directMemoryCacheAlignment, <span class="string">"directMemoryCacheAlignment"</span>);</span><br><span class="line">    <span class="comment">// 内存对齐需要 unsafe 的支持，判断如果 JDK 实现中没有的话是不支持内存对齐的</span></span><br><span class="line">    <span class="keyword">if</span> (directMemoryCacheAlignment &gt; <span class="number">0</span> &amp;&amp; !isDirectMemoryCacheAlignmentSupported()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"directMemoryCacheAlignment is not supported"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 继续验证对齐值是否为 2 的幂次方</span></span><br><span class="line">    <span class="keyword">if</span> ((directMemoryCacheAlignment &amp; -directMemoryCacheAlignment) != directMemoryCacheAlignment) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"directMemoryCacheAlignment: "</span></span><br><span class="line">                + directMemoryCacheAlignment + <span class="string">" (expected: power of two)"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// pageShift = log2(pageSize)</span></span><br><span class="line">    <span class="keyword">int</span> pageShifts = validateAndCalculatePageShifts(pageSize);</span><br><span class="line">    <span class="comment">// 如果内存不够是无法开启 arena 的，而 arena 是池化的核心之一</span></span><br><span class="line">    <span class="keyword">if</span> (nHeapArena &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 初始化 arena，这些 arena 会被缓存池 PoolThreadLocalCache 引用</span></span><br><span class="line">        heapArenas = newArenaArray(nHeapArena);</span><br><span class="line">        List&lt;PoolArenaMetric&gt; metrics = <span class="keyword">new</span> ArrayList&lt;PoolArenaMetric&gt;(heapArenas.length);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; heapArenas.length; i ++) &#123;</span><br><span class="line">            PoolArena.HeapArena arena = <span class="keyword">new</span> PoolArena.HeapArena(<span class="keyword">this</span>,</span><br><span class="line">                    pageSize, maxOrder, pageShifts, chunkSize,</span><br><span class="line">                    directMemoryCacheAlignment);</span><br><span class="line">            heapArenas[i] = arena;</span><br><span class="line">            metrics.add(arena);</span><br><span class="line">        &#125;</span><br><span class="line">        heapArenaMetrics = Collections.unmodifiableList(metrics);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        heapArenas = <span class="keyword">null</span>;</span><br><span class="line">        heapArenaMetrics = Collections.emptyList();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 省略 directArena 初始化部分，同上</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 对 metric 初始化，暴露该分配器的的一些信息</span></span><br><span class="line">    metric = <span class="keyword">new</span> PooledByteBufAllocatorMetric(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到这里分配器的本身的初始化已经完成，包含了一个缓存池：<code>PoolThreadLocalCache</code>。这是 <code>FastThreadLocal&lt;PoolThreadCache&gt;</code> 的子类，同时也是 <code>PooledByteBufAllocator</code> 的一个非静态内部类，缓存池内的很多信息直接引用了分配器的一些成员变量，后续的 <code>ByteBuf</code> 的分配都是直接或者间接地通过这个缓存来执行的。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title>网络配置参数和调优的一些总结</title>
    <url>/2019/10/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E5%92%8C%E8%B0%83%E4%BC%98%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h3 id="内核配置"><a href="#内核配置" class="headerlink" title="内核配置"></a>内核配置</h3><p>先来了解几个关于网络的内核配置。</p>
<h4 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h4><p>以 CentOS 7 为例，目录 <code>/proc/sys/</code> 存放着内核相关配置，其中网络相关的主要集中在 <code>/proc/sys/net/core/</code>、<code>/proc/sys/net/ipv4/</code>、<code>/proc/sys/net/ipv6/</code> 几个目录下。在这几个目录下，不同参数名称对应一个文件，修改文件值可以调整对应参数。</p>
<p>同时，想要修改 <code>/proc/sys/</code> 下参数也可以通过修改 <code>/etc/sysctl.conf</code> 配置文件达到目的。如：想要修改 <code>/proc/sys/net/ipv4/tcp_max_syn_backlog</code> 为 <code>1024</code>，可以添加一行 <code>net.ipv4.tcp_max_syn_backlog = 1024</code>。也可以将自定义配置放入 <code>/etc/sysctl.d/</code> 中，自定义 <code>60-&lt;custom&gt;.conf</code> 的文件。具体可详见另一篇更改系统设置的文章。</p>
<a id="more"></a>

<h4 id="主要参数说明"><a href="#主要参数说明" class="headerlink" title="主要参数说明"></a>主要参数说明</h4><h5 id="一般需要调优的参数"><a href="#一般需要调优的参数" class="headerlink" title="一般需要调优的参数"></a>一般需要调优的参数</h5><ul>
<li><code>somaxconn</code> 完成连接队列上线。应用完成连接队列大小计算方式：  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">min(backlog, somaxconn)</span><br></pre></td></tr></table></figure>
  <code>backlog</code> 为打开 socket 时候的传入值，完成连接队列大小取决于该参数系统配置的最小值</li>
<li><code>tcp_max_syn_backlog</code> tcp 半连接队列上限。应用半连接队列大小计算方式：    <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">table_entries &#x3D; min(min（somaxconn，backlog）,tcp_max_syn_backlog)</span><br><span class="line">roundup_pow_of_two(table_entries + 1) # 大于 table_entries + 1 的最小 2 的 n 次幂</span><br></pre></td></tr></table></figure>
  <code>somaxconn</code> 和 <code>tcp_max_syn_backlog</code> 同时影响半连接队列的大小。所以对于一般应用程序需要在开启 Socket 时候指定 <code>backlog</code>，还需要提前对系统进行调优。<ul>
<li>默认情况下 <code>somaxconn == tcp_max_syn_backlog == 128</code> 需要配置提高，不然可能导致应用配置无效。</li>
<li>举例来说 redis、nginx 使用的 backlog 为 511。在系统配置满足的情况下，半连接队列为 512，完成连接队列为 511</li>
</ul>
</li>
<li><code>tcp_abort_on_overflow</code> 控制完成连接队列满时，收到客户端 ACK 时的处理方案。默认为 0，会忽略该次 ACK，导致向客户端重发 ACK+SYN，期望客户端再次发送 ACK 时候完成连接队列有空闲。设置为 1 会直接发送 RST 给客户端。</li>
</ul>
<p>由 TCP 全连接队列和半连接队列导致问题的典型案例可以参看<a href="http://jm.taobao.org/2017/05/25/525-1/" target="_blank" rel="external nofollow noopener noreferrer">阿里这一次问题复盘</a></p>
<hr>
<ul>
<li><code>tcp_timestamps</code> 连接需要额外使用 10 个字节来发送对方和回复的时间戳，用来辅助判断 TCP 包顺序判断。以下两个选项需要双方都开启 <code>tcp_timestamp</code> 才能正常生效</li>
<li><code>tcp_tw_reuse</code> 一般针对客户端方生效（比如压测发起机），是否允许将处于 TIME_WAIT 状态 socket 用于开启新的连接。如果禁用需要等待 2 个 MSL</li>
<li><code>tcp_tw_recycle</code> 系统缓存不同 IP 请求的最新 timestamp，如果来自同一主机的 SYN 请求时间小于缓存时间会被丢弃，如果大于则复用 TIME_WAIT 连接。但是由于大部分网络请求都经过 NAT，所以容易产生错误错误的过滤。一般不会开启。</li>
</ul>
<h5 id="其他参数"><a href="#其他参数" class="headerlink" title="其他参数"></a>其他参数</h5><ul>
<li><code>tcp_syncookies</code> 控制是否在连接 ESTABLISHED 阶段才进行资源分配，默认 1。<ul>
<li>1 连接队列满时生效</li>
<li>0 不生效，始终在收到 SYN 时分配资源</li>
<li>2 始终生效</li>
</ul>
</li>
<li><code>tcp_fastopen</code> 应用程序作为服务端是否支持 TCP FastOpen</li>
</ul>
<h5 id="Socket-选项"><a href="#Socket-选项" class="headerlink" title="Socket 选项"></a>Socket 选项</h5><ul>
<li><code>SO_REUSEADDR</code> 允许应用程序绑定同一端口</li>
<li><code>SO_LINGER</code> 默认为禁用，此时 <code>close()</code> 方法会直接返回，同时将 buffer 中内容交给操作系统发出并执行四次挥手；设置开启时需要指定时间，<code>close()</code> 方法会进行等待内容的全部发出并进行四次挥手，直到超时时间，如果超过时间阈值时将直接发送 RST 直接中断连接不再进行数据发送和四次挥手</li>
</ul>
<h3 id="服务器配置"><a href="#服务器配置" class="headerlink" title="服务器配置"></a>服务器配置</h3><p>默认情况下 Java 程序给出的 SererSocket 默认 <code>backlog</code> 为 100，系统的 <code>somaxconn</code> 为 128，这对于一些访问量高的程序来说可能并不够。一般来说，首先会把服务器的调高如 1024（因为无论是 ng、redis 还是一些 web 服务 128 都挺小的）。同时如果使用 <em>tomcat</em> 还需要注意一下几个配置：</p>
<ul>
<li><code>maxThreads</code> 工作线程池最大数，默认 200</li>
<li><code>maxConnections</code> 最多连接的 Socket 数量。BIO 默认 200，NIO 默认 10000，APR 默认 8192</li>
<li><code>disableKeepAlivePercentage</code> 需要主动关闭长连接的阈值</li>
<li><code>acceptCount</code> 对应 socket 的 backlog 数值，通过 netstat/ss 观察到有丢弃的连接时需要调整 accept 队列容量</li>
</ul>
<p>作为一些及时性要求高的应用或者还需要在 TCP 连接建立时候关闭 delay ack 的优化，因为默认的情况下为了提高传输效率会开启 Nagle 算法（将短时间内的多个 ack 合并成一个包，类型响应合并）</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="http://jm.taobao.org/2017/05/25/525-1/" target="_blank" rel="external nofollow noopener noreferrer">http://jm.taobao.org/2017/05/25/525-1/</a></li>
<li><a href="http://ifeve.com/tomcat-connector-tuning-1/" target="_blank" rel="external nofollow noopener noreferrer">http://ifeve.com/tomcat-connector-tuning-1/</a></li>
</ul>
]]></content>
      <categories>
        <category>Net</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP 头部选项的理解</title>
    <url>/2019/10/TCP-Options/</url>
    <content><![CDATA[<h4 id="TCP-Options"><a href="#TCP-Options" class="headerlink" title="TCP Options"></a>TCP Options</h4><p>TCP 报头通常包含 20 字节信息。但是同时可以携带额外的选项用来说明额外的信息（下图 Options）。</p>
<p><img src="https://i.loli.net/2019/10/28/naEFGM8OSbKwreY.png" alt="TCP-header.png"></p>
<p>每一组选项包含 1 个字节的类型标识，1 个字节的长度声明，n 个字节的具体数据，最大不超过 40 字节。</p>
<a id="more"></a>

<table>
<thead>
<tr>
<th align="center">Kind</th>
<th align="center">Length</th>
<th align="center">Value</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1 Byte</td>
<td align="center">1 Byte</td>
<td align="center">(Length - 2) Bytes</td>
</tr>
</tbody></table>
<p>以下是典型的几个选项说明：</p>
<table>
<thead>
<tr>
<th align="left">Kind</th>
<th align="left">Length</th>
<th align="left">Name</th>
<th align="left">Reference</th>
<th align="left">Desc</th>
</tr>
</thead>
<tbody><tr>
<td align="left">0</td>
<td align="left">1</td>
<td align="left">EOL</td>
<td align="left">RFC 793</td>
<td align="left">选项列表结束标识</td>
</tr>
<tr>
<td align="left">1</td>
<td align="left">1</td>
<td align="left">NOP</td>
<td align="left">RFC 793</td>
<td align="left">用于作为填充</td>
</tr>
<tr>
<td align="left">2</td>
<td align="left">4</td>
<td align="left">MSS</td>
<td align="left">RFC 793</td>
<td align="left">最大报文长度</td>
</tr>
<tr>
<td align="left">3</td>
<td align="left">3</td>
<td align="left">WSOPT</td>
<td align="left">RFC 1323</td>
<td align="left">窗口扩大系数</td>
</tr>
<tr>
<td align="left">4</td>
<td align="left">2</td>
<td align="left">SACK-Permitted</td>
<td align="left">RFC 2018</td>
<td align="left">标识支持SACK</td>
</tr>
<tr>
<td align="left">5</td>
<td align="left">可变</td>
<td align="left">SACK</td>
<td align="left">RFC 2018</td>
<td align="left">SACK Block</td>
</tr>
<tr>
<td align="left">8</td>
<td align="left">10</td>
<td align="left">TSPOT</td>
<td align="left">RFC 1323</td>
<td align="left">Timestamps</td>
</tr>
<tr>
<td align="left">19</td>
<td align="left">18</td>
<td align="left">TCP-MD5</td>
<td align="left">RFC 2385</td>
<td align="left">MD5认证</td>
</tr>
<tr>
<td align="left">28</td>
<td align="left">4</td>
<td align="left">UTO</td>
<td align="left">RFC 5482</td>
<td align="left">User Timeout</td>
</tr>
<tr>
<td align="left">29</td>
<td align="left">可变</td>
<td align="left">TCP-AO</td>
<td align="left">RFC 5925</td>
<td align="left">算法认证</td>
</tr>
<tr>
<td align="left">253/254</td>
<td align="left">可变</td>
<td align="left">Experimental</td>
<td align="left">RFC 4727</td>
<td align="left">实验性保留</td>
</tr>
</tbody></table>
<h5 id="End-of-Option-List"><a href="#End-of-Option-List" class="headerlink" title="End of Option List"></a>End of Option List</h5><p>列表结束标识，简称 <strong>EOL</strong>，仅包含 Kind 标识，1 个字节。用于隔开报头和报文数据。</p>
<h5 id="NO-Operation"><a href="#NO-Operation" class="headerlink" title="NO-Operation"></a>NO-Operation</h5><p>无操作 <strong>NOP</strong>。该选项仅包含 Kind 标识 1 个字节，用来进行对齐填充。因为报头长度需要满足 32bits(4Bytes) 倍数。 </p>
<h5 id="Maximum-Segment-Size"><a href="#Maximum-Segment-Size" class="headerlink" title="Maximum Segment Size"></a>Maximum Segment Size</h5><p>最大报文长度声明，简称 <strong>MSS</strong>。不仅仅是通知对端需要发送小于该值的报文，且不会接受报文长度大于该值的数据报。这个选项只会出现在 SYN 包中，如果在握手时该选项不存在，那么会使用默认值 536Bytes，最大值为 2^16-1 = 65535，长度 2 个字节。在一般的 ipv4 网络上，以太网 MTU = 1500Bytes, MSS 典型值 = 1500 - 20(ip header）- 20(tcp header) = 1460。</p>
<h5 id="Window-Scale"><a href="#Window-Scale" class="headerlink" title="Window Scale"></a>Window Scale</h5><p>窗口缩放大小。见滑动窗口说明。</p>
<h5 id="SACK-Permitted"><a href="#SACK-Permitted" class="headerlink" title="SACK-Permitted"></a>SACK-Permitted</h5><p>SACK 快速重传允许标识。SACK 见快速重传说明。</p>
<h5 id="SACK-Block"><a href="#SACK-Block" class="headerlink" title="SACK-Block"></a>SACK-Block</h5><p>SACK 阻塞段标识。见快速重传说明。</p>
<h5 id="Timestamp"><a href="#Timestamp" class="headerlink" title="Timestamp"></a>Timestamp</h5><p>该选项总长度 10Bytes。包含 16bits TimestampValue(TSval) 和 16bits TimestampEchoReply(TSecr)。如果双方都支持 timestamp，那发送方会在发送报文时写入当前时间戳，接受方会在 ACK 时候将对手时间戳写入 TSecr。基于 timestamp，可以方便地计算 RTT、防止序列号回绕、支持 tcp_tw_reuse 等。</p>
<h5 id="User-Timeout"><a href="#User-Timeout" class="headerlink" title="User Timeout"></a>User Timeout</h5><p>该选项用以提示对手方，本方等待 ACK 的时间。如果指定时间内没有收到 ACK 会，会连接断开。</p>
<h5 id="TCP-MD5-amp-TCP-AO"><a href="#TCP-MD5-amp-TCP-AO" class="headerlink" title="TCP-MD5 &amp; TCP-AO"></a>TCP-MD5 &amp; TCP-AO</h5><p>主要用来 TCP Spoofing Attacks 的防范。不展开。</p>
<p>–</p>
<p>以下回顾说明几个头部选项涉及到的概念。</p>
<h4 id="拓展：滑动窗口"><a href="#拓展：滑动窗口" class="headerlink" title="拓展：滑动窗口"></a>拓展：滑动窗口</h4><p>在 TCP 头部有个<strong>窗口大小</strong>，形容了接收端的处理能力，这是为了更好地协调双发通信的节奏，就是控制了 TCP 通信的流量。这个部分占头部的 16bits，也就是发送端可以声明的最大缓冲区大小 65535Bytes（当然现在一般是不够了）。</p>
<h5 id="接收窗口-amp-拥塞窗口"><a href="#接收窗口-amp-拥塞窗口" class="headerlink" title="接收窗口 &amp; 拥塞窗口"></a>接收窗口 &amp; 拥塞窗口</h5><p>发送端缓存了一批数据，这批数据通过接受端返回的窗口大小可以区分为 <em>已被确认<em>、</em>已发送未被确认<em>、</em>可发送<em>、</em>不可发送</em> 四个类型。抛开 <em>已被确认</em> 的数据部分，<em>已发送未被确认<em>、</em>可发送</em> 数据的范围大小由接收端的<strong>接收窗口</strong>和本方的<strong>拥塞窗口</strong>的最小大小限制，一般称这部分是<strong>发送窗口</strong>。通过减去 <em>已发送未被确认</em> 的数据得到，这一部分可以继续发送，称为<strong>可用窗口</strong>。余下的一部分缓存数据由于接收端处理能力不够（窗口大小不够）暂时不能发送。<br><strong>接收窗口 RWND</strong>：描述了接收方当前的剩余处理能力，按字节大小计算。<br><strong>拥塞窗口 CWND</strong>：描述了发送方考虑网络状况，对自己限流的情况，按可传输的 MSS 段来计算。</p>
<p>假设场景：</p>
<ol>
<li>接受端缓冲区大小为 1000，在握手 ACK 时通知了对方。</li>
<li>发送方发送了 400Bytes ，接收端的 ACK 数据报 Win=1000-400=600</li>
<li>发送方继续发送 400Bytes，接受端缓存仍未读取，ACK 数据报 Win=600-400=200</li>
<li>发送方此时最大可以发送 200Bytes，需要等待发送方窗口恢复才可继续发送。</li>
</ol>
<h6 id="零窗口嗅探"><a href="#零窗口嗅探" class="headerlink" title="零窗口嗅探"></a>零窗口嗅探</h6><p>从之前假设的场景可以看到，如果接收方因为高压力等原因数据处理较慢，返回给发送方一个 Win=0 的 ACK。而由于接收方窗口大小是由 ACK 包返回的，但发送方已经不能再发送数据了，这会让发送方一直处于等待状态？<br>在发送方收到 Win=0 的提示后，会触发一个 Len=0 Seq=Max(ACK)-1 的数据包，让接收方确认窗口恢复。</p>
<h6 id="窗口缩放"><a href="#窗口缩放" class="headerlink" title="窗口缩放"></a>窗口缩放</h6><p>发送方会将接收方返回的窗口进行缩放, 0~14。数值 n 代表左移位数，即最终缩放大小为 2 的 n 次方。原本 TCP header 中 window size 长度为 16 bit，即最大的标识区间是 65535 Bytes，通过 scale 可以将大小最大拓展成 65535 &lt;&lt; 14。由于 TCP 窗口是固定的，通过握手时确定大小，所以这个选项仅在 SYN 包中存在。</p>
<h5 id="拥塞处理"><a href="#拥塞处理" class="headerlink" title="拥塞处理"></a>拥塞处理</h5><h6 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h6><p>控制拥塞窗口的方法有很多，通常的一种是<strong>慢启动</strong>方案。期初分配较小的窗口值，通过交互时候的不断通信来提升拥塞窗口大小。</p>
<ul>
<li>linux 一般默认的 initcwnd = 10</li>
<li>每次收到 ACK cwnd + 1</li>
<li>由于 cwnd 在每次收到 ACK 后扩大 1，所以一个 RTT 内相当于 cwnd &lt;&lt; 1 也就是进行了翻倍。</li>
</ul>
<h6 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h6><p>由于慢启动 cwnd 增长太快，当达到 ssthresh 时候会切换方案。</p>
<ul>
<li>不再按每次 ACK 进行 cwnd + 1</li>
<li>收到 ACK 时候，cwnd = cwnd + 1/cwnd，这样在大约在一个 RTT 内 cwnd + 1，好处在于会将<strong>指数型增长的 cwnd 变成线性增长</strong>。在收到三个重复 ACK 时候会视为轻度拥堵，此时会直接进行拥塞避免状态：</li>
</ul>
<ol>
<li>降低 ssthresh，ssthresh = cwnd &gt;&gt; 1</li>
<li>cwnd = ssthresh</li>
</ol>
<h4 id="拓展：SACK-快速重传机制"><a href="#拓展：SACK-快速重传机制" class="headerlink" title="拓展：SACK 快速重传机制"></a>拓展：SACK 快速重传机制</h4><p>TCP 回复 ACK 时候携带的确认序列号意义为 <strong>小于该序列号的所有数据报已收到</strong>。假设有以下场景：</p>
<table>
<thead>
<tr>
<th align="left">发送方</th>
<th align="left">假设状态</th>
<th align="left">接收方返回信息</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1-100</td>
<td align="left">received</td>
<td align="left">ACK=101</td>
</tr>
<tr>
<td align="left">101-200</td>
<td align="left">miss</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">201-300</td>
<td align="left">received</td>
<td align="left">ACK=101</td>
</tr>
<tr>
<td align="left">301-400</td>
<td align="left">received</td>
<td align="left">ACK=101</td>
</tr>
<tr>
<td align="left">401-500</td>
<td align="left">received</td>
<td align="left">ACK=101</td>
</tr>
<tr>
<td align="left">101-200</td>
<td align="left">retry</td>
<td align="left">ACK=501</td>
</tr>
<tr>
<td align="left">201-300</td>
<td align="left">maybe retry</td>
<td align="left">ACK=501</td>
</tr>
</tbody></table>
<p>通常情况，包的重发会等待超时时间，并且会在不成时不短翻倍。再开启 SACK 之后，会通过连续收到三个相同的 ACK 来判断数据报丢失来出触发重发。SACK <strong>包含多个已收到的连续字节区间信息</strong>以提示发送方重发数据。这可以提高重发的效率，并且只需要重发丢失区间的信息即可:</p>
<table>
<thead>
<tr>
<th align="left">发送方</th>
<th align="left">假设状态</th>
<th align="left">接收方返回信息</th>
</tr>
</thead>
<tbody><tr>
<td align="left">1-100</td>
<td align="left">received</td>
<td align="left">ACK=101</td>
</tr>
<tr>
<td align="left">101-200</td>
<td align="left">miss</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">201-300</td>
<td align="left">miss</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">301-400</td>
<td align="left">received</td>
<td align="left">ACK=101,SACK=&lt;301,401&gt;</td>
</tr>
<tr>
<td align="left">401-500</td>
<td align="left">received</td>
<td align="left">ACK=101,SACK=&lt;301,501&gt;</td>
</tr>
<tr>
<td align="left">501-600</td>
<td align="left">received</td>
<td align="left">ACK=101,SACK=&lt;301,601&gt;</td>
</tr>
<tr>
<td align="left">101-200</td>
<td align="left">fast retransmission</td>
<td align="left">ACK=201,SACK=&lt;301,601&gt;</td>
</tr>
<tr>
<td align="left">201-300</td>
<td align="left">fast retransmission</td>
<td align="left">ACK=601</td>
</tr>
</tbody></table>
<p>可能由于网络延迟或者 ACK 回复丢失，导致 ACK 号大于 SACK 区间（D-SACK）并不需要针对区间重发。</p>
]]></content>
      <categories>
        <category>Net</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>G1GC 解读</title>
    <url>/2019/06/G1GC-%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<p>之前对 G1 之前的垃圾回收器进行了整理<a href="http://kun3375.com/2019/02/JVM-垃圾回收器小记/" target="_blank" rel="external nofollow noopener noreferrer">《JVM 垃圾回收器小记》</a>，但是留下了 G1 的坑长久未填，现在把相关的概念、配置参数以及 G1 的流程进行了整理。</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h3><p>不同于之前的垃圾回收按照连续的物理内存空间进行划分产生 Yong、Tenured、MetaSpace 区域并使用分代垃圾回收处理。G1 将整个堆空间切分成若干个小型的区域 Region 来存放对象，每个 Region 可以单独作为 <em>Yong<em>、</em>Tenured</em> 或者 <em>Humongous</em>（大对象分配区域），这使得不同代的内存区域在物理上是可以割裂的。</p>
<a id="more"></a>

<pre><code>Humongous 区域特性：
- 一块 Humongous 区域不止占用一个 Region 基本大小，因为那些大于等于 Region 基本大小一半的对象都会被分配到 Humongous 区域。
- Humongous 大对象直接作为 Tenured，在 GCM Cleanup 阶段或者 FullGC 时候被回收。
- 大对象分配前会检查 InitiatingHeapOccupancyPercent 数值和 MarkingThreshold，超过则启动 GCM，避免 FullGC 和分配失败的可能。</code></pre><h3 id="Card-Table"><a href="#Card-Table" class="headerlink" title="Card Table"></a>Card Table</h3><p>卡表，这个概念也适用于 CMS GC 并发垃圾回收。堆区空间会被划分成一个个 512 Byte 的卡，并维护一个卡表，保存一个标识位来标识对应卡区是否可能持有有年轻代的引用。目的是减少在 YongGC 时候对于整个 Tenured 区域的扫描。如果可能存在 Yong 区的引用则称为 <strong>Dirty Card</strong>（<strong>脏卡</strong>）。</p>
<h3 id="Remembered-Set"><a href="#Remembered-Set" class="headerlink" title="Remembered Set"></a>Remembered Set</h3><p>简称 RSet，基于 Card Table 概念实现。对于 Region 而言，Card Table 记录了是否引用 Young 区对象，而 RSet 则是记录了其他 Card 引用本 Region 的信息。RSet 是一个哈希表，键为引用本 Region 的其他 Region 的起始地址，值为引用了对应 Region 中对应 Card 的集合。</p>
<ul>
<li>效益：G1 回收部分 Region，YongGC 时候可以通过 RSet 找到跨代引用的 Tenured Region，MixedGC 时候可以通过全部 YongRegion 和 Tenured RSet 得到，不用全堆扫描。</li>
<li>维护：write barrier：写入屏障，即时编译生成的机器码中对于所有引用的更新都会生成额外的逻辑，来记录 Card Table 和 RSet 的改变。</li>
</ul>
<h3 id="Collection-Set"><a href="#Collection-Set" class="headerlink" title="Collection Set"></a>Collection Set</h3><p>简称 CSet，所有需要被回收的对象。</p>
<h3 id="Pause-Prediction-Model"><a href="#Pause-Prediction-Model" class="headerlink" title="Pause Prediction Model"></a>Pause Prediction Model</h3><p>停顿预测模型。G1 是响应时间优先的算法，和 CMS 不同，它可以设置用于期望停顿时间，通过 MaxGCPauseMillis（这是一个软要求 ）设定。G1 根据历史回收数据和 MaxGCPauseMillis 来判断需要回收的 Region 数量。其以衰减标准偏差为理论基础实现，具体数学内容不展开。</p>
<h3 id="Float-Garbage"><a href="#Float-Garbage" class="headerlink" title="Float Garbage"></a>Float Garbage</h3><p>由于 G1 基于启动时的存活对象的快照（Snapshot At The Begining，SATB）所有在收集过程中产生的对象会被视为存活对象，无法识别垃圾。这部分对象只会在下一次 GC 时候被清理，被称为 Float Garbage。</p>
<h2 id="标记方案"><a href="#标记方案" class="headerlink" title="标记方案"></a>标记方案</h2><p><strong>Global Concurrent Marking</strong>：并发标记本身为 MixedGC 提供对象标记服务，但是它的发生是随着 YoungGC 而开始的，总共几个阶段：</p>
<ul>
<li>初始标记（Initial Mark，STW）。它标记了从 GC Root 开始直接可达的对象（Root Trace），因为需要暂停所有应用线程（STW）代价较大，它会复用 YoungGC 的 Root Trace。</li>
<li>根区域扫描（Root Region Scan）标记了从 GC Roots 开始可达的老年代对象。</li>
<li>并发标记（Concurrent Marking）。这个阶段从 GC Root 开始对堆中的对象标记，标记线程与应用程序线程并行执行，并且收集各个 Region 的存活对象信息，这个步骤可以被新的 YoungGC 打断。</li>
<li>最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。 </li>
<li>清除垃圾（Cleanup）。执行最后的清理工作，清除空 Region（没有存活对象的），并把存活对象进行移动，减少 Region 的碎片化。</li>
</ul>
<h2 id="回收方案"><a href="#回收方案" class="headerlink" title="回收方案"></a>回收方案</h2><ul>
<li><strong>YoungGC</strong><br>也就是 MinorGC，指定所有的年轻代 Region 进行回收。通过控制年轻代 Region 个数（内存大小）来控制 YoungGC 的消耗时间。</li>
<li><strong>MixedGC</strong><br>其实 MixedGC 是作为 YoungGC 的升级，和 YoungGC 的区别在于使用了不同的 CSet，在 MixedGC 过程会包含若干 Tenured Region。在老年代对象占用堆区的内存达到阈值 <code>InitiatingHeapOccupancyPercent</code> 时会触发标记，并在标记结束时切换成 MixedGC。纳入每次 MixedGC 中除了 Yong Region，Tenured Region 数量会由期望停顿时间 <code>MaxGCPauseMillis</code> 估算出来。剩余的 Tenured Region 的部分会在下一次 MixedGC 中被回收。一次标记后 MixedGC 的最大次数由 <code>G1MixedGCCountTarget</code> 控制。</li>
<li><strong>SerialOldGC</strong><br>根据 MixedGC 的执行行为可以了解到，如果垃圾产生的速度超过 MixedGC 速度，JVM 有必要采取额外的措施进行垃圾回收了，会使用一次 SerialGC 进行完全回收（FullGC）。还会触发 FullGC 的 MetaSpace 的使用。（关于 MetaSpace 推荐文章 <a href="http://lovestblog.cn/blog/2016/10/29/metaspace/，精简细致，不再搬运" target="_blank" rel="external nofollow noopener noreferrer">《MetaSpace解读》</a> 了解</li>
</ul>
<h2 id="重要参数"><a href="#重要参数" class="headerlink" title="重要参数"></a>重要参数</h2><ul>
<li>-XX:G1HeapWastePercent：允许浪费的堆空间阈值。在 Global Concurrent Marking 结束之后，我们可以知道老年代 Region 中有多少空间要被回收，在每次 YGC 之后和再次发生 MixedGC 之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生 MixedGC。</li>
<li>-XX:G1MixedGCLiveThresholdPercent：老年代 Region 中的存活对象的占比，只有在此参数之下，才会被选入 CSet，默认 65%。</li>
<li>-XX:G1MixedGCCountTarget：一次 Global Concurrent Marking 之后，最多执行 MixedGC 的次数。</li>
<li>-XX:G1OldCSetRegionThresholdPercent：一次 MixedGC 中能被选入 CSet 的最多老年代 Region 数量，默认堆的 10%。</li>
<li>-XX:G1HeapRegionSize：设置Region大小，并非最终值，默认会自动计算出一个合适值。</li>
<li>-XX:MaxGCPauseMillis：设置G1收集过程目标时间，默认值200ms，软限制。</li>
<li>-XX:G1NewSizePercent：新生代最小值，默认值5%。</li>
<li>-XX:G1MaxNewSizePercent：新生代最大值，默认值60%。</li>
<li>-XX:ParallelGCThreads：STW期间，并行GC线程数。可以不进行指定，默认会使用 CPU 支持的线程数（如果线程数小于等于 8），或者按 8 + 线程数 * 调整值 5/8 或 5/16（线程数大于 8）。</li>
<li>-XX:ConcGCThreads：并发标记阶段，并行执行的线程数，为 ParallelGCThreads/4。</li>
<li>-XX:InitiatingHeapOccupancyPercent：设置触发标记周期的 Java 非年轻代堆占用率阈值。默认值是 45%。</li>
<li>-XX:G1ReservePercent=10：空闲空间预留内存百分比。</li>
</ul>
<p>参考</p>
<ul>
<li><a href="https://liuzhengyang.github.io/2017/06/07/garbage-first-collector/" target="_blank" rel="external nofollow noopener noreferrer">https://liuzhengyang.github.io/2017/06/07/garbage-first-collector/</a></li>
<li><a href="https://tech.meituan.com/2016/09/23/g1.html" target="_blank" rel="external nofollow noopener noreferrer">https://tech.meituan.com/2016/09/23/g1.html</a></li>
<li><a href="https://www.oracle.com/technetwork/cn/articles/java/g1gc-1984535-zhs.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.oracle.com/technetwork/cn/articles/java/g1gc-1984535-zhs.html</a></li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringKafkaListener 增效</title>
    <url>/2019/04/SpringKafkaConsumer-%E5%A2%9E%E6%95%88/</url>
    <content><![CDATA[<p>通过 spring-kafka 的集成，我们可以通过注解 <code>@KafkaListener</code> 以及 <code>spring.kafka.consumer</code> 相关配置轻松的管理 kafka 消费。但是消费速度往往仍然不够理想，需要进一步调整。</p>
<p>在 kafka 的实现中，某个 topic 的 partition 即分区的数量，基本上决定在这个 topic 下的最大并发程度。因为客户端的数量是受限于 partition 数量的。对于一定数量的 partition 而言，客户端数量如果更少，将有部分客户端会被分配上多个分区；如果客户端数量更多，超过 partition 数量的客户端将会无法消费，这是由 kafka 本身的负载均衡策略决定的。<br>尽管我们可以动态地调整 partition，但是对于基于 Key 的消息，并需要有序消费时，由于 kafka 通过 Key 进行 hash 分片，更改 partition 数量将无法保证有序性。</p>
<a id="more"></a>

<p>所以首先可以肯定的是：</p>
<blockquote>
<ul>
<li>对于一个 topic 来说，设置适量多的 partition 是有必要的。分区数量决定了消费消费的并行度。</li>
</ul>
</blockquote>
<p>分区的变更以及过多的分区可以看看：<a href="https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster" target="_blank" rel="external nofollow noopener noreferrer" title="how-choose-number-topics-partitions-kafka-cluster">如何选择分片数量</a></p>
<p>那么在选择了一定数量的 partition 之后，并行度的限制绝大程度上就变成了客户端的消费能力。</p>
<p>如上所说的如果客户端过少将有部分客户端消费多个 partition。在不考虑留一定 partition 来拓展的情况下假定我们需要拥有同样数量的客户端。</p>
<p>事实上 spring-kafka 为我们提供了方便的配置：</p>
<blockquote>
<p><code>spring.kafka.listener.concurrency</code> 对应每个 Listener 对应的 kafka client 数量。<br>tips: <code>@KafkaListener</code> 其中的 <code>topicPartitions</code> 更可以精确控制消费的 partition</p>
</blockquote>
<p>这字面意思为监听器的并发数，该配置会在我们的一个应用实例上建立对应数量的 kafka client。<br>从 spring 所做的实现上来看，每个 kafka consumer client 由一个 <code>ListenerConsumer</code> 包装，并由 <code>MessageListenerContainer</code> 持有。如果设置了并发数 <code>concurrency</code>，那么则会使用装饰器模式使用 <code>ConcurrentMessageListenerContainer</code> 进行包装，组合多个 <code>KafkaMessageListenerContainer</code>。这对于每个持有 <code>@KafkaListener</code> 注解的端点都是如此。</p>
<p><code>Container</code> 启动之后会将 <code>ListenerConsumer</code> （实现了 <code>Runnable</code>）提交至一个异步执行器：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// KafkaMessageListenerContainer</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doStart</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">this</span>.listenerConsumerFuture = containerProperties</span><br><span class="line">				.getConsumerTaskExecutor()</span><br><span class="line">				.submitListenable(<span class="keyword">this</span>.listenerConsumer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中 <code>ConsumerTaskExecutor</code> 一般是一个简单的异步线程处理。继续看 <code>ListenerConsumer.run()</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// KafkaMessageListenerContainer$ListenerConsumer</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">while</span>(isRunning()) &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">        ConsumerRecords&lt;K, V&gt; records = <span class="keyword">this</span>.consumer.poll(<span class="keyword">this</span>.containerProperties.getPollTimeout());</span><br><span class="line">        <span class="comment">// ... 以自动提交模式为例</span></span><br><span class="line">        invokeListener(records);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用 kafka 客户端拉取消息后，使用对应的 MessageListener 适配器进行消息处理 <code>onMessage(ConsumerRecord)</code> </p>
<p>所以，尽管配置了分片数量，并使用 concurrency 配置提高了 kafka 客户端数量，但是对于每一个 kafka client，他们都是<strong>同步</strong>进行消息消费的！如果业务非 CPU 密集型任务，有一定的 IO 操作，需要应用手动进行消息的异步处理。如通过信号量或线程池等手段来增加吞吐量。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MQ</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 垃圾回收器小记</title>
    <url>/2019/02/JVM-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="能力各异的垃圾回收器"><a href="#能力各异的垃圾回收器" class="headerlink" title="能力各异的垃圾回收器"></a>能力各异的垃圾回收器</h3><h4 id="Serial"><a href="#Serial" class="headerlink" title="Serial"></a>Serial</h4><p>Serial 收集器是一个新生代串行垃圾回收器，单线程执行，使用复制算法，整个流程会 STW。在单核环境下可能会不存在线程切换的问题而有略高的效率。也是之前 client 模式下的默认垃圾回收器。</p>
<h4 id="ParNew"><a href="#ParNew" class="headerlink" title="ParNew"></a>ParNew</h4><p>ParNew 收集器是一个新生代并行垃圾回收器，多线程执行，使用复制算法，整个流程会 STW。除了使用多个线程进行垃圾回收之外，其余和 Serial 一致。</p>
<a id="more"></a>
<h4 id="Parallel-Scavenge"><a href="#Parallel-Scavenge" class="headerlink" title="Parallel Scavenge"></a>Parallel Scavenge</h4><p>Parallel Scavenge 收集器是一个新生代并行垃圾回收器，多线程执行，使用复制算法，整个流程会 STW。其设计的初衷是为了提高系统吞吐量（应用程序时间占比）。相对后文中的 CMS 尽管缩短了用户线程的停顿时间但是两次扫描会拉长整个垃圾回收的时间。</p>
<h4 id="Serial-Old"><a href="#Serial-Old" class="headerlink" title="Serial Old"></a>Serial Old</h4><p>Serial Old 是一个老年代串行垃圾回收器，使用单线程的标记整理算法。类似 Serial 的老年代版本，常用于 client 模式。</p>
<h4 id="Parallel-Old"><a href="#Parallel-Old" class="headerlink" title="Parallel Old"></a>Parallel Old</h4><p>Parallel Old 是一个老年代并行垃圾回收器，使用多线程执行标记整理算法。</p>
<h4 id="Concurrent-Mark-Sweep"><a href="#Concurrent-Mark-Sweep" class="headerlink" title="Concurrent Mark Sweep"></a>Concurrent Mark Sweep</h4><p>Concurrent Mark Sweep 垃圾收集器，简称 CMS，一个近乎并发执行的垃圾回收器，其设计的初衷就是尽可能地缩短用户线程的停顿时间。它分为 4 个阶段：</p>
<ol>
<li>初始标记（Initial Mark）标记所有 GC Roots 关联的对象，速度十分快。</li>
<li>并发标记（Concurrent Mark）沿 GC Roots 搜索对象，判断是否存活。</li>
<li>重新标记（Remark）标记并发阶段出现的对象。</li>
<li>并发清除（Concurrent Sweep）对垃圾对象清理。</li>
</ol>
<p>在初始标记和重新标记阶段仍然需要暂停用户线程（STW），但是速度很短，所以一般视 CMS 为一个并发回收器。尽管 CMS 停顿时间少，但是它依然有着显著的缺点：</p>
<ol>
<li>吞吐量降低。并发标记和清理会会和用户线程抢占 CPU 资源，而且这两个阶段持续的时间会相对较长。</li>
<li>无法处理浮动垃圾。由于 CMS 线程和用户线程并行工作，所以期间产生的一些垃圾会无法回收，直到下一次 GC。同时 CMS 模式下需要在老年代预留一定的空间，而不能等到近乎填满之后才启动。如果 Concurrent Mode Failure，那么会触发一次 SerialOld FullGC。</li>
<li>产生内存碎片。这是由于 CMS 使用标记清除算法的原因。最后严重的堆碎片化可能因为无法容纳一个大对象而被迫提前进行一个 FullGC。对此，可以控制 JVM 在一定次数的 CMS GC 之后进行一次碎片整理。</li>
</ol>
<h4 id="Garbage-First"><a href="#Garbage-First" class="headerlink" title="Garbage First"></a>Garbage First</h4><p>Garbage First 简称 G1，是 JDK7 后引入的一个分代收集器，在 JDK9 已是默认选项。<br>感觉有必要关于 G1 新开笔记，待更。</p>
<h3 id="相关参数和注意"><a href="#相关参数和注意" class="headerlink" title="相关参数和注意"></a>相关参数和注意</h3><table>
<thead>
<tr>
<th align="center">参数</th>
<th align="center">效果</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>通用参数</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>-XX:+PrintCommandLineFlags</code></td>
<td align="center">打印当前 JVM 定制的参数，可查看使用的垃圾回收器</td>
</tr>
<tr>
<td align="center"><code>-XX:+PrintGC</code> <code>-XX:+PrintGCDetails</code></td>
<td align="center">打印 GC 日志，精简 or 详细</td>
</tr>
<tr>
<td align="center"><code>-XX:+PrintGCApplicationStoppedTime</code></td>
<td align="center">打印 GC 时暂停的时间</td>
</tr>
<tr>
<td align="center"><code>-XX:+PrintGCApplicationConcurrentTime</code></td>
<td align="center">打印 GC 间应用运行的时间</td>
</tr>
<tr>
<td align="center"><code>-XX:+PrintGCTimeStamps</code></td>
<td align="center">打印 GC 阶段触发的时间戳</td>
</tr>
<tr>
<td align="center"><code>-XX:+PrintHeapAtGC</code></td>
<td align="center">在 GC 时打印堆详情</td>
</tr>
<tr>
<td align="center"><code>-XX:+DisableExplicitGC</code></td>
<td align="center">禁用程序中显式的提示 FullGC 触发：System.gc()，有 OOM 风险，许多框架使用永久区内存，只能通过 FullGC 调用 sun.misc.Cleaner 进行回收</td>
</tr>
<tr>
<td align="center"><strong>回收器选择</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>-XX:+UseSerialGC</code></td>
<td align="center">使用串行垃圾回收器，Serial+SerialOld(MSC)</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseParallelGC</code></td>
<td align="center">Young 使用并行回收器(Parallel Scavenge)，Old 默认串行回收，可以搭配 ParOld 而无法搭配 CMS</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseParNewGC</code></td>
<td align="center">Young 使用并行回收器(Parrallel New), 可以搭配 CMS 使用</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseParallelOldGC</code></td>
<td align="center">Old 使用并行回收器（Parallel Old），一般搭配 ParScvg 提高系统吞吐量</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseConcMarkSweepGC</code></td>
<td align="center">Old 使用并行回收器（CMS），默认 Young 使用 ParNew，备用 SerialOld 进行 FullGC</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseG1GC</code></td>
<td align="center">使用 G1 回收器</td>
</tr>
<tr>
<td align="center"><strong>ParallelYoungGC 配置</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>-XX:ParallelGCThreads</code></td>
<td align="center">配置 Young 区的并行收集线程数，默认 <code>(ncpus &lt;= 8) ? ncpus : 3 + ((ncpus * 5) / 8)</code></td>
</tr>
<tr>
<td align="center"><strong>Parallel Scavenge 涉及配置</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>-XX:GCTimeLimit</code></td>
<td align="center">设置 GC 时间上限，默认 98，超出后抛出 OOM</td>
</tr>
<tr>
<td align="center"><code>-XX:GCHeapFreeLimit</code></td>
<td align="center">设置非 GC 中的时间阈值，默认 2，低于该值会抛出 OOM</td>
</tr>
<tr>
<td align="center"><code>-XX:MaxGCPauseMillis</code></td>
<td align="center">设置年轻代回收停顿的最大毫秒数，如果在 GC 时超过该阈值，JVM 会尝试调整堆空间的配比，处理优先级高</td>
</tr>
<tr>
<td align="center"><code>-XX:GCTimeRatio</code></td>
<td align="center">配置 GC 时间的比重 1/(1 + N)，如果过长 JVM 会调整堆空间的配比，处理优先级低于 MaxGCPauseMillis，但是高于其他空间配置</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseAdaptiveSizePolicy</code></td>
<td align="center">开启堆空间自适应调整，推荐在 Parallel Scavenge 下启用，如果需要手动调整堆空间配比，请使用 <code>-</code> 停用</td>
</tr>
<tr>
<td align="center"><strong>CMS 相关配置</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>-XX:+CMSParallelInitialMarkEnabled</code></td>
<td align="center">使 CMS 的初始化标记阶段并行进行，1.8 已并行处理，该选项针对 1.5~1.7</td>
</tr>
<tr>
<td align="center"><code>-XX:ParallelCMSThreads</code></td>
<td align="center">设置 CMS 回收线程数量，默认为 (Young 并行回收线程 ParallelGCThreads + 3)/4</td>
</tr>
<tr>
<td align="center"><code>-XX:CMSWaitDuration</code></td>
<td align="center">设置 CMS 扫描线程的间隔时间，默认 2000 ms</td>
</tr>
<tr>
<td align="center"><code>-XX:CMSInitiatingOccupancyFraction</code></td>
<td align="center">设置 CMS <strong>首次</strong>触发回收的堆占用百分比，1.7 之后默认 92，后续的回收触发比例由 JVM 自行控制</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseCMSInitiatingOccupancyOnly</code></td>
<td align="center">设置每次 CMS 触发的堆占用比例都沿用 CMSInitiatingOccupancyFraction 设定值</td>
</tr>
<tr>
<td align="center"><code>-XX:+CMSScavengeBeforeRemark</code></td>
<td align="center">设置 CMS 启动前进行一次 YoungGC，以减轻重新标记阶段时候的工作量，减少暂停时间，需要斟酌</td>
</tr>
<tr>
<td align="center"><code>-XX:+UseCMSCompactAtFullCollection</code></td>
<td align="center">允许在内存不够时进行碎片整理，碎片整理时无法并发，仅 CMS 启用时有效，默认开启</td>
</tr>
<tr>
<td align="center"><code>-XX:+CMSFullGCsBeforeCompaction</code></td>
<td align="center">多少次 FullGC 之后进行碎片压缩，默认 0，每次进行压缩</td>
</tr>
<tr>
<td align="center"><code>-XX:+CMSClassUnloadingEnabled</code></td>
<td align="center">针对 1.6~1.7，允许 CMS 清理永久区，对不再使用的类进行清理，需要斟酌，代替更早之前的 CMSPermGenSweepingEnabled</td>
</tr>
<tr>
<td align="center"><code>-XX:+CMSInitatingPermOccupancyFraction</code></td>
<td align="center">针对 1.7 及之前，针对永久区控制触发 CMS 的阈值，效果同 CMSInitiatingOccupancyFraction</td>
</tr>
<tr>
<td align="center"><code>-XX:+ExplicitGCInvokesConcurrent</code> <code>-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses</code></td>
<td align="center">使用 CMS 来执行 FullGC，DisableExplicitGC 的 OOM 风险可以使使用该命令来避免</td>
</tr>
<tr>
<td align="center"><strong>G1 相关配置</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>-XX:+UseStringDeduplication</code></td>
<td align="center">优化字符串空间，去除冗余字符串</td>
</tr>
<tr>
<td align="center"><code>-XX:StringDeduplicationAgeThreshold</code></td>
<td align="center">字符串去重会针对年龄大的字符串对象，而该值则控制这个年龄阈值，默认 3</td>
</tr>
<tr>
<td align="center"><code>-XX:+PrintStringDeduplicationStatistics</code></td>
<td align="center">打印 StringDeduplication 的触发情况</td>
</tr>
<tr>
<td align="center"><strong>关于 GC 日志记录</strong></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><code>-Xloggc:&lt;FilePath&gt;</code></td>
<td align="center">记录 GC 日志，设定日志目录。如果需要虚拟机全部日志信息需要使用 <code>XX:+LogVMOutput</code> 以及 <code>-XX:LogFile=&lt;FilePath&gt;</code></td>
</tr>
<tr>
<td align="center"><code>-XX:+UseGCLogFileRotation</code></td>
<td align="center">开启 GC 日志的滚动</td>
</tr>
<tr>
<td align="center"><code>-XX:NumberOfGCLogFiles=&lt;N&gt;</code></td>
<td align="center">设置 GC 滚动日志的文件个数，N &gt;= 1</td>
</tr>
<tr>
<td align="center"><code>-XX:GCLogFileSize=N</code></td>
<td align="center">设置 GC 每个滚动日志的文件大小，N &gt;= 8KB</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 主从复制</title>
    <url>/2019/01/MySQL-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<p>最近工作也比较忙，很久没有写新的日记了。开始重新整理一下知识点，先找一个有意思点开始吧。</p>
<h3 id="复制原理"><a href="#复制原理" class="headerlink" title="复制原理"></a>复制原理</h3><p>这个原理其实十分简单，只要搜索一下，那些搜索引擎就会给出图示和合理的答案：</p>
<ol>
<li>主库开启二进制日志（或者叫主机日志）bin-log。这会使得数据库在更新时记录下它的操作动作。</li>
<li>从机开启 slave 模式，使用一个 IO 线程去请求 master 的数据，记录在中继日志 relay-log 中；master 方面有一个 dump 线程配合传输这份数据。</li>
<li>从机的另一个 SQL 线程读取中继日志内容并解析后执行相应的操作。</li>
</ol>
<h3 id="复制方案"><a href="#复制方案" class="headerlink" title="复制方案"></a>复制方案</h3><p>通常的，我们做主从复制，不仅仅为了数据备份。同时会在从机上设置只读，对 MySQL 集群做读写分离，提高数据库的响(wu)应(jin)速(qi)度(yong)，所以一般都采用了<strong>异步复制</strong>方案。主机采用完全独立的 dump 线程来传输 bin-log，备份完全异步化。</p>
<a id="more"></a>
<p>另一个方案是<strong>半同步复制</strong>。通过选择性开启半同步复制插件开启。主机在每次 bin-log 刷盘时通知 dump 线程传输数据并挂起，在完成给从机的传输后唤醒原线程返回客户端结果。这可以保证至少一个从机能获得完整的 bin-log 所对应 relay-log 信息，但是不能保证从机 SQL 执行完毕；同时，从机的卡顿、阻塞会影响主机的稳定。应用面不广。</p>
<h3 id="主机参数"><a href="#主机参数" class="headerlink" title="主机参数"></a>主机参数</h3><p>首先需要修改主机的 MySQL 配置文件 <code>my.cnf</code> 或者（更推荐）更改自定义配置文件（需要在主配置文件中指定目录），一般在 <code>/etc/mysql/conf.d/</code> 下。选几个主要参数说明一下：</p>
<ul>
<li><code>seriver-id=1</code><br>服务端编号，值选个大于零的数就好，一般会用个 ip 啥的，没什么好说的，用来区别不同 MySQL 实例。</li>
<li><code>log-bin=/var/lib/mysql/binlog</code><br>用来指定 bin-log 生成的路径和名称前缀，其实以上就是默认值和数据文件在一起，最后生成的 bin-log 是 <em>/var/lib/mysql/binlog.xxxxxx</em>。</li>
<li><code>binlog-format=mixed</code><br>指定二进制信息的形式，有三种选项：<ul>
<li><strong>row</strong> 拷贝命令结果，这种方式会记录原始和改动后的记录行，比较占用空间，但是可以方便地回溯同时避免很多数据上的问题（待展开），一般会使用该格式</li>
<li><strong>statement</strong> 拷贝命令，随机函数等命令无法精准复制</li>
<li><strong>mixed</strong> 默认拷贝命令，不佳时拷贝结果  </li>
</ul>
</li>
<li><code>binlog-ignore-db=mysql</code><br>指定需要忽略的库，不记录 bin-log。多个写多次。  </li>
<li><code>binlog-do-db=db_business</code><br>指定需要同步的库，以上二选一即可。多个写多次。  </li>
<li><code>expire_logs_days=15</code><br>可选，设置 bin-log 过期天数，到期自动删除。该值默认为 0，永不删除。可以使用 purge 命令手动删除 bin-log。也行。  </li>
<li><code>slave_skip_errors=1062</code><br>可选，设置忽略同步过程中的错误，比如 1062 是主键重复，1032 是数据不存在。  </li>
<li><code>log_bin_trust_function_creators=true</code><br>为真时，对函数和存储过程一样进行同步。</li>
</ul>
<p>再讲两个额外的选项，本身和主从复制过程无关，但是会对集群和主从间的数据一致性造成影响：</p>
<ul>
<li><code>innodb_flush_log_at_trx_commit=1</code><br>默认值：1。为了减少 IO 创造高效，在 innoDB 每次提交事务的时候，可以不立刻刷盘。设置 0 时：log-buf 每隔一秒同步 bin-log 并刷盘；设置 1 时：事务每次提交都会同步刷盘；2：每次同步 log 文件缓冲，但是每隔一秒刷盘。</li>
<li><code>sync_binlog=1</code><br>默认值：1。设置多少次提交后进行刷盘，一般配合以上选项使用。这两个选项会对性能造成明显的影响。但是一般对数据一致性不敏感且追求速度的场合会进行调整。</li>
</ul>
<h3 id="从机参数"><a href="#从机参数" class="headerlink" title="从机参数"></a>从机参数</h3><p>从机同样修改配置文件。如果使用主机镜像或者拷贝的 docker volume 需要修改 <em>/var/lib/mysql/auto.cnf</em> 中的 UUID。</p>
<ul>
<li><code>server-id=2</code><br>类似主机配置。  </li>
<li><code>binlog-do-db=db_business</code><br>选择要复制的数据库。多个写多次。</li>
<li><code>binlog-ignore-db=mysql</code><br>拒绝不复制的数据库。</li>
<li><code>relay_log=/var/lib/mysql/2-relay-bin</code><br>可选，指定中继日志位置。启动 slave 模式必然会产生中继日志，默认在 <em>/数据目录/${host}-relay-bin.xxxxxx</em>  </li>
<li><code>read-only=1</code><br>从机只读，不要修改数据。</li>
</ul>
<p>如果从机还作为主机的话：</p>
<ul>
<li><code>log-bin=secondary-binlog</code><br>也需要开启 bin-log，其他主机参数也要配置哦。  </li>
<li><code>log_slave_updates=1</code><br>从机记录复制事件进二进制日志中。</li>
</ul>
<h3 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h3><h4 id="搭建全新主从数据库环境"><a href="#搭建全新主从数据库环境" class="headerlink" title="搭建全新主从数据库环境"></a>搭建全新主从数据库环境</h4><p>先来说说搭建一个全新的主从架构。一种是是基于 bin-log position 的复制方案，另一种方案是使用 GTID 策略。先说说第一种方案：</p>
<p>主机创建数据同步用户并授权，尽量指定 ip，少给与权限尤其是 <strong>super</strong> 权限，super 权限用户可以无视 read-only…</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant replication slave, replication client on *.* to &#39;user_slave&#39;@&#39;%&#39; identified by &#39;Kun3375&#39;;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<p>记录下主机 bin-log 位置信息 <code>File</code> / <code>Position</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show master status;</span><br></pre></td></tr></table></figure>

<p>启动从机并设置主机信息，并启动 slave 状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">change master to </span><br><span class="line">master_host&#x3D;&#39;mysql-master&#39;, </span><br><span class="line">master_port&#x3D;3306, master_user&#x3D;&#39;user_slave&#39;, master_password&#x3D;&#39;Kun3375&#39;, master_log_file&#x3D;&#39;binlog.000014&#39;, master_log_pos&#x3D;497;</span><br><span class="line">start slave;</span><br></pre></td></tr></table></figure>

<p>检查 slave 状态信息。当 <code>Slave_IO_Running</code> 与 <code>Slave_SQL_Running</code> 同时为 <code>Yes</code> 意味着 IO/SQL 两线程正常工作，从机状态正常。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show slave status;</span><br></pre></td></tr></table></figure>

<p>出现问题的同学可以检查一下各个配置，再次启动如果存在错误，尝试清除一下脏数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stop slave;</span><br><span class="line">reset slave;</span><br></pre></td></tr></table></figure>

<h4 id="使用-GTID-来搭建主从关系"><a href="#使用-GTID-来搭建主从关系" class="headerlink" title="使用 GTID 来搭建主从关系"></a>使用 GTID 来搭建主从关系</h4><h5 id="关于-GTID"><a href="#关于-GTID" class="headerlink" title="关于 GTID"></a>关于 GTID</h5><p>之所以引入 GTID 是因为在使用 bin-log position 方案进行主备复制时如果遇到错误需要通过重新定位 bin-log 位置，使用 <em>sql_slave_skip_counter</em> 或者 <em>slave_skip_errors</em> 来跳过错误语句，比较麻烦。<br>来看看 GTID 是什么：GTID：Global Transaction Identifier，它在事务提交时候生成并且唯一，格式为 <code>server_uuid:txn_no</code>，其中 <em>sever_uuid</em> 是实例启动时候生成的，<em>txn_no</em> 是每次事务提交时候自增的整数。<br>GTID 生成策略有两种，不同的策略会影响事务的执行成功与否，这可以被 session 变量 <strong>gtid_next</strong> 所控制，有两个选项：</p>
<ul>
<li><code>gtid_next=automatic</code> 默认的自动增长方式，记录 bin-log 时候会自动记录 GTID 信息，并把该值记录在实例的 GTID 集合之中。</li>
<li><code>gtid_next=&lt;gtid&gt;</code> 显式指定一个固定值，如果该值不存在 GTID 集合之中，那么下一次提交的事务会使用该值；如果已存在，下一个事务将被忽略。</li>
</ul>
<h5 id="GTID-模式指定主机"><a href="#GTID-模式指定主机" class="headerlink" title="GTID 模式指定主机"></a>GTID 模式指定主机</h5><p>如果打算使用 GTID 进行主从备份可以参考下面语句，不需要再指定 log 和 position 了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">change master to master_host&#x3D;&#39;mysql-master&#39;, master_port&#x3D;3306, master_user&#x3D;&#39;user_slave&#39;, master_password&#x3D;&#39;Kun3375&#39;, master_auto_position&#x3D;1</span><br></pre></td></tr></table></figure>

<p>和使用 position 方式从指定位置开始读取 bin-log 不同，在从机指定了主机之后，会发送本机的 GTID 集合给主机，主机比对出本机和从机的 GTID 差集，如果差集中的 GTID 事务日志已经不存在了会产生错误；如果正常，主机会寻找第一个从机没有的 GTID 位置进行读取</p>
<h4 id="为既有服务器增加从机"><a href="#为既有服务器增加从机" class="headerlink" title="为既有服务器增加从机"></a>为既有服务器增加从机</h4><p>首先进行主库的备份操作，使用 <code>mysqldump</code> 命令（确保操作用户拥有权限）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqldump -uUSERNAME -pPASSWORD --routines --single-transaction --master-data=2 --all-databases &gt; DUAMPFILE.sql</span><br></pre></td></tr></table></figure>
<p>选项说明：</p>
<ul>
<li>–routines 同时导出存储过程和函数</li>
<li>master-data 默认值为 1。在备份文件追加 <em>change master</em> 主机指定命令。设置 2，可以将该语句追加并注释。该选项会自动打开 <em>lock-all-tables</em> 进行锁表，除非使用 <em>single-transaction</em> 见下文。</li>
<li>–single-transaction 开启单一事务备份。不在备份执行时进行锁表，而仅仅在开始时获取 master status 时候锁表（它依然隐含了以下几个短暂的动作）：<ol>
<li>FLUSH TABLES WITH READ LOCK</li>
<li>SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ</li>
<li>START TRANSACTION WITH CONSISTENT SNAPSHOT</li>
<li>SHOW VARIABLES LIKE ‘gtid_mode’</li>
<li>SHOW MASTER STATUS</li>
<li>UNLOCK TABLES</li>
</ol>
</li>
<li>–skip-lock-tables 尽管 <em>single-transaction</em> 这可以在不长时间锁表的情况下进行备份，并保证在相应 bin-log 位置下数据的准确。如果数据库在任何时候的访问都十分频繁，可能会无法执行 TABLE LOCK，如果可以接受可能有小部分数据不准确的风险，那么可以使用该参数来跳过获取 master status（即 bin-log 位置）前的锁表动作。</li>
<li><ul>
<li>–all-databases 可以备份全库</li>
</ul>
</li>
<li><ul>
<li>–databases 用来指定需要备份的数据库，顺便整理一下导出语句的灵活用法<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 导出多个库，主从备份时只能用这个或者 all-databases</span><br><span class="line">mysqldump --databases DB_NAME_1 DB_NAME_2 &gt; DUMPFILE.sql</span><br><span class="line"># 导出一个库的多个表，不包含建库语句和 use 命令</span><br><span class="line">mysqldump DB_NAME TAB_NAME_1 TAB_NAME_2 &gt; DUMPFILE.sql</span><br><span class="line"># 导出结构不含数据</span><br><span class="line">mysqldump DB_NAME TAB_NAME_1 TAB_NAME_2 &gt; DUMPFILE.sql</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<p>将备份文件拷贝至从机，从机执行 <code>source DUMPFILE.sql</code>。如果之前 <em>master-data</em> 设置为 2 需要手动放开注释或者数据导入之后手动执行 <em>change master</em> 命令。最后 <code>start slave</code> 就好啦，记得使用 <code>show slave status</code> 确认从机状态。</p>
<h4 id="为现有主从体系新增从机"><a href="#为现有主从体系新增从机" class="headerlink" title="为现有主从体系新增从机"></a>为现有主从体系新增从机</h4><p>新增从机的我们可以在完全不对主库进行操作以减少风险。可以在从机上使用 <code>mysqldump</code> 并将 <em>master-data</em> 替换为 <em>dump-slave</em>，从从机导出数据并记录主机的 bin-log 位置。选项数值意义一致。需要注意从机在 dump 时候会暂停复制的 IO 线程。需要确保是否可以接受这样的同步延迟，考虑暂停某从机的使用。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>ES 数据类型、元字段与映射</title>
    <url>/2018/11/ES-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%85%83%E5%AD%97%E6%AE%B5%E4%B8%8E%E6%98%A0%E5%B0%84/</url>
    <content><![CDATA[<p>在 ES 中所有的字段都是由映射规则所控制，这将输入的数据信息转化成对应的数据格式来进行索引或保存。配置合理的映射规则有助于维护文档，增加操作效率。在了解映射相关配置之前需要了解一下 ES 的数据类型和元字段的意义。</p>
<h3 id="字段类型"><a href="#字段类型" class="headerlink" title="字段类型"></a>字段类型</h3><ul>
<li><strong><em>text</em></strong><br>文本类型，十分常用的类型，通常作用于需要被全文检索的字段上。这样的字段内容会被分词器拆成词项后生成倒排索引，它不用于排序，也很少用于聚合。</li>
<li><strong><em>keyword</em></strong><br>关键字类型，通常用于索引结构化的字段（通常意义明确，用于过滤），这样的字段只能被精确搜索。<a id="more"></a></li>
<li><strong><em>number</em></strong><br>数字类型，这是一个概括。其中包含了 <code>byte</code>，<code>short</code>，<code>integer</code>，<code>long</code>，<code>float</code>，<code>double</code>，<code>half_float</code>，<code>scaled_float</code>。除了和 Java 类似的数字类型以外，还有相对于 <code>float</code> 精度折半的 <code>half_float</code>，以及将浮点数进行缩放后存储的 <code>scaled_float</code>。<strong>字段长度越短，空间分配越合理，搜索效率越高</strong>。注意在浮点数中 <code>+0.0</code> 与 <code>-0.0</code> 是<strong>不同</strong>的存在。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 设置某字段为 scaling_float，缩放因子 100</span><br><span class="line"># 适合存储精确至小数点后两位的数字，底层对数字扩大 100 做整形存储</span><br><span class="line"># 而对 API 为 float 型</span><br><span class="line">PUT &#x2F;&lt;索引&gt;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;&lt;类型&gt;&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;&lt;字段名称A&gt;&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;scaled_float&quot;,</span><br><span class="line">          &quot;scaling_factor&quot;: 100</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><strong><em>date</em></strong><br>日期类型，ES 支持日期格式化后的字符串、从 epoch 开始的毫秒数（长整型）、从 epoch 开始的秒数（整形），在 ES 内部，<strong>日期都会转化为 UTC 时间并存储为从 epoch 开始的毫秒数</strong>。在开启动态映射的时候如果有新的字段被添加，默认会自动进行日期检测以判断是否该字段为日期类型（可以被关闭，将某类型的 <code>date_detection</code> 选项设置为 <em>false<em>）。同时日期格式也支持自定义（通过制定字段的 <code>format</code> 选项，默认为 *strict_date_optional_time || epoch_millis</em>），除了 *yyyy-MM-dd HH:mm:ss</em> 这样的个性格式，其他预置的格式枚举很多，详情查看官方文档。</li>
<li><strong><em>boolean</em></strong><br>布尔类型，只接受 <code>true</code> 和 <code>false</code>。</li>
<li><strong><em>binary</em></strong><br>二进制类型，该类型字段仅接受 <strong>Base64</strong> 编码后的字符串，字段默认不存储（store=false）也不搜索。</li>
<li><strong><em>array</em></strong><br>数组类型，其本身是其他类型。数组中的所有值<strong>必须为统一类型</strong>（可以包含 null），而空数组由于无法确定类型会被作为 missing field 对待。在动态映射时，第一个加入数组的元素会决定整个数组的数据类型。</li>
<li><strong><em>object</em></strong><br>对象类型。在 JSON 中，对象是可以包含层级关系的，但是在 ES 中复合的对象会被<strong>扁平化处理</strong>，成为简单的 k-v 键值对。如果需要在建立索引时进行静态映射，mappings 支持 object 的显示映射。</li>
<li><strong><em>nested</em></strong><br>嵌套对象，这是 object 类型的特例，支持 object 对象数据的独立索引和查询（ES 在使用对象类型的数组时由于扁平化处理会导致一些索引问题）。当指定了 nested 类型进行索引某个字段时，该字段会内容会作为<strong>独立的隐藏文档</strong>存在。这样支持了嵌套对象的索引，但是由于类似结构化数据的关联查询一般，<strong>nested 字段越多，搜索越复杂</strong>，所以每个索引可以使用嵌套对象被限制在 50。</li>
<li><strong><em>geo_point</em></strong><br>地理坐标，用来精确存储地理经纬信息的类型，支持 4 中写入方式：<ul>
<li>经纬坐标字符串，如：<code>&quot;40.3,116.17&quot;</code></li>
<li>经纬坐标键值对，如：<code>{&quot;lat&quot;: 40.3, &quot;lon&quot;: 116.17}</code></li>
<li>地理位置哈希值，如：<code>&quot;drm3btev3e86&quot;</code></li>
<li>经纬坐标数组，如：<code>[40.3, 116.17]</code></li>
</ul>
</li>
<li><strong><em>geo_shape</em></strong><br>地理区块，使用 GeoJSON 对区块进行编码，描述一块地理区域，支持点线面等多种特征。一下列举集中典型表达，更多使用方案参数 GeoJSON 相关文档：  </li>
</ul>
<table>
<thead>
<tr>
<th align="center">GeoJSON 类型</th>
<th align="center">ES 类型</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Point</td>
<td align="center">point</td>
<td align="center">精确坐标点</td>
</tr>
<tr>
<td align="center">LineString</td>
<td align="center">linestring</td>
<td align="center">线条，多个点组成</td>
</tr>
<tr>
<td align="center">Polygon</td>
<td align="center">polygon</td>
<td align="center">封闭多边形，多个点组成</td>
</tr>
<tr>
<td align="center">MultiPoint</td>
<td align="center">multipoint</td>
<td align="center">多个不连续但可能关联的点</td>
</tr>
<tr>
<td align="center">MultiLineString</td>
<td align="center">multilinestring</td>
<td align="center">多条不关联的线</td>
</tr>
<tr>
<td align="center">MultiPolygon</td>
<td align="center">MultiPolygon</td>
<td align="center">多个不关联的多边形</td>
</tr>
<tr>
<td align="center">GeometryCollection</td>
<td align="center">geometrycollection</td>
<td align="center">集合对象集合，可以包括点线面</td>
</tr>
<tr>
<td align="center">N/A</td>
<td align="center">envelope</td>
<td align="center">由左上右下坐标确定的封闭矩形</td>
</tr>
<tr>
<td align="center">N/A</td>
<td align="center">circle</td>
<td align="center">圆心和半径确定的圆，单位米</td>
</tr>
</tbody></table>
<p>在使用 geo_shape 类型之后，插入文档时指定字段必须明确 Geo 类型和数据，如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;&lt;索引&gt;&#x2F;&lt;类型&gt;&#x2F;&lt;编号&gt;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;&lt;geo_shape字段&gt;&quot;：&#123;</span><br><span class="line">    &quot;type&quot;: &quot;linestring&quot;,</span><br><span class="line">    &quot;coordinates&quot;: [[40.3, 116.17], [31.3, 116.17]]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong><em>ip</em></strong><br>ip 类型，可以保存 ip 地址，支持 IPv4 及 IPv6，以及无类型域间选路格式</li>
<li><strong><em>range</em></strong><br>范围类型，支持 <code>integer_range</code>，<code>long_range</code>，<code>float_range</code>，<code>double_range</code>，<code>date_rage</code>。其中日期区间以毫秒计时。在某字段使用 rage 类型之后，插入数据需要<strong>指定对应的范围</strong>，可以使用 <code>gt</code>、<code>lte</code> 等关键字描述。</li>
<li><strong><em>token_count</em></strong><br>词项统计类型，其本身是一个整形。一般用来给某个属性增加附加字段并指定 token_count 来统计词项长度。词项长度取决于具体内容和指定的分词器。</li>
</ul>
<h3 id="元字段"><a href="#元字段" class="headerlink" title="元字段"></a>元字段</h3><p>元字段描述了文件本身的属性，是 ES 内置的。总的来看元字段描述了从文档属性、源文档、索引、路由等相关信息，同时也支持自定义元字段。这些元字段支持部分的查询方式和脚本。  </p>
<table>
<thead>
<tr>
<th align="center">元字段</th>
<th align="center">元字段分类</th>
<th align="center">意义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">_index</td>
<td align="center">文档属性</td>
<td align="center">描述文档所属的索引</td>
</tr>
<tr>
<td align="center">_type</td>
<td align="center">文档属性</td>
<td align="center">描述文档的类型</td>
</tr>
<tr>
<td align="center">_id</td>
<td align="center">文档属性</td>
<td align="center">描述文档的编号</td>
</tr>
<tr>
<td align="center">_uid</td>
<td align="center">文档属性</td>
<td align="center">包含_type及_id</td>
</tr>
<tr>
<td align="center">_source</td>
<td align="center">源文档属性</td>
<td align="center">文档原始的JSON资料</td>
</tr>
<tr>
<td align="center">_size</td>
<td align="center">源文档属性</td>
<td align="center">描述源文档的大小，需要插件 mapper-size</td>
</tr>
<tr>
<td align="center">_all</td>
<td align="center">索引属性</td>
<td align="center">包含索引中全部的字段的内容，用来泛检索</td>
</tr>
<tr>
<td align="center">_field_names</td>
<td align="center">索引属性</td>
<td align="center">包含所有不存在空值的字段名</td>
</tr>
<tr>
<td align="center">_parent</td>
<td align="center">路由属性</td>
<td align="center">指定文档间的父子关系</td>
</tr>
<tr>
<td align="center">_routing</td>
<td align="center">路由属性</td>
<td align="center">用来设定文档进行路由的自定义值</td>
</tr>
<tr>
<td align="center">_meta</td>
<td align="center">自定义</td>
<td align="center">自定义的元数据</td>
</tr>
</tbody></table>
<h3 id="映射参数"><a href="#映射参数" class="headerlink" title="映射参数"></a>映射参数</h3><p>在设置索引的映射时候，有一些针对索引、类型或者具体文档属性的参数可以选择性调整。语法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;index_name</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;type_name&quot;: &#123;</span><br><span class="line">      &quot;&lt;类型配置如 dynamic 等&gt;&quot;: &lt;配置内容&gt;,</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;property_name_one&quot;: &#123;</span><br><span class="line">          &quot;&lt;属性配置如 boot 等&gt;&quot;: &lt;配置内容&gt;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上的命令也可以简化使用 _mapping API：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;index_name&#x2F;_mapping&#x2F;type_name</span><br><span class="line">&#123;</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;property_name_one&quot;: &#123;</span><br><span class="line">      &quot;&lt;属性配置如 boot 等&gt;&quot;: &lt;配置内容&gt;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来是一些可配置项：</p>
<ul>
<li><strong><em>analyzer</em></strong><br>分词器选项，针对文档属性，调整对应字段的默认分词器，会影响文档的索引以及查询（未指定 search_analyzer 时）。</li>
<li><strong><em>search_ananlyzer</em></strong><br>查询分词器选项，针对文档属性，仅查询生效，可以覆盖 analyzer 选项。</li>
<li><strong><em>normalizer</em></strong><br>标准化配置，针对文档属性，用于属性值在解析前的预处理。对某属性使用的标准化配置需要在设置时配置好。</li>
<li><strong><em>boost</em></strong><br>权重，针对文档属性，默认值为 <code>1</code>，可以手动通过该选择项改变关键字在某属性中出现时的权重。但是在映射配置中设定 boost 后如果不重新索引文档是无法改变权重的，所以<strong>更推荐在搜索时指定权重</strong>，更为灵活且效果一样。</li>
<li><strong><em>coerce</em></strong><br>强制转型，针对文档属性，默认值 <code>true</code>，用于将类型不正确的输入数据自动转化为文档中对应的类型。</li>
<li><strong><em>copy_to</em></strong><br>字段拷贝，用于自定义 _all 字段，可以将多个字段内容拷贝进指定的字段。</li>
<li><strong><em>doc_value</em></strong><br>建立倒排索引时的额外的列式存储映射开关，针对文档属性，默认值 <code>true</code>，牺牲空间换取排序、聚合操作的速度。如果明确一些字段不需要排序或者聚合操作可以关闭。</li>
<li><strong><em>dynamic</em></strong><br>新字段自动映射开关，针对类型。在插入文档时如果文档中含有没有指定配置过的属性，插入的结果会取决于该选项的设置。它有三个可选项，默认为 <code>true</code>：<ul>
<li><em>true</em> 对新增的字段采取自动映射</li>
<li><em>false</em> 忽略未映射的新字段</li>
<li><em>strict</em> 严格模式，如果发现新字段会抛出异常</li>
</ul>
</li>
<li><strong><em>enable</em></strong><br>ES 默认索引所有字段，但是某些字段没有查询、聚合等需求，可以直接使用 <code>&quot;enable&quot;: false</code> 来直接关闭。关闭的字段不会被索引和搜索，需要获取值时可以从 _source 中得到。</li>
<li><strong><em>fielddata</em></strong><br>这是一个特殊的选项。上文可知大部分类型字段默认都会生成 doc_value 以加快排序和聚合，但是 text 类型除外，取而代之的是在 text 首次被排序、聚合或者使用脚本时生成 fielddata 数据。fielddata 是在堆内存中的记录文档和词项关系的数据，所以它非常消耗内存，默认是不开启的。因为大部分情况下对一个 text 字段做排序聚合似乎都是无意义的。</li>
<li><strong><em>format</em></strong><br>针对日期字段设定格式</li>
<li><strong><em>ignore_above</em></strong><br>针对 keyword 类型的属性，如果目标字段的内容长度超过设定值，将不会被索引（查询不到哦）</li>
<li><strong><em>ignore_malformed</em></strong><br>针对文档属性，支持不兼容数据类型的开关，打开时，如果某个字段存在不兼容数据类型，异常会被忽略，仅该属性被忽略，其他字段仍然索引，可以避免存在不规则数据时整个文档索引出错。</li>
<li><strong><em>include_in_all</em></strong><br>针对文档属性，每个字段的该选择项默认为 <code>true</code>，即所有字段内容都会加入 _all，如果需要 _all 中不包含某字段可以设置为 <code>false</code>。</li>
<li><strong><em>index</em></strong><br>设定某个字段是否被索引，如果关闭了当然就不能被搜索了</li>
<li><strong><em>index_options</em></strong><br>针对文档属性，控制某属性被索引时保存进倒排索引表中的信息，具体取值有下：<ul>
<li><code>docs</code> 默认，只保存文档编号</li>
<li><code>freqs</code> 保存文档编号和词项频率</li>
<li><code>positions</code> 保存文档编号、词项频率和词项偏移位置（用于临近搜索和短语查询）</li>
<li><code>offset</code> 保存文档编号、词项频率、词项位置、词项开始和结束字符位置。</li>
</ul>
</li>
<li><strong><em>fields</em></strong><br>针对文档属性，可以为某个属性增加附加的属性，以使用额外的索引方式或者 token_count。</li>
<li><strong><em>norms</em></strong><br>标准化文档，针对某个文档属性，用于文档评分，会占用额外的磁盘空间，如果不需要评分可以关闭。</li>
<li><strong><em>null_value</em></strong><br>空值映射，针对文档属性，通常值为 <code>null</code> 的字段不会被索引也不能被搜索，这时候可以显式地告诉 ES <code>null</code> 值需要映射成什么，如：<code>&quot;null_value&quot;: &quot;NULL&quot;</code> 会使得某个字段的空值显式地转化为 NULL 字符串，以被索引和查询。</li>
<li><strong><em>position_increment_gap</em></strong><br>一般针对某 text 数组类型属性，因为 text 类型在索引时会考虑词项的位置，而对于一个 text 数组，其中每个元素在保存的时候会有一定的 <em>间距</em> ，通过这个间距（默认 100）来区分不同元素。举一个 match_phrase query 的例子：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;player&#x2F;football&#x2F;1</span><br><span class="line">&#123;&quot;name&quot;: [&quot;Lionel Messi&quot;, &quot;Cristiano Ronaldo&quot;]&#125;</span><br><span class="line"></span><br><span class="line">GET &#x2F;player&#x2F;football</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match_phrase&quot;: &#123;       </span><br><span class="line">      &quot;name&quot;: &#123;</span><br><span class="line">        &quot;query&quot;: &quot;Messi Cristiano&quot;,</span><br><span class="line">        # 为了查询到该文档，需要</span><br><span class="line">        &quot;slop&quot;: 101</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
像上面了例子也可以改变字段的的间距值，比如：<code>&quot;position_increment_gap&quot;: 0</code>。</li>
<li><strong><em>properties</em></strong><br>这个选项其实用的太普遍了以至于我们都忽略了。如果把 properties 看作一个配置项，那么它是针对某个类型的，用来指定属性的类型和其他配置。</li>
<li><strong><em>similarity</em></strong><br>用于指定某字段会用的评分模型，ES 中预置了三种模型：<ul>
<li><em>BM25</em> 默认评分模型</li>
<li><em>classic</em> TF/IDF 评分模型</li>
<li><em>boolean</em> 布尔评分模型</li>
</ul>
</li>
<li><strong><em>store</em></strong><br>决定某个字段是否被存储。默认字段会被索引但是不会存储，因为 _source 中包含了源文档的数据。</li>
<li><strong><em>term_vector</em></strong><br>决定词项量存储时候包含的信息：<ul>
<li><em>no</em> 默认值，不存储词向量</li>
<li><em>yes</em> 保存词项集合</li>
<li><em>with_positions</em> 保存词项和词项位置</li>
<li><em>with_offsets</em> 保存词项和字符偏移位置</li>
<li><em>with_positions_offsets</em> 保存词项、词项位置和字符偏移位置</li>
</ul>
</li>
<li><strong><em>dynamic_templates</em></strong><br>这也是一个特殊配置项，针对某个类型而言，配置 dynamic template 可以在字段进行自动映射时候按一定的规则确定索引字段的类型及别的配置。模板中<strong>至少需要包含一个条件</strong>，<strong>多个模板存在先后关系</strong>，<strong>最先匹配的模板会被应用</strong>。下面是一个例子：当文档中添加以 long_ 开头而不以 _text 结尾的字段时自动映射为 long 数据类型：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;index_name</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;type_name&quot;: &#123;</span><br><span class="line">      &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;template_name&quot;: &#123;</span><br><span class="line">            &quot;match_mapping_type&quot;: &quot;string&quot;,</span><br><span class="line">            &quot;match&quot;: &quot;long_&quot;,</span><br><span class="line">            &quot;unmatch&quot;: &quot;_text&quot;,</span><br><span class="line">            &quot;mapping&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;long&quot;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>以上内容涉及了字段类型、元字段性质以及配置映射时候的选项，本质是对索引管理内容的深化，除了了解 ES 本身的机制，这些内容的学习可以为学习 ES 带来更好的铺垫。</p>
<hr>
<p>参考：</p>
<ul>
<li>《从Lucene到ElasticSearch全文检索实战》 姚攀</li>
</ul>
]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>ES 分片路由</title>
    <url>/2018/10/ES-%E5%88%86%E7%89%87%E8%B7%AF%E7%94%B1/</url>
    <content><![CDATA[<h3 id="分片路由"><a href="#分片路由" class="headerlink" title="分片路由"></a>分片路由</h3><p>ES 在创建新文档时候时如何选择具体存储在哪个分片上？这就是一个文档分片路由的机制。ES 使用路由值（routing）的哈希散列进行分片的路由：<code>index_of_shards = hash(routing) % num_of_shards</code>。</p>
<h4 id="ES-查询请求过程"><a href="#ES-查询请求过程" class="headerlink" title="ES 查询请求过程"></a>ES 查询请求过程</h4><p>假设在一个多分片的 ES 进行查询，会有以下几个步骤：</p>
<ol>
<li>请求被某个节点接受</li>
<li>接受请求的节点将该请求广播到所有节点</li>
<li>每个分片进行搜索，并返回</li>
<li>各个分片的结果在一个节点合并，排序，返回响应</li>
</ol>
<a id="more"></a>

<h4 id="利用路由值进行搜索优化"><a href="#利用路由值进行搜索优化" class="headerlink" title="利用路由值进行搜索优化"></a>利用路由值进行搜索优化</h4><p>在默认情况下路由值等于文档的编号：<code>routing=_id</code>，这样可以让文档均匀的散列在所有分片上。但是在很多查询的时候 ES 无法确定查询的文档所在分片，所有会向所有分片进行广播。<strong>指定路由值可以避免广播请求</strong>，一定程度上减少资源消耗和增加效率，在请求时跟上 <code>routing</code> 参数即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /index/<span class="built_in">type</span>/_search?routing=123123</span><br></pre></td></tr></table></figure>

<p>指定 <code>routing</code> 的这个时候请求指向的分片事实上是<strong>确定</strong>的！这样的请求通常是查询的文档已经通过同样的路由值被添加了！否则这样的查询是无效的。</p>
<p>路由值是可以指定多个的，中间使用逗号 <code>,</code> 隔开。</p>
<h4 id="显式路由指定的弊端"><a href="#显式路由指定的弊端" class="headerlink" title="显式路由指定的弊端"></a>显式路由指定的弊端</h4><p>通常各个分片上的数据是均匀分布的（默认使用 id 进行哈希），但是如果大量使用显式路由指定文档，容易造成数据偏移在某些节点上。所以使用时需要对数据有足够了解。</p>
<hr>
<p>参考：</p>
<ul>
<li>《从Lucene到Elasticsearch全文检索实战》 姚攀</li>
</ul>
]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>ES 操作-文档管理</title>
    <url>/2018/10/ES-%E6%93%8D%E4%BD%9C-%E6%96%87%E6%A1%A3%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h4 id="创建文档"><a href="#创建文档" class="headerlink" title="创建文档"></a>创建文档</h4><p>ES 提供了一套遵守 Restful 语义的接口，相关的操作可以通过不同的请求方法来进行调用，比如简单的新增可以使用 POST 请求或者 PUT 请求</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># PUT 多次请求结果幂等，仅增加文档版本号，文档编号不可省略</span></span><br><span class="line">PUT /&lt;索引&gt;/&lt;类型&gt;/&lt;编号&gt;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"字段A"</span>: <span class="string">"值A"</span>,</span><br><span class="line">    <span class="string">"字段B"</span>: <span class="string">"值B"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># POST 请求在版本号省略时，可以自动生成字符串文档编号</span></span><br><span class="line">POST /&lt;索引&gt;/&lt;类型&gt;/[编号]</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"字段A"</span>: <span class="string">"值A"</span>,</span><br><span class="line">    <span class="string">"字段B"</span>: <span class="string">"值B"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h4 id="简单查询"><a href="#简单查询" class="headerlink" title="简单查询"></a>简单查询</h4><h5 id="单一文档指定查询"><a href="#单一文档指定查询" class="headerlink" title="单一文档指定查询"></a>单一文档指定查询</h5><p>查询特定的文档，（先不考虑条件查询等）需要明确指定索引名称，类型名称和文档编号，如果文档存在，返回的 <code>found</code> 域会为 true</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 GET 请求获取指定的文档信息</span></span><br><span class="line">GET /&lt;索引名称&gt;/&lt;类型名称&gt;/&lt;文档编号&gt;</span><br><span class="line"><span class="comment"># 可以使用利用版本号-version来控制资源的时效性（ES 悲观锁机制），版本号不正确会抛出异常</span></span><br><span class="line">GET /&lt;索引名称&gt;/&lt;类型名称&gt;/&lt;文档编号&gt;?version=&lt;期望版本号&gt;</span><br></pre></td></tr></table></figure>

<p>如果不需要文档内容，只需要确认文档是否存在可以使用 HEAD 请求</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># HEAD 请求，200 成功，404 未找到</span></span><br><span class="line">HEAD /&lt;索引名称&gt;/&lt;类型名称&gt;/&lt;文档编号&gt;</span><br></pre></td></tr></table></figure>

<h5 id="多个文档指定查询"><a href="#多个文档指定查询" class="headerlink" title="多个文档指定查询"></a>多个文档指定查询</h5><p>在指定查询多个文档时候需要使用 <code>_mget</code> API：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /[公共索引名称]/[公共类型名称]/_mget</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"docs"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"_index"</span>: <span class="string">"具体索引名称A"</span>, <span class="comment"># 当未指定公共索引名称时需要</span></span><br><span class="line">            <span class="string">"_type"</span>: <span class="string">"具体类型名称A"</span>, <span class="comment"># 当未指定公共类型名称时需要</span></span><br><span class="line">            <span class="string">"_id"</span>: <span class="string">"具体文档编号"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"_index"</span>: <span class="string">"具体索引名称B"</span>,</span><br><span class="line">            <span class="string">"_type"</span>: <span class="string">"具体类型名称B"</span>,</span><br><span class="line">            <span class="string">"_id"</span>: <span class="string">"具体文档编号"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在查询同一索引同一类型时最简写法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /&lt;公共索引名称&gt;/&lt;公共类型名称&gt;/_mget</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"ids"</span>: [<span class="string">"编号1"</span>, <span class="string">"编号2"</span>, <span class="string">"编号3"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="文档更新"><a href="#文档更新" class="headerlink" title="文档更新"></a>文档更新</h4><h5 id="简单更新操作"><a href="#简单更新操作" class="headerlink" title="简单更新操作"></a>简单更新操作</h5><p>文档更新时候，ES 会删除旧的文档，更新文档内容后索引新的文档。通常，最简单的更新操作可以直接使用 PUT 操作完成：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /&lt;索引&gt;/&lt;类型&gt;/&lt;编号&gt;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"字段A"</span>: <span class="string">"新值A"</span>,</span><br><span class="line">    <span class="string">"新字段B"</span>: <span class="string">"新值B"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ES 悲观锁机制，默认情况下每次更新会使得版本号增 1，其实也可以手动指定值（当然指定的版本号需要大于当前版本号）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /&lt;索引&gt;/&lt;类型&gt;/&lt;编号&gt;?version=&lt;版本号&gt;&amp;version_type=external</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"字段A"</span>: <span class="string">"新值A"</span>,</span><br><span class="line">    <span class="string">"新字段B"</span>: <span class="string">"新值B"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="脚本更新操作"><a href="#脚本更新操作" class="headerlink" title="脚本更新操作"></a>脚本更新操作</h5><p>更为复杂的更新操作可以使用 POST 请求操作 <code>_update API</code>，下面是一个简单例子：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /&lt;索引&gt;/&lt;类型&gt;/&lt;编号&gt;/_update</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment"># 声明使用脚本进行操作文档</span></span><br><span class="line">    <span class="string">"script"</span>: &#123;</span><br><span class="line">        <span class="comment"># 书写脚本内容（the 'inline' is deprecated）</span></span><br><span class="line">        <span class="comment"># 这里五个语句分别是：字段值修改，移除字段，新增字段（类似修改），字段值修改（api调用），文档删除</span></span><br><span class="line">        <span class="string">"source"</span>: <span class="string">"ctx._source.count += params.count; ctx._source.remove(\"to_be_removed\"); ctx._source.tags=[]; ctx._source.tags.add(params.class); ctx._source.op=\"delete\""</span>,</span><br><span class="line">        <span class="comment"># 声明脚本语言</span></span><br><span class="line">        <span class="string">"lang"</span>: <span class="string">"painless"</span>,</span><br><span class="line">        <span class="comment"># 输入脚本入参集合</span></span><br><span class="line">        <span class="string">"params"</span>: &#123;</span><br><span class="line">            <span class="string">"count"</span>: 3,</span><br><span class="line">            <span class="string">"class"</span>: <span class="string">"Java"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment"># 可选，当指定更新的资源不存在时，进行插入</span></span><br><span class="line">    <span class="string">"upsert"</span>: &#123;</span><br><span class="line">        <span class="string">"字段A"</span>: <span class="string">"值A"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="条件过滤更新"><a href="#条件过滤更新" class="headerlink" title="条件过滤更新"></a>条件过滤更新</h5><p>同时 ES 也支持条件查询后对文档进行更新，使用 <code>_update_by_query</code>，类似 SQL 中 update…where 的形式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /[索引名]/[类型名]/_update_by_query</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment"># 脚本的具体使用同上</span></span><br><span class="line">    <span class="string">"script"</span>: &#123;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment"># 查询条件，具体之后深入</span></span><br><span class="line">    <span class="string">"query"</span>: &#123;</span><br><span class="line">        <span class="string">"term"</span>: &#123;</span><br><span class="line">            <span class="string">"age"</span>: 18</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h4><h5 id="简单删除操作"><a href="#简单删除操作" class="headerlink" title="简单删除操作"></a>简单删除操作</h5><p>很简单的，使用 DELETE 方法并指定资源即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除指定文档，自动路由</span></span><br><span class="line">DELETE /&lt;索引&gt;/&lt;类型&gt;/&lt;文档编号&gt;</span><br><span class="line"><span class="comment"># 删除指定文档，并给定路由参数</span></span><br><span class="line">DELETE /&lt;索引&gt;/&lt;类型&gt;/&lt;文档编号&gt;?routing=&lt;路由值&gt;</span><br></pre></td></tr></table></figure>

<h5 id="条件过滤删除"><a href="#条件过滤删除" class="headerlink" title="条件过滤删除"></a>条件过滤删除</h5><p>如同更新操作，可以在删除前进行查询操作，以过滤出需要删除的文档，使用 <code>_delete_by_query</code> API 操作：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /[索引名]/[类型名]/_delete_by_query</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"query"</span>: &#123;</span><br><span class="line">        <span class="comment"># 查询条件</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h4><p>很多时候需要同时操作大量的文档，一个一个来执行命令显然是不可能的。ES 提供了 <code>_bulk</code> API，并支持多文档的创建，更新，删除等操作，但是对格式有一定的要求。首先需要一个 JSON 格式的内容：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># 新建</span><br><span class="line">&#123;<span class="attr">"create / index"</span>: &#123;<span class="attr">"_index"</span>: <span class="string">"索引名称"</span>, <span class="attr">"_type"</span>: <span class="string">"类型名称"</span>, <span class="attr">"_id"</span>: <span class="string">"不指定则自动生成"</span>&#125;&#125;</span><br><span class="line">&#123;&lt;文档内容&gt;&#125;</span><br><span class="line"></span><br><span class="line"># 删除</span><br><span class="line">&#123;<span class="attr">"delete"</span>: &#123;<span class="attr">"_index"</span>: <span class="string">"索引名称"</span>, <span class="attr">"_type"</span>: <span class="string">"类型名称"</span>, <span class="attr">"_id"</span>: <span class="string">"id值"</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"># 更新</span><br><span class="line">&#123;<span class="attr">"update"</span>: &#123;<span class="attr">"_index"</span>: <span class="string">"索引名称"</span>, <span class="attr">"_type"</span>: <span class="string">"类型名称"</span>, <span class="attr">"_id"</span>: <span class="string">"id值"</span>, <span class="attr">"_retry_on_conflict"</span>: <span class="number">3</span>&#125;&#125;</span><br><span class="line">&#123;"doc": &#123;&lt;需要更新的内容&gt;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>然后使用一个 POST 请求：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -XPOST <span class="string">"地址/_bulk?pretty"</span> --data-binary @JSON文件名</span><br></pre></td></tr></table></figure>
<p>bulk 请求时注意文件的大小，因为整个请求会被加载进被请求的节点，所以同时可供其他请求的内存会相应变小。合适的大小值不是一个固定值，这取决机器配置和索引复杂度，搜索负载等。一个合适的批次通常在 5~15 MB之间。</p>
<hr>
<p>参考：</p>
<ul>
<li>《从Lucene到Elasticsearch全文检索实战》 姚攀</li>
</ul>
]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Git 命令笔记</title>
    <url>/2018/10/Git-%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<ul>
<li>初始化仓库<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化一个 git 仓库并且建立工作目录</span></span><br><span class="line">git init</span><br><span class="line"><span class="comment"># 初始化一个干净的仓库，使用 bare 选项不带有工作目录，使用 shared 选项，提供组可写的权限</span></span><br><span class="line">git init --bare --shared</span><br></pre></td></tr></table></figure></li>
<li>克隆仓库<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在未指定协议的时候优先会采用 ssh</span></span><br><span class="line">git <span class="built_in">clone</span> [地址]</span><br></pre></td></tr></table></figure></li>
<li>暂存文件<br>将文件提交至暂存区（进入 staged 状态）<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add [路径]</span><br><span class="line"><span class="comment"># 只暂存所有已经跟踪的文件，这通常可以减少多余文件的提交</span></span><br><span class="line">git add -u</span><br></pre></td></tr></table></figure>
<a id="more"></a></li>
<li>查看当前工作区以及暂存区的文件状态<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 该命令会展示所有文件的状态，包括它是否已经修改，是否被跟踪，是否被暂存</span></span><br><span class="line">git status</span><br></pre></td></tr></table></figure></li>
<li>查看工作区和暂存区文件差异<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看工作区和暂存区快照间的差异（文件与上一次 add 时的差异）</span></span><br><span class="line">git diff</span><br><span class="line"><span class="comment"># 查看工作区和上次提交时的差异（文件与上一次 commit 时的差异）</span></span><br><span class="line">git diff --staged</span><br><span class="line">git diff --cached</span><br><span class="line"><span class="comment"># 可以携带版本号，可以指定文件名产看，版本间指定文件的差异</span></span><br><span class="line"><span class="comment"># 第二版本号省略时默认为当前版本，文件路径省略时默认所有文件</span></span><br><span class="line">git diff [版本号] [版本号]</span><br><span class="line">git diff [版本号] [版本号] -- [文件路径]</span><br><span class="line"><span class="comment"># 查看在之前祖先基础上的差异需要在源版本号前添加'...'，如：</span></span><br><span class="line">git diff master...feature</span><br></pre></td></tr></table></figure></li>
<li>提交更新<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在暂存区准备妥当之后，把暂存区内容提交</span></span><br><span class="line">git commit</span><br><span class="line"><span class="comment"># 在提交时会要求输入提交备注，可以直接在命令行键入</span></span><br><span class="line">git commit -m [提交备注]</span><br><span class="line"><span class="comment"># 偶尔跳过暂存步骤，将工作区全部的修改直接提交</span></span><br><span class="line">git commit -a</span><br></pre></td></tr></table></figure></li>
<li>文件删除<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除动作会将文件删除，并且在完成动作时修改暂存区</span></span><br><span class="line">git rm [路径]</span><br><span class="line"><span class="comment"># 如果该文件已经被本次修改后暂存（staged）需要强制删除</span></span><br><span class="line">git rm -f [路径]</span><br><span class="line"><span class="comment"># 从仓库中删除而不删除工作区文件，即放弃跟踪</span></span><br><span class="line">git rm --cached [路径]</span><br></pre></td></tr></table></figure></li>
<li>文件移动<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如同文件删除，移动命令会在移动后对暂存区修改</span></span><br><span class="line">git mv [源路径] [目标路径]</span><br></pre></td></tr></table></figure></li>
<li>查看提交历史<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看历史时会展示历次提交的哈希值、作者、时间以及提交备注</span></span><br><span class="line">git <span class="built_in">log</span></span><br><span class="line"><span class="comment"># 使用 p 选项展示内容差异</span></span><br><span class="line">git <span class="built_in">log</span> -p</span><br><span class="line"><span class="comment"># 可以指定展示条目数量</span></span><br><span class="line">git <span class="built_in">log</span> -[N: int]</span><br><span class="line"><span class="comment"># 展示增删改行数统计</span></span><br><span class="line">git <span class="built_in">log</span> --<span class="built_in">stat</span></span><br><span class="line"><span class="comment"># 按单词维度检测修改内容，需要同时指定显示的上下行数</span></span><br><span class="line">git <span class="built_in">log</span> --word-diff -U[N: int]</span><br><span class="line"><span class="comment"># 支持图形化展示</span></span><br><span class="line">git <span class="built_in">log</span> --graph</span><br><span class="line"><span class="comment"># 支持格式化记录的显示</span></span><br><span class="line">git <span class="built_in">log</span> --pretty=[FormatMode]</span><br><span class="line"><span class="comment"># FormatMode 常用形式</span></span><br><span class="line"><span class="comment"># oneline 单行显示，仅显示提交的哈希值和备注</span></span><br><span class="line"><span class="comment"># fuller 完整显示，包括作者，创建时间，提交者，提交时间，提交备注等</span></span><br><span class="line"><span class="comment"># format:[格式字符串] 按指定格式输出，具体占位符含义查看手册</span></span><br><span class="line"><span class="comment"># 查看在 A 分支上而不在 B 分支上的提交，有多种写法</span></span><br><span class="line">git <span class="built_in">log</span> B..A</span><br><span class="line">git <span class="built_in">log</span> ^B A</span><br><span class="line">git <span class="built_in">log</span> A --not B</span><br><span class="line"><span class="comment"># 查看在多个分支上仅不在 B 分支上的提交</span></span><br><span class="line">git <span class="built_in">log</span> A C --not B</span><br><span class="line">git <span class="built_in">log</span> A C ^B</span><br><span class="line"><span class="comment"># 查看在 A 或 B 上，但不同时存在于 A 和 B 上的提交，使用 left-right 选项区分提交所在分支位置</span></span><br><span class="line">git <span class="built_in">log</span> --left-right A...B</span><br></pre></td></tr></table></figure></li>
<li>文件修改<ul>
<li>提交修改<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果遗漏部分提交，可以重新更新暂存区后使用 amend 选项修改之前次的提交，比如如下操作</span></span><br><span class="line">git commit -a -m <span class="string">'first commit'</span></span><br><span class="line">touch a.txt</span><br><span class="line">git add a.txt</span><br><span class="line">git commit --amend -m <span class="string">'first commit with a.txt'</span></span><br></pre></td></tr></table></figure></li>
<li>撤销暂存区快照<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 取消暂存状态的修改</span></span><br><span class="line">git reset HEAD [路径]</span><br></pre></td></tr></table></figure></li>
<li>撤销工作区修改<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 这会使工作区的内容还原至上一次提交时的状态，慎用</span></span><br><span class="line">git checkout -- [路径]</span><br></pre></td></tr></table></figure></li>
<li>还原代码至指定的版本（也可以向上）<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mixed 默认选项，回退 HEAD 并还原暂存区，所有修改保留在工作区</span></span><br><span class="line"><span class="comment"># soft 选项，仅回退 HEAD，保留暂存区和工作区的改动</span></span><br><span class="line"><span class="comment"># hard 选项，将回退 HEAD 并还原暂存区和工作区内容，彻底的回退</span></span><br><span class="line">git reset [--soft/hard/mixed] [版本号]</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>远程仓库<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 远程仓库列表，默认仅显示仓库名称，v 选项列出具体地址</span></span><br><span class="line">git remote -v</span><br><span class="line"><span class="comment"># 添加远程仓库</span></span><br><span class="line">git remote add [远端名称] [远端仓库地址]</span><br><span class="line"><span class="comment"># 展示远端具体信息，包括未跟踪的分支、提交的信息等</span></span><br><span class="line">git remote show [远端名称]</span><br><span class="line"><span class="comment"># 重命名远程名称</span></span><br><span class="line">git remote rename [源远程名称] [新远程名称]</span><br><span class="line"><span class="comment"># 删除关联的远程仓库</span></span><br><span class="line">git remote rm [远程名称]</span><br></pre></td></tr></table></figure></li>
<li>标签处理<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 展示所有标签，</span></span><br><span class="line">git tag</span><br><span class="line"><span class="comment"># 使用 l 选项过滤标签，可以使用通配符</span></span><br><span class="line">git tag -l <span class="string">'v1.*'</span></span><br><span class="line"><span class="comment"># 创建轻量级标签，如果版本哈希值省略，则为当前版本打标签</span></span><br><span class="line">git tag [标签名称] [版本哈希值或分支名或标签名]</span><br><span class="line"><span class="comment"># 创建携带附注的标签，使用 m 选项可以直接输入标签备注</span></span><br><span class="line">git tag -a [标签名称] -m [标签备注]</span><br><span class="line"><span class="comment"># 使用 GPG 签名创建标签</span></span><br><span class="line">git tag -s [标签名称]</span><br><span class="line"><span class="comment"># 验证标签，仅对于签名的标签</span></span><br><span class="line">git tag -v [标签名称]</span><br></pre></td></tr></table></figure></li>
<li>分支处理<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看所有分支，默认展示本地分支，使用 r 选项展示远端分支，a 选项全部展示</span></span><br><span class="line">git branch -a</span><br><span class="line"><span class="comment"># 新建分支，如果版本哈希值省略，默认在当前版本新建分支</span></span><br><span class="line">git branch [分支名称] [版本哈希值或分支名或标签名]</span><br><span class="line"><span class="comment"># 新建分支后并不会直接切换至该分支，需要进行切换</span></span><br><span class="line">git checkout [分支名称]</span><br><span class="line"><span class="comment"># 新建并检出一个分支</span></span><br><span class="line">git checkout -b [新分支名称] [版本哈希值或分支名或标签名]</span><br><span class="line"><span class="comment"># 使用 track 选项简化上述命令，直接新建同名分支并跟踪远端分支</span></span><br><span class="line">git checkout --track [远程名]/[分支名称]</span><br><span class="line"><span class="comment"># 使用 d 选项删除分支</span></span><br><span class="line">git branch -d [分支名称]</span><br></pre></td></tr></table></figure></li>
<li>拉取和推送<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 大部分时候，远程名称可以省略，默认使用 origin</span></span><br><span class="line"><span class="comment"># 拉取远程仓库的数据（这不会直接进行合并</span></span><br><span class="line">git fetch [远程名称]</span><br><span class="line"><span class="comment"># 向远端推送数据，远程分支名称省略时推送至已关联的远程分支上，本地分支名称和远程分支名称一起省略时可以推送当前分支至远程对应分支上</span></span><br><span class="line">git push [远程名称] [本地分支名称]:[远程分支名称]</span><br><span class="line"><span class="comment"># 删除远程分支</span></span><br><span class="line">git push [远程名称] :[远程分支名称]</span><br></pre></td></tr></table></figure></li>
<li>变基操作<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可以将某一些特性在指定的基分支上重演，省略特性分支时默认为当前分支</span></span><br><span class="line">git rebase [基分支] [特性分支]</span><br><span class="line"><span class="comment"># 有时候需要变基的特性分支和并不直接基于基分支，在需要跳过中间分支的情况下需要使用 onto 选项</span></span><br><span class="line">git rebase --onto [基分支] [跳过分支] [特性分支]</span><br><span class="line"><span class="comment"># 变基过程中可能遇到冲突，git 会自动停下等待处理</span></span><br><span class="line"><span class="comment"># 冲突处理完成后继续</span></span><br><span class="line">git rebase --<span class="built_in">continue</span></span><br><span class="line"><span class="comment"># 放弃处理冲突，放弃变基</span></span><br><span class="line">git rebase --abort</span><br></pre></td></tr></table></figure></li>
<li>使用补丁<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 diff 创建一个简单的补丁，diff 的输出就是一个标准的 patch 内容，例子如下：</span></span><br><span class="line">git diff master &gt;&gt; [补丁路径]</span><br><span class="line"><span class="comment"># 打上补丁，之后需要手动提交</span></span><br><span class="line">git apply [补丁路径]</span><br><span class="line"><span class="comment"># 添加补丁前最好测试是否存在冲突</span></span><br><span class="line">git apply --check [补丁路径]</span><br><span class="line"><span class="comment"># 使用 git format-patch 创建补丁，该补丁已邮件方式存在，并包含提交者信息，可以添加额外的描述，通常使用 M 选项检测重命名</span></span><br><span class="line">git format-patch [比较的版本号]</span><br><span class="line">git format-patch HEAD^^</span><br><span class="line"><span class="comment"># 使用 format-patch 创建的补丁需要使用 am 指定来确认</span></span><br><span class="line">git am [补丁路径]</span><br><span class="line"><span class="comment"># 如同变基操作一样，在遇到冲突或者无法快速合并时候，git 会停下让你解决冲突或者放弃</span></span><br><span class="line"><span class="comment"># 冲突解决完成，继续</span></span><br><span class="line">git am --[<span class="built_in">continue</span>/resolved/r]</span><br><span class="line"><span class="comment"># 放弃并还原</span></span><br><span class="line">git am --abort</span><br><span class="line"><span class="comment"># 跳过该补丁</span></span><br><span class="line">git am --skip</span><br><span class="line"><span class="comment"># 在存在公共祖先的时候，git 可以更智能地合并</span></span><br><span class="line">git am -3 [补丁路径]</span><br></pre></td></tr></table></figure></li>
<li>发布<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 发布前准备，需要打上一个标注标签（使用 a 或 s 选项）</span></span><br><span class="line"><span class="comment"># 查看内部版本号，通常用来做归档压缩包的名称</span></span><br><span class="line">git describe [分支或标签名称]</span><br><span class="line"><span class="comment"># 进行归档，可以使用 prefix 增加根目录，使用 format 指定格式</span></span><br><span class="line">git archive [分支或标签名称] --prefix=<span class="string">'[增加的根目录名称/]'</span> --format=[zip/tar/tar.gz/...]</span><br><span class="line"><span class="comment"># 上述命令仅输出二进制内容，需要将其输入至归档文件，如</span></span><br><span class="line">git archive master --prefix=<span class="string">'project/'</span> --format=zip &gt; `git describe master`.zip</span><br></pre></td></tr></table></figure></li>
<li>储藏内容<br>git 可以帮助储藏一份临时性的改动便于之后恢复<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将已跟踪的文件的改动进行储藏</span></span><br><span class="line">git stash</span><br><span class="line">git stash push [描述]</span><br><span class="line"><span class="comment"># 查看储藏栈内所有的储藏记录</span></span><br><span class="line">git stash list</span><br><span class="line"><span class="comment"># 将储藏内容还原至工作区和暂存区，名称省略时使用栈顶记录</span></span><br><span class="line">git stash apply [stash@&#123;N&#125;]</span><br><span class="line"><span class="comment"># 删除储藏栈中的记录</span></span><br><span class="line">git stash drop stash@&#123;N&#125;</span><br><span class="line"><span class="comment"># 清除全部储藏站中的记录</span></span><br><span class="line">git stash clear</span><br><span class="line"><span class="comment"># 将储藏内容还原，并立即移除记录</span></span><br><span class="line">git stash pop stash@&#123;N&#125;</span><br><span class="line"><span class="comment"># 还原应用的储藏内容，通过 show -p 选项展示 diff patch 内容，并使用 apply -R 来撤销应用</span></span><br><span class="line">git stash show -p [stash@&#123;N&#125;] | git apply -R</span><br><span class="line"><span class="comment"># 直接从储藏中新开分支来避开冲突解决，使用栈顶记录时可省略储藏名称，完成时会自动移除储藏栈记录</span></span><br><span class="line">git stash branch [新分支名称] [stash@&#123;N&#125;]</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>ES 操作-索引管理</title>
    <url>/2018/09/ES-%E6%93%8D%E4%BD%9C-%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<h4 id="新建索引"><a href="#新建索引" class="headerlink" title="新建索引"></a>新建索引</h4><p>新建索引很简单，但是需要注意的是：</p>
<ul>
<li>ES 中索引名称不能包含大写字母</li>
<li>不能再次 PUT 一个已经存在的索引</li>
<li>ES 默认给索引设置 5 个分片和 1 个副本，该值可以通过 setting 参数域进行修改。其中副本数在索引创建之后支持修改，而分片数无法修改！<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /person</span><br><span class="line"><span class="comment"># 可选项，不附加请求体的情况下统一使用默认值</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"settings"</span>: &#123;</span><br><span class="line">        <span class="comment"># 分片数量</span></span><br><span class="line">        <span class="string">"number_of_shards"</span>: 3,</span><br><span class="line">        <span class="comment"># 副本数量</span></span><br><span class="line">        <span class="string">"number_of_replicas"</span>: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<a id="more"></a>

</li>
</ul>
<h4 id="更新索引"><a href="#更新索引" class="headerlink" title="更新索引"></a>更新索引</h4><p>对某属性设置相应的值即可。如果设置为 <code>null</code> 可以将其恢复成默认值</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /person/_settings</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"number_of_replicas"</span>: 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="索引设置"><a href="#索引设置" class="headerlink" title="索引设置"></a>索引设置</h5><p>部分设置的含义在后文涉及</p>
<ul>
<li>静态设置<br>这部分的设置只有在索引创建或者关闭时支持修改（分片数量只能在创建索引时设置）  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 主分片数，默认为5.只能在创建索引时设置，不能修改</span></span><br><span class="line">index.number_of_shards</span><br><span class="line"><span class="comment"># 是否应在索引打开前检查分片是否损坏，当检查到分片损坏将禁止分片被打开</span></span><br><span class="line"><span class="comment">#   false //默认值</span></span><br><span class="line"><span class="comment">#   checksum //检查物理损坏</span></span><br><span class="line"><span class="comment">#   true //检查物理和逻辑损坏，这将消耗大量内存和CPU</span></span><br><span class="line"><span class="comment">#   fix //检查物理和逻辑损坏。有损坏的分片将被集群自动删除，这可能导致数据丢失</span></span><br><span class="line">index.shard.check_on_startup</span><br><span class="line"><span class="comment"># 自定义路由值可以转发的目的分片数。默认为 1，只能在索引创建时设置。此值必须小于index.number_of_shards</span></span><br><span class="line">index.routing_partition_size</span><br><span class="line"><span class="comment"># 数据压缩方式，默认使用LZ4，也可以设置为 best_compression，它使用 DEFLATE 方式以牺牲字段存储性能为代价来获得更高的压缩比例</span></span><br><span class="line">index.codec</span><br></pre></td></tr></table></figure></li>
<li>动态设置<br>这部分配置支持直接修改<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 每个主分片的副本数，默认为 1</span></span><br><span class="line">index.number_of_replicas</span><br><span class="line"><span class="comment"># 基于可用节点的数量自动分配副本数量，默认为 false（即禁用此功能）</span></span><br><span class="line">index.auto_expand_replicas</span><br><span class="line"><span class="comment"># 执行刷新操作的频率，这使得索引的最近更改可以被搜索。默认为 1s。可以设置为 -1 以禁用刷新。</span></span><br><span class="line">index.refresh_interval</span><br><span class="line"><span class="comment"># 用于索引搜索的 from + size 的最大值，默认为 10000</span></span><br><span class="line">index.max_result_window</span><br><span class="line"><span class="comment"># 在搜索此索引中 rescore 的 window_size 的最大值</span></span><br><span class="line">index.max_rescore_window</span><br><span class="line"><span class="comment"># 设置为 true 使索引和索引元数据为只读，默认 false 为允许写入和元数据更改</span></span><br><span class="line">index.blocks.read_only</span><br><span class="line"><span class="comment"># 设置为 true 可禁用对索引的读取操作，默认 false</span></span><br><span class="line">index.blocks.read</span><br><span class="line"><span class="comment"># 设置为 true 可禁用对索引的写入操作，默认 false</span></span><br><span class="line">index.blocks.write</span><br><span class="line"><span class="comment"># 设置为 true 可禁用索引元数据的读取和写入，默认 false</span></span><br><span class="line">index.blocks.metadata</span><br><span class="line"><span class="comment"># 索引的每个分片上可用的最大刷新侦听器数</span></span><br><span class="line">index.max_refresh_listeners</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="查询索引"><a href="#查询索引" class="headerlink" title="查询索引"></a>查询索引</h4><p>关于查询也是简单的，通过 GET 请求和 _setting API 可以获得索引的配置信息。而 _cat API 可以以摘要的形式展示所有索引的开关状态，健康状态，分片数，副本数以及一些其他信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查询单个索引设置</span></span><br><span class="line">GET /person/_settings</span><br><span class="line"><span class="comment"># 查询多个索引设置</span></span><br><span class="line">GET /person,animal/_settings</span><br><span class="line"><span class="comment"># 按通配符查询索引设置</span></span><br><span class="line">GET /p*/_settings</span><br><span class="line"><span class="comment"># 查询所有索引设置</span></span><br><span class="line">GET /_all/settings</span><br><span class="line"><span class="comment"># 使用 _cat API 来展示所有索引的综合信息</span></span><br><span class="line">GET /_cat/indices</span><br></pre></td></tr></table></figure>

<h4 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h4><p>删除是最简单，当然如果指定的索引名称不存在会响应 404</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">DELETE /person</span><br></pre></td></tr></table></figure>

<h4 id="索引开关"><a href="#索引开关" class="headerlink" title="索引开关"></a>索引开关</h4><p>可以关闭一些暂时不用的索引来减少系统资源的开销，关闭后将无法进行读写</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST person/_close</span><br></pre></td></tr></table></figure>
<p>相对的，打开操作：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST person/_open</span><br></pre></td></tr></table></figure>
<p>这里依然支持同时操作多个索引，以及通配符和 _all 关键字的处理：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /person,animal/_close</span><br></pre></td></tr></table></figure>
<p>如果同时指定的索引中存在不存在的索引，会显示抛出错误。这可以通过一个简单参数 <code>ignore_unavailable=true</code> 来忽略</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /person,animal/_close?ignore_unavailable=<span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h4 id="索引复制"><a href="#索引复制" class="headerlink" title="索引复制"></a>索引复制</h4><p>通过 _reindex API 可以将一个索引的内容复制至另一个索引，这同时可以指定过滤条件，已筛选需要的 type 以及 doc。<br>需要注意的是，由于这不会同时复制索引的配置信息，所以在操作的时候需要提前建立好新索引</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /_reindex</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"source"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"person"</span>,</span><br><span class="line">        <span class="comment"># 可选项，用于过滤类型 type</span></span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"student"</span></span><br><span class="line">        <span class="comment"># 可选项，用于过滤文档 doc</span></span><br><span class="line">        <span class="string">"query"</span>: &#123;</span><br><span class="line">            <span class="string">"term"</span>: &#123; <span class="string">"sex"</span>: <span class="string">"male"</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"dest"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"person_new"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="索引收缩"><a href="#索引收缩" class="headerlink" title="索引收缩"></a>索引收缩</h4><p>分片数量在索引初始化之后便无法修改。_shrink API 可以将一个索引收缩成一个分片数量更少的索引。当然，这是有要求的：</p>
<ul>
<li>收缩后索引的分片数必须是收缩前索引的分片数的因子，如 8 -&gt; 4，或者 15 -&gt; 5。这意味着如果源索引的分片数如果是质数，那么很尴尬，只能收缩成 1 个分片的新索引</li>
<li>收缩前，索引的每个分片需要都存在于同一节点上（可以指定路由实现）</li>
<li>索引必须为只读状态</li>
</ul>
<p>后两者条件可以通过以下指令实现：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /person/_settings</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"index.routing.allocation.require._name"</span>: <span class="string">"shrink_node_name"</span>,</span><br><span class="line">    <span class="string">"index.block.write"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来便可以实际进行索引的收缩了，ES 完成的流程包括这几个步骤：</p>
<ol>
<li>创建一个配置与源索引相同但是分片数减少的新索引</li>
<li>源索引硬链接至新索引（文件系统不支持的情况下会进行复制）</li>
<li>打开新的索引</li>
</ol>
<p>_shrink 的一个例子如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /person/_shrink/person_new</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"settings"</span>: &#123;</span><br><span class="line">        <span class="string">"index.number_of_replicas"</span>: 0,</span><br><span class="line">        <span class="string">"index.number_of_shards"</span>: 1,</span><br><span class="line">        <span class="string">"index.codec"</span>: <span class="string">"best_compression"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment"># 就如同新建索引一样，可以同时设置别名</span></span><br><span class="line">    <span class="string">"aliases"</span>: &#123;</span><br><span class="line">        <span class="string">"pn"</span>: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="索引别名"><a href="#索引别名" class="headerlink" title="索引别名"></a>索引别名</h4><p>通过 _aliases API 可以选择为索引设置别名，这就像软连接一样</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"actions"</span>: [&#123;</span><br><span class="line">        <span class="comment"># 新增索引，可以一次操作多个索引，并合并书写</span></span><br><span class="line">        <span class="string">"add"</span>: &#123;</span><br><span class="line">            <span class="string">"indices"</span>: [<span class="string">"animal"</span>, <span class="string">"plant"</span>],</span><br><span class="line">            <span class="string">"alias"</span>: <span class="string">"living_thing"</span></span><br><span class="line">        &#125;&#125;, &#123;</span><br><span class="line">         <span class="comment"># 删除索引，也可以一次操作多个索引，支持通配符</span></span><br><span class="line">        <span class="string">"remove"</span>: &#123;</span><br><span class="line">            <span class="string">"index"</span>: <span class="string">"person"</span>,</span><br><span class="line">            <span class="string">"alias"</span>: <span class="string">"person_alias"</span></span><br><span class="line">        &#125;&#125;, &#123;</span><br><span class="line">        <span class="string">"remove"</span>: &#123;</span><br><span class="line">            <span class="string">"index"</span>: <span class="string">"school"</span>,</span><br><span class="line">            <span class="string">"alias"</span>: <span class="string">"school_alias"</span></span><br><span class="line">        &#125;&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在通常使用时，别名基本和原索引名用法一样。但是如果别名和索引不是一对一关系的时候，无法通过别名索引文档或者通过 ID 来查询</p>
<p>关于索引别名的查询也十分简单：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果想知道某索引（如 person）的别名</span></span><br><span class="line">GET /person/_aliases</span><br><span class="line"><span class="comment"># 获取所有别名</span></span><br><span class="line">GET /_aliases</span><br><span class="line"><span class="comment"># 使用 _cat API 获取所有索引摘要</span></span><br><span class="line">GET /_cat/aliases</span><br></pre></td></tr></table></figure>

<h3 id="补充-Restful-语义"><a href="#补充-Restful-语义" class="headerlink" title="补充 Restful 语义"></a>补充 Restful 语义</h3><p>在 ES 操作中，以下几个请求方式是最常用的，补充一下以下请求代表的语义：</p>
<ul>
<li><code>GET</code>：获取资源信息</li>
<li><code>DELETE</code>：删除指定的资源标识符下的资源</li>
<li><code>POST</code>：提交一个新的资源，不具备幂等性</li>
<li><code>PUT</code>：新增或更新一个资源标识符下资源，操作具有幂等性</li>
<li><code>HEAD</code>：获取该次请求的响应头信息</li>
</ul>
]]></content>
      <categories>
        <category>ElasticSearch</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 服务端消息过滤</title>
    <url>/2018/08/RocketMQ-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B6%88%E6%81%AF%E8%BF%87%E6%BB%A4/</url>
    <content><![CDATA[<p>在服务端进行消息过滤，可以减少不必要的流量，提高带宽利用度和吞吐量。<br>RocketMQ 支持多种方式来进行服务端的消息过滤</p>
<h2 id="消息使用-Tag-标签"><a href="#消息使用-Tag-标签" class="headerlink" title="消息使用 Tag 标签"></a>消息使用 Tag 标签</h2><p>作为一条 Message，它有着特定的 Topic，同时也可以指定唯一的 Tag 标记子分类。消费方在订阅消息时候，Broker 可以在指定 Topic 的 ConsumeQueue 下按 Tag 进行过滤，只从 CommitLog 中取出 Tag 命中的消息。 </p>
<a id="more"></a>
<p>使用 Tag 进行过滤是高效的，因为消息在 MessageQueue 的存储格式如下：</p>
<ul>
<li>CommitLog Offset：顾名思义，保存着在 CommitLog 中的偏移量，占用 8 个字节</li>
<li>Size：使用 4 个字节来记录消息的大小</li>
<li>Message Tag HashCode：记录对应消息的 Tag 的哈希</li>
</ul>
<p>在获取消息时候，通过 Tag HashCode 的对比，从 CommitLog 读取对应消息。由于哈希冲突实际上是不可避免的，消息在从 CommitLog 中拉取之后被消费之前，仍然会进行 Tag 的完整对比，以消除潜在哈希冲突问题</p>
<h2 id="携带-MessageKey-来发送和查询"><a href="#携带-MessageKey-来发送和查询" class="headerlink" title="携带 MessageKey 来发送和查询"></a>携带 MessageKey 来发送和查询</h2><p>其实这部分内容并不属于服务端消息过滤的功能，但是也为我们提供了一种较精确的查询指定消息的功能。在发送消息之前可以为消息设定指定的 Key，通常这个 Key 是在业务层面是唯一的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Message msg = <span class="keyword">new</span> Message(<span class="string">"Topic"</span>, <span class="string">"Tag"</span>, <span class="string">"Content"</span>.getBytes());</span><br><span class="line">msg.setKey(uniqueKey);</span><br></pre></td></tr></table></figure>
<p>尽管 Broker 不会对消息进行 Key 相关的过滤，但是会为消息定制相应的索引。看一下索引格式：</p>
<ul>
<li>Key HashCode：4 个字节的 Key 的哈希，用来快速检索</li>
<li>CommitLog Offset：8 个字节来保存 CommitLog 中的偏移量</li>
<li>Timestamp：使用 4 个字节记录消息存储时间和产生时间的时间差</li>
<li>Next Index Offset：使用 4 个字节来记录下一索引的偏移量<br>在存储 Key 相应的索引时候，其实分了多个哈希桶来（Slot）存储，也就是相对 Key 进行了两次散列。怎么解决哈希冲突？因为索引结构中保存了 Key 的哈希，所以对于哈希值不同而模数相同的 Key 在查询时候可以直接区分开来。对于哈希值相等但是 Key 本身不相等的情况，客户端继续做一次 Key 比较来进行筛选。<br>一般应用中进行消息过滤使用 Tag，而使用命令行工具 mqadmin 做运维时查询特定 Key 的消息，用法：<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mqadmin queryMsgByKey -k &lt;Key&gt; -n &lt;NamesrvAddr&gt; -t &lt;Topic&gt; -f &lt;endTime&gt;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="使用-MessageId-来查询消息"><a href="#使用-MessageId-来查询消息" class="headerlink" title="使用 MessageId 来查询消息"></a>使用 MessageId 来查询消息</h2><p>每次消息成功发送后，都会生产一个 <strong>MsgId</strong> 和 <strong>OffsetMsgId</strong>，来标识这条消息：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Message msg = <span class="keyword">new</span> Message(<span class="string">"Topic"</span>, <span class="string">"Tag"</span>, <span class="string">"Content"</span>.getBytes());</span><br><span class="line">SendResult result = producer.send(msg);</span><br><span class="line"><span class="comment">// producer 产生的 id</span></span><br><span class="line">String msgId = result.getMsgId();</span><br><span class="line"><span class="comment">// broker 产生的 id</span></span><br><span class="line">String offsetMsgId = result.getOffsetMsgId();</span><br></pre></td></tr></table></figure>
<ul>
<li>对于 MsgId，由 producer ip + pid + MessageClientIDSetter.class.getClassLoader().hashCode() + time + counter 组成</li>
<li>而对于 OffsetMsgId，由 broker ip + CommitLog Offset 组成，可以精确地定位消息存储的位置</li>
</ul>
<p>同时我们可以使用运维工具 mqadmin 针对 OffsetMsgId 进行检索</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mqadmin queryMsgById -n &lt;NamesrvAddr&gt; -I &lt;OffsetMsgId&gt;</span><br></pre></td></tr></table></figure>

<h2 id="使用自定义属性和类-SQL-过滤"><a href="#使用自定义属性和类-SQL-过滤" class="headerlink" title="使用自定义属性和类 SQL 过滤"></a>使用自定义属性和类 SQL 过滤</h2><p>在发送消息前，我们可以为消息设置自定义的属性：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Message msg = <span class="keyword">new</span> Message(<span class="string">"Topic"</span>, <span class="string">"Tag"</span>, <span class="string">"Content"</span>.getBytes());</span><br><span class="line">msg.putUserProperty(<span class="string">"p1"</span>, <span class="string">"v1"</span>);</span><br><span class="line">msg.putUserProperty(<span class="string">"p2"</span>, <span class="string">"v2"</span>);</span><br></pre></td></tr></table></figure>
<p>在服务端进行消费时候，可以针对自定义属性，利用类 SQL 的表达式来进行消息的进一步筛选：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">consumer.subscribe(<span class="string">"Topic"</span>, MessageSelector.bySql(<span class="string">"p1 = v1"</span>);</span><br></pre></td></tr></table></figure>
<p>使用这样的方式进行过滤，需要 Broker 先从 CommitLog 中取出消息，得到消息中的自定义属性进行对应的计算。理所当然的，功能很强大，但是效率没有使用 Tag 的过滤方式高。</p>
<h3 id="对于表达式的语法支持如下："><a href="#对于表达式的语法支持如下：" class="headerlink" title="对于表达式的语法支持如下："></a>对于表达式的语法支持如下：</h3><ul>
<li>对比操作：<ul>
<li>数字：&gt;, &lt;, &lt;=, &gt;=, =, BETWEEN</li>
<li>字符串：=, &lt;&gt;, IN</li>
<li>空值判断：IS NULL, IS NOT NULL</li>
<li>逻辑判断：AND, OR, NOT</li>
</ul>
</li>
<li>数据类型：<ul>
<li>数字：123，456</li>
<li>字符串：’abc’, ‘def’, 必须使用单引号</li>
<li>空值：NULL</li>
<li>布尔：TRUE，FALSE</li>
</ul>
</li>
</ul>
<h2 id="使用自定义代码和-Filter-Server"><a href="#使用自定义代码和-Filter-Server" class="headerlink" title="使用自定义代码和 Filter Server"></a>使用自定义代码和 Filter Server</h2><p>对于 Filter Server，事实上实在 Broker 所在服务器启动了多个类似中转代理的进程，这几个进程负责充当 Consumer 从 Broker 上拉取代码，使用用户上传的 Java 代码进行过滤，最后传送给消费者。<br>这个中转代理会和 Broker 本身争抢 CPU 资源，需要按需求谨慎使用；同时用于过滤的代码需要严格的审查，避免可能影响 Broker 宕机的风险操作。这个过滤操作只支持 PushConsumer<br>使用流程：</p>
<ol>
<li>启动 Broker 时指定 <code>filterServerNums=&lt;n&gt;</code>，当然使用配置文件也可以。n 的数量就是中转代理 FilterServer 的进程数</li>
<li>实现 <code>org.apache.rocketmq.common.filter.MessageFilter</code> 接口，定制过滤逻辑</li>
<li>接收消息：<pre><code class="java">PushConsumer.subscribe(<span class="keyword">final</span> String topic, <span class="keyword">final</span> String fullClassName, <span class="keyword">final</span> String filterClassSource)</code></pre>
filterClassSource 是前一步 MessageFilter 接口实现的源码，必须使用 utf-8 编码。这会在 Consumer 启动时将过滤逻辑上传至 Broker</li>
</ol>
<p>参考：</p>
<ol>
<li>MessageId 生成解读 <a href="https://www.cnblogs.com/linlinismine/p/9184917.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/linlinismine/p/9184917.html</a></li>
</ol>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 日志设置</title>
    <url>/2018/08/RocketMQ-%E6%97%A5%E5%BF%97%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="日志配置文件位置"><a href="#日志配置文件位置" class="headerlink" title="日志配置文件位置"></a>日志配置文件位置</h2><p>RocketMQ 日志基于 slf4j 实现，支持 Logback、Log4j。如果需要指定日志的配置文件的位置有三种方式：</p>
<ul>
<li>环境变量：<br><code>ROCKETMQ_CLIENT_LOG_CONFIGFILE=&lt;custom-file&gt;</code></li>
<li>启动参数：<br><code>rocketmq.client.log.configFile=&lt;customer-file&gt;</code>，作为 JVM 变量，启动时时需要增加 -D 标识，优先级也比环境变量更高</li>
<li>作为 Java 实现，日志位置信息是通过 <code>System.getProperty()</code> 或者 <code>System,getenv()</code> 得到的，所以可以在程序入口 <code>System.setProperty(“rocketmq.client.log.configFile”, customer_file)</code> 来配置</li>
</ul>
<a id="more"></a>

<h2 id="日志相关系统变量"><a href="#日志相关系统变量" class="headerlink" title="日志相关系统变量"></a>日志相关系统变量</h2><ul>
<li><code>rocketmq.client.log.loadconfig</code><br>默认 true，是否加载指定配置文件，当设置为 false 时，RocketMQ 客户端会会使用应用本身的日志配置。这可能反而是最简单的日志配置方式</li>
<li><code>rocketmq.client.log4j.resource.fileName</code>、<code>rocketmq.client.logback.resource.fileName</code>、 <code>rocketmq.client.log4j2.resource.fileName</code><br>三种日志框架的的配置文件名，默认值分别为 log4j_rocketmq_client.xml、logback_rocketmq_client.xml、log4j2_rocketmq_client.xml</li>
<li><code>rocketmq.client.log.configFile</code><br>日志配置文件路径，上述。如果使用了自定义的日志配置文件，通常你不再需要设置以下的变量了</li>
<li><code>rocketmq.client.logRoot</code><br>RocketMQ 日志信息默认存放日志为：$USER_HOME/Logs/rocketmqLogs，通过改变此变量可以变更日志路径</li>
<li><code>rocketmq.client.logLevel</code><br>日志输出级别，默认 INFO</li>
<li><code>rocketmq.client.logFileMaxIndex</code><br>滚动窗口的索引最大值，默认 10</li>
</ul>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ Producer 摘要</title>
    <url>/2018/08/RocketMQ-Producer-%E6%91%98%E8%A6%81/</url>
    <content><![CDATA[<p>上一篇介绍完了 RocketMQ 消费者的默认实现，现在来瞅一瞅生产者的用法。</p>
<h2 id="设置必要的属性"><a href="#设置必要的属性" class="headerlink" title="设置必要的属性"></a>设置必要的属性</h2><p>同样的，是 DefaultMQProducer，新建实例之后，在使用生产者发送消息之前，需要初始化几个属性：</p>
<ul>
<li><code>InstanceName</code> 实例名称<br>这是为了当一个 JVM 上启动了多个生产者时，区分不同的生产者实例，系统默认名称为 DEFAULT</li>
<li><code>RetryTimesWhenSendFailed</code> 重试次数<br>当消息投递失败时，有可能是因为网络原因，可以设置多投递几次减少丢消息的情况。<br>很多实用者在使用时，为了避免重复的消息设置不重试是不正确的做法：因为 RocketMQ 本身并不保证消息的不重复，作为客户端对消息进行幂等处理是必要的。而在次前提下，对发送失败的场景拒绝重发，不仅对避免重复消息没有任何意义，同时也增加了消息的丢失的可能。</li>
<li><code>NamesrvAddr</code><br>需要 NameServer 的地址，写法和 Consumer 一致<a id="more"></a>

</li>
</ul>
<h2 id="消息发送方式和投递结果"><a href="#消息发送方式和投递结果" class="headerlink" title="消息发送方式和投递结果"></a>消息发送方式和投递结果</h2><h3 id="发送方式"><a href="#发送方式" class="headerlink" title="发送方式"></a>发送方式</h3><ul>
<li>同步发送：<code>Producer.send(Message message)</code></li>
<li>异步发送：<code>Producer.send(Message message, SendCallback callback)</code></li>
</ul>
<h3 id="发送结果"><a href="#发送结果" class="headerlink" title="发送结果"></a>发送结果</h3><p>对于消息发送的结果，存在四中可能返回的状态。而且在不同的配置方式下，意义可能有所不同</p>
<ul>
<li><strong><code>SEND_OK</code></strong><br>发送成功，标志着消息已经成功被发送到 Broker。（这时候不一定意味着主从复制完成或者刷盘完成）</li>
<li><strong><code>FLUSH_DISK_TIMEOUT</code></strong><br>刷盘时间超时，只有在刷盘策略为 <code>SYNC_FLUSH</code> 时才可能出现</li>
<li><strong><code>FLUSH_SLAVE_TIMEOUT</code></strong><br>主从同步时间超时，只有在主备形式下使用 <code>SYNC_MASTER</code> 才可能出现</li>
<li><strong><code>SLAVE_NOT_AVAILABLE</code></strong><br>从机缺失，只有在主备形式下使用 <code>SYNC_MASTER</code> 才可能出现，类似于 FLUSH_SLAVE_TIMEOUT<br>对于不同的业务场景具体需求，如何处理消息发送的结果是程序质量的一个重要考量点</li>
</ul>
<h2 id="特殊的消息"><a href="#特殊的消息" class="headerlink" title="特殊的消息"></a>特殊的消息</h2><h3 id="延迟消息"><a href="#延迟消息" class="headerlink" title="延迟消息"></a>延迟消息</h3><p>RocketMQ 支持延迟消息，Broker 收到消息后并不会立即投递，而是等待一段时间后再讲消息送出去。</p>
<ul>
<li>使用方式：在消息发送前执行 <code>Message.setDelayTimeLevel(int level)</code></li>
<li>延迟等级：默认 1s/5s/10s/30s/1m/2m/3m/4m/5m/6m/7m/8m/9m/10m/20m/30m/1h/2h，索引 1 开始<br>尽管 RocketMQ 的延迟消息不支持任意精度，但是各等级的延迟是可以预设的，更改配置文件即可</li>
</ul>
<h3 id="队列选择"><a href="#队列选择" class="headerlink" title="队列选择"></a>队列选择</h3><p>对于一个 Topic 通常有多个 MessageQueue 来接收消息，默认情况下 Producer 轮流向各个 MessageQueue 发送消息，而 Consumer 根据默认的负载策略进行消费，所以无法明确对应 Producer 的消息是哪个 Consumer 消费。在需要指定特定 MessageQueue 来投递消息时，可以实现 <code>MessageQueueSelector</code> 接口，定制选择逻辑；发送时选择带有选择器的重载方法即可</p>
<h3 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h3><p>介绍事务消息是必要的，但是并不推荐使用。因为事务消息会造成磁盘脏页，影响磁盘性能，在 4.x 版本中已经移除，需要使用时需要手动根据顶层接口实现。简单的说，RocketMQ 的事务消息流程如下：</p>
<ol>
<li>向 Broker 发送消息（消息状态为未确认状态）</li>
<li>Broker 对收到的消息完成持久化，返回成功状态。发送的第一阶段结束</li>
<li>执行本地逻辑</li>
<li>事务消息的结束<ul>
<li>本地逻辑结束，客户端向 Broker 确认消息<ul>
<li>commit：提交，该消息将会被 Broker 进行投递</li>
<li>rollback：回滚，Broker 会删除之前接收到的消息</li>
</ul>
</li>
<li>超过一定时间，服务端对客户端发起回查请求<br>Producer 对回查请求返回 commit 或者 rollback 的响应。如果此时发送消息的 Producer 无法访问，回查请求会发送给同一 ProducerGroup 内的其他 Producer</li>
</ul>
</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://github.com/apache/rocketmq" target="_blank" rel="external nofollow noopener noreferrer">RocketMQ on GitHub</a></li>
<li>《RocketMQ 实战与原理解析》机械工业出版社 杨开元</li>
</ul>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ Consumer 摘要</title>
    <url>/2018/08/RocketMQ-Consumer-%E6%91%98%E8%A6%81/</url>
    <content><![CDATA[<p>结束了对 RocketMQ 组件的初步理解以及配置的简单设定，可以对 RocketMQ 仔细研究一番了。先来看看 RocketMQ 的消费者实现，以及服务端是如何处理消费者客户端的请求，把消息送出去的。</p>
<p>RocketMQ 对于消费者客户端，支持推模型和拉模型。对于推模型，由消息服务端作为主动方，向客户端推送消息（尽管其本质是一个长轮询式的拉模型实现）；而拉模型由客户端主动拉取消息。</p>
<a id="more"></a>

<h2 id="PushConsumer"><a href="#PushConsumer" class="headerlink" title="PushConsumer"></a>PushConsumer</h2><h3 id="客户端的实现："><a href="#客户端的实现：" class="headerlink" title="客户端的实现："></a>客户端的实现：</h3><p><code>DefaultMQPushConsumerImpl</code> 是客户端的一个默认实现，可以从 <code>pullMessage()</code> 方法切入，观察它的实现。</p>
<h3 id="基本要素："><a href="#基本要素：" class="headerlink" title="基本要素："></a>基本要素：</h3><p>以下几个属性，不仅仅是推模型的重要配置，同时也称得上是每个客户端的标配。</p>
<ul>
<li><strong>NameServerAddr</strong><br>指定 NameServer 地址是必要的，可以通过客户端 API 设置（使用 <code>;</code> 分割多个地址），或者使用环境变量 <code>NAMESRV_ADDR</code></li>
<li><strong>ConsumerGroup</strong><br>将多个消费者组织一起，提高并发，需要配合 <code>MessageModel</code> 属性一起使用<ul>
<li><strong>MessageModel</strong><br>消息模式分为两种，<strong>集群模式</strong>：<strong>Clustering</strong>；<strong>广播模式</strong>：<strong>Broadcasting</strong><ul>
<li><strong>Clustering</strong>：集群模式，所订阅 Topic 下的消息，每一条只会被同一 ConsumerGroup 下的一个消费者所消费，达到负载均衡的目的</li>
<li><strong>Broadcasting</strong>：广播模式，同一 ConsumerGroup 下的每一个 Consumer 都会消费到所订阅 Topic 下的全部消息。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Topic</strong><br>消息类型主题，作为不同消息的标识，决定了消费者订阅哪些消息。Topic 默认是可以由客户端创建的，生产环境下通常改权限被关闭，需要使用 mqadmin 工具来初始化可用的 Topic<ul>
<li><strong>Tag</strong><br>Tag 可以进一步过滤消费需要订阅的消息，在 Java 客户端 API 下，使用 <code>null</code> 或者 <code>*</code> 来消费所有 Tag 类型，需要具体指定时可以使用 <code>||</code> 来分割多个 Tag</li>
</ul>
</li>
</ul>
<h3 id="服务端推送方式："><a href="#服务端推送方式：" class="headerlink" title="服务端推送方式："></a>服务端推送方式：</h3><p>消费者的推模型是通过长轮询实现的，因为完全的推模型方式会使得服务端增加许多压力，明显的降低效率，同时也会因为各客户端消费能力不足的问题造成隐患。Broker 服务端在处理客户端请求时如果发现没有消息，会休眠一小会-短轮询间隔（<code>shortPollingTimeMills</code>），重复循环，直到超过最大等待时间（<code>brokerSuspendMaxTimeMills</code>），在此期间内的收到消息会立即发送给客户端，达到“推”的效果</p>
<h3 id="客户端流量控制："><a href="#客户端流量控制：" class="headerlink" title="客户端流量控制："></a>客户端流量控制：</h3><p>客户端维护了一个线程池来接受服务端“推”来的消息，针对每个 <code>MessageQueue</code> 都有使用一个 <code>ProcessQueue</code> 来保存快照状态和处理逻辑。<code>ProcessQueue</code> 主要由一个 TreeMap 和读写锁组成</p>
<ul>
<li><code>ProcessQueue.lockTreeMap</code> 保存了所有获取后还没有被消费的消息<ul>
<li>Key：MessageQueue‘s offset</li>
<li>Value：消息内容引用</li>
</ul>
</li>
<li><code>DefaultMQPushConsumerImpl.pullMessage()</code> 会检查以下每个属性，任意属性超过阈值会暂缓拉取动作。由于通过 ProcessQueue 的信息来比较，检查域是每个 Queue<ul>
<li><code>cachedMessageCount</code><br>检查当前缓存的但是未消费的消息数量是否大于设定值（<code>pullThresholdForQueue</code>，默认 1000）</li>
<li><code>cachedMessageSizeInMiB</code><br>同上，检查队列中消息缓存的大小（<code>pullThresholdSizeForQueue</code>，默认 100MiB）</li>
<li>maxSpan<br>检查 <code>ProcessQueue</code> 中未消费消息的 offset 跨度（<code>consumeConcurrentlyMaxSpan</code>，默认 200），<em>在顺序消费时不检查</em></li>
</ul>
</li>
</ul>
<h2 id="PullConsumer"><a href="#PullConsumer" class="headerlink" title="PullConsumer"></a>PullConsumer</h2><h3 id="客户端的实现：-1"><a href="#客户端的实现：-1" class="headerlink" title="客户端的实现："></a>客户端的实现：</h3><p>初次接触，可以从这几个方法了解 PullConsumer 的消息拉取思路，并从官方的几个例子中了解一些常用的处理方式。</p>
<ol>
<li>前置操作<ul>
<li><code>DefaultMQPullConsumerImpl.fetchSubscribeMessageQueues()</code></li>
<li><code>DefaultMQPullConsumerImpl.fetchConsumerOffset()</code></li>
<li><code>DefaultMQPullConsumerImpl.fetchMessageQueuesInBalance()</code></li>
</ul>
</li>
<li>拉取动作<ul>
<li><code>DefaultMQPullConsumerImpl.pull()</code></li>
<li><code>DefaultMQPullConsumerImpl.pullBlockIfNotFound()</code></li>
</ul>
</li>
</ol>
<h3 id="客户端额外操作："><a href="#客户端额外操作：" class="headerlink" title="客户端额外操作："></a>客户端额外操作：</h3><p>在使用 PullConsumer 时候，通常使用需要额外关心 <code>MessageQueue</code> 和 <strong>offset</strong> 等一些要素，灵活的封装可以带来更多的自主性。<br>以 <code>fetchSubscribeMessageQueues()</code> 和 <code>pull()</code> 方法说明几个要素：</p>
<ul>
<li><strong>MessageQueue</strong><br>一个 Topic 下通常会使用多个 MessageQueue，如果需要获取全部消息，需要遍历返回的所有队列。特殊情况下可以针对特定队列消费</li>
<li><strong>Offsetstore</strong><br>使用者需要手动记录和操作消息偏移量，随着消息消费而改变它，需要额外注意他的持久化，正确的偏移量是准确消费的前提</li>
<li><strong>PullStatus</strong><br>针对某队列的拉取动作结束，会返回相应状态，使用者需要针对不同状态采取不同的动作<ul>
<li><code>FOUND</code></li>
<li><code>NO_MATCHED_MSG</code></li>
<li><code>NO_NEW_MSG</code></li>
<li><code>OFFSET_ILLEGAL</code></li>
</ul>
</li>
<li><code>shutDown()</code><br>关闭操作会进行保存 offset 的操作，在 NameServer 注销客户端的操作等。对于保存的 offset 可以通过 OffsetStore 对象获取，启动时加载。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://github.com/apache/rocketmq" target="_blank" rel="external nofollow noopener noreferrer">RocketMQ on GitHub</a></li>
<li>《RocketMQ 实战与原理解析》机械工业出版社 杨开元</li>
</ul>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RokcetMQ 配置项</title>
    <url>/2018/08/RocketMQ-%E9%85%8D%E7%BD%AE%E9%A1%B9/</url>
    <content><![CDATA[<p>RocketMQ 的配置分为两部分，一者是 JVM 的配合，另一者则是对 Broker 应用本身的参数配置。<br>在初次接触时候，除了 RocketMQ 本身的一些特性，同时也难免会被一些配置给迷惑或者踩坑，这里来看一下通常的配置点。</p>
<a id="more"></a>

<h2 id="Broker-JVM-配置"><a href="#Broker-JVM-配置" class="headerlink" title="Broker JVM 配置"></a>Broker JVM 配置</h2><p>JVM 的配置默认不需要修改，只需要根据硬件情况调整相应的堆栈内存和对外内存的占用量即可。附上启动时的 JVM 配置脚本片段：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-OmitStackTraceInFastThrow"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+AlwaysPreTouch"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:MaxDirectMemorySize=15g"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-UseLargePages -XX:-UseBiasedLocking"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -Djava.ext.dirs=$&#123;BASE_DIR&#125;/lib"</span><br><span class="line"><span class="meta">#</span><span class="bash">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"</span></span></span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; $&#123;JAVA_OPT_EXT&#125;"</span><br><span class="line">JAVA_OPT="$&#123;JAVA_OPT&#125; -cp $&#123;CLASSPATH&#125;"</span><br></pre></td></tr></table></figure>
<p>需要额外关注的点在于：</p>
<ul>
<li><code>-Xms8g -Xmx8g -Xmn4g</code> 默认 Broker 需要 8g 的堆内存，不要轻易在自己的笔记本上运行哦 😂</li>
<li><code>-XX:MaxDirectMemorySize=15g</code> 默认的最大堆外内存为 15g，nio 通过内存映射文件所提高 IO 效率而用。</li>
<li><code>JAVA_OPT_EXT</code> 该环境变量可以追加和替换原有的配置</li>
</ul>
<h2 id="Broker-应用配置"><a href="#Broker-应用配置" class="headerlink" title="Broker 应用配置"></a>Broker 应用配置</h2><h3 id="自定义配置启动"><a href="#自定义配置启动" class="headerlink" title="自定义配置启动"></a>自定义配置启动</h3><p>启动 Broker 时可以自定义配置：<code>sh bin/mqbroker -c CONFIG.properties</code></p>
<h3 id="配置可选项"><a href="#配置可选项" class="headerlink" title="配置可选项"></a>配置可选项</h3><ul>
<li>获取可配置项的列表：<code>sh bin/mqbroker -m</code></li>
<li>获取配置项以及默认值：<code>sh bin/mqbroker -p</code></li>
<li>源码中配置类：<code>BrokerConfig</code> / <code>NettyServerConfig</code> / <code>NettyClientConfig</code> / <code>MessageStoreConfig</code></li>
</ul>
<h3 id="配置参数介绍"><a href="#配置参数介绍" class="headerlink" title="配置参数介绍"></a>配置参数介绍</h3><p>介绍几个常用的，或者说通常需要配置的选项。</p>
<ul>
<li><code>namesrvAddr=IP:PORT;IP:PORT</code><br>配置 NameServer 的地址，多个地址间使用 <code>;</code> 隔开，该选项没有默认值，可以启动时通过 <code>-n</code> 参数设置</li>
<li><code>brokerClusterName=DefaultCluster</code><br>配置 RocketMQ 集群的名称，默认为 DefaultCluster</li>
<li><code>brokerName=broker-a</code><br>Broker 的名称，在同一 NameServer 群下，只有使用相同的 brokerName 的 Broker 实例才可以组成主从关系</li>
<li><code>brokerId=0</code><br>在一个 Broker 群下（都使用了同样的 brokerName），所有实例通过 brokerId 来区分主从，主机只有一个：<code>brokerId=0</code>（默认）</li>
<li><code>fileReservedTime=48</code><br>消息数据在磁盘上保存的时间，单位：小时，默认：48</li>
<li><code>deleteWhen=04</code><br>在指定的时间删除那些超过了保存期限的消息，标识小时数，默认：凌晨 4 时</li>
<li><code>brokerRole=SYNC_MASTER</code><br>有三种选项，前两者主要描述 Broker 实例间的同步机制<ul>
<li><code>SYNC_MASTER</code><br>Broker Master 的选项，消息同步给 Slave 之后才返回发送成功状态</li>
<li><code>ASYNC_MASTER</code><br>Broker Master 的选项，主从间消息同步异步处理</li>
<li><code>SLAVE</code><br>Broker Slave 的选项（没得选）</li>
</ul>
</li>
<li><code>flushDiskType=ASYNC_FLUSH</code><br>有两种选项，分别同步或异步的刷盘策略<ul>
<li><code>SYNC_FLUSH</code><br>消息只有在真正写入磁盘之后才会返回成功状态，牺牲性能，但可以确保不丢失消息</li>
<li><code>ASYNC_FLUSH</code><br>异步刷盘，消息写入 page_cache 后即返回成功</li>
</ul>
</li>
<li><code>brokerIP1=127.0.0.1</code><br>设置 Broker 对外暴露的 IP，通常 Broker 启动时会自动探测，但是由于容器环境或者多网卡的影响，通常需要手动设置。需要多个暴露 IP 时，可以使用 <code>brokerIP2/3/4/...</code> 的方式配置</li>
<li><code>listenPort=10911</code><br>Broker 实例监听的端口号</li>
<li><code>storePathRootDir=/home/rocketmq/store-a</code><br>存储消息和一些配置的根目录</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://github.com/apache/rocketmq" target="_blank" rel="external nofollow noopener noreferrer">RocketMQ on GitHub</a></li>
<li>《RocketMQ 实战与原理解析》机械工业出版社 杨开元</li>
</ul>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 配置探索</title>
    <url>/2018/07/RocketMQ-%E9%85%8D%E7%BD%AE%E6%8E%A2%E7%B4%A2/</url>
    <content><![CDATA[<p>目前被广泛使用的 MQ 有很多，包括 ActiveMQ，Kafka，RabbitMQ，RocketMQ 等等，它们各有长短。而近期所在项目选择了 RocketMQ 作为消息中间件，此前并未系统地了解研究，所以趁此机会整理了一些笔记和想法。</p>
<a id="more"></a>

<h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><p>简单地说一下在这么多消息中间件中的选型优势。作为阿里的开源项目，想必还是可靠的，尤其是经受过双十一的考验令人信服。</p>
<ul>
<li>支持严格的消息顺序；</li>
<li>支持 Topic 与 Queue 两种模式；</li>
<li>亿级消息堆积能力；</li>
<li>比较友好的分布式特性；</li>
<li>同时支持 Push 与 Pull 方式消费消息；</li>
</ul>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li><strong>Producer</strong>：消息生产者，生产消息。</li>
<li><strong>Consumer</strong>：消息消费者，消费消息。<ul>
<li><strong>Pull Consumer</strong>：消费者拉模型的实现。通过与 Broker 建立长连接，从中主动拉取消息。</li>
<li><strong>Push Consumer</strong>：消费者推模型的实现。本质仍然是建立长连接，但是通过注册监听器，在收到消息时回调监听方法。</li>
</ul>
</li>
<li><strong>Producer Group</strong>：生产者集合，通常包含发送逻辑一致的消费者，影响事务消息的流程。</li>
<li><strong>Consumer Group</strong>：消费者集合，通常包含消费逻辑一致的消费者，影响着负载均衡和集群消息。</li>
<li><strong>Name Server</strong>：注册服务器，可以由一到多个近乎无状态的节点构成，扮演者类似 Zookeeper 的角色。Broker 向其中注册，而 Producer 和 Consumer 向其中拉取 Broker 地址。</li>
<li><strong>Broker</strong>：核心组件，保存和转发消息。</li>
</ul>
<p>拓扑结构如下：<br><img src="/images/rocketmq-net.png" alt="RocketMQ Network"></p>
<h2 id="初次使用"><a href="#初次使用" class="headerlink" title="初次使用"></a>初次使用</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>RocketMQ 是纯 Java 语言的实现，你可以从 Github 上<a href="https://github.com/apache/rocketmq" target="_blank" rel="external nofollow noopener noreferrer">下载</a>源码并使用 Maven 进行编译，当然也可以从<a href="http://rocketmq.apache.org/" target="_blank" rel="external nofollow noopener noreferrer">官网入口</a>下载。</p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>第一次启动，简单地测试一下效果，进入 bin 目录，使用 nohup 启动一下 NameService：</p>
<pre><code>nohup ./mqnamesrv -n 127.0.0.1:9876 &amp;</code></pre><p>然后启动一下 Broker：</p>
<pre><code>nohup ./mqbroker -n 127.0.0.1:9876 &amp;</code></pre><p>还有一个 mqadmin 也是常用的工具，包含的管理员常用的功能，包含查看集群列表，查看、删除主题等，可以直接通过 <code>./mqadmin</code> 获得帮助。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>在 RocketMQ 顺利启动之后，进行一下测试吧，快速的体验一把。<br>从 MavenRepository 找到对应的 RocketMQ 客户端：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.rocketmq/rocketmq-client --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.rocketmq<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>rocketmq-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>或者打开刚才从 Github 上下载的源码，example 模块下提供了许多测试用例，附上略微改动的生产者和消费者代码：</p>
<ul>
<li>生产者<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">    DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">"ProducerGroupName"</span>);</span><br><span class="line">    producer.setNamesrvAddr(<span class="string">"127.0.0.1:9876"</span>);</span><br><span class="line">    producer.setInstanceName(<span class="string">"p001"</span>);</span><br><span class="line">    <span class="comment">// 可以设定失败重试次数</span></span><br><span class="line">    producer.setRetryTimesWhenSendFailed(<span class="number">3</span>);</span><br><span class="line">    producer.start();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(</span><br><span class="line">	    	<span class="string">"TopicTest1"</span>,</span><br><span class="line">                <span class="string">"TagA"</span>,</span><br><span class="line">                <span class="string">"key113"</span>,</span><br><span class="line">                <span class="string">"Hello world"</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            System.out.printf(<span class="string">"%s%n"</span>, sendResult);</span><br><span class="line"></span><br><span class="line">            QueryResult queryMessage =</span><br><span class="line">                producer.queryMessage(<span class="string">"TopicTest1"</span>, <span class="string">"key113"</span>, <span class="number">10</span>, <span class="number">0</span>, System.currentTimeMillis());</span><br><span class="line">            <span class="keyword">for</span> (MessageExt m : queryMessage.getMessageList()) &#123;</span><br><span class="line">                System.out.printf(<span class="string">"%s%n"</span>, m);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    producer.shutdown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>消费者<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, MQClientException </span>&#123;</span><br><span class="line"></span><br><span class="line">    DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">"ConsumerGroupName"</span>);</span><br><span class="line">    <span class="comment">// 指定 NameServer 的地址，多个 NameServer 使用 ; 隔开</span></span><br><span class="line">    consumer.setNamesrvAddr(<span class="string">"127.0.0.1:9876"</span>);</span><br><span class="line">    consumer.setInstanceName(<span class="string">"c001"</span>);</span><br><span class="line">    <span class="comment">// 指定订阅的 Topic 以及 Tag，多个 Tag 使用 || 分开，* 代表全部 Tag</span></span><br><span class="line">    consumer.subscribe(<span class="string">"TopicATest1"</span>, <span class="string">"TagA"</span>);</span><br><span class="line">    <span class="comment">// 可以设定开始消费的位置，仅针对 Push Consumer</span></span><br><span class="line">    consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">    <span class="comment">// 可以设定批量消费数量，默认 1，不保证每次的数量，近针对 Push Consumer</span></span><br><span class="line">    consumer.setConsumeMessageBatchMaxSize(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                System.out.println(<span class="keyword">new</span> String(msg.getBody()));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;  </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    consumer.start();</span><br><span class="line">    System.out.println(<span class="string">"Consumer Started."</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
动手运行一下吧。</li>
</ul>
<h2 id="关于配置"><a href="#关于配置" class="headerlink" title="关于配置"></a>关于配置</h2><p>事实上，大多数小伙伴在 RocketMQ 启动时都明显能感觉电脑卡卡的，是因为 RocketMQ 默认需求的内存太大了。那么，如何查看和修订所需要的配置呢？<br>之前我们通过 <code>./mqbroker</code> 启动了 Broker，那么来看一下 mqbroker 的脚本，注意脚本末尾的命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 省略 ROCKETMQ_HOME 的配置</span></span><br><span class="line">sh <span class="variable">$&#123;ROCKETMQ_HOME&#125;</span>/bin/runbroker.sh org.apache.rocketmq.broker.BrokerStartup <span class="variable">$@</span></span><br></pre></td></tr></table></figure>
<p>这里将启动命令转移给了 runbroker.sh 进行执行。</p>
<h3 id="JVM-参数配置"><a href="#JVM-参数配置" class="headerlink" title="JVM 参数配置"></a>JVM 参数配置</h3><p>既然如此，继续查看一下 runbroker.sh：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="comment">#===========================================================================================</span></span><br><span class="line"><span class="comment"># Java Environment Setting</span></span><br><span class="line"><span class="comment">#===========================================================================================</span></span><br><span class="line">error_exit ()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"ERROR: <span class="variable">$1</span> !!"</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[ ! -e <span class="string">"<span class="variable">$JAVA_HOME</span>/bin/java"</span> ] &amp;&amp; JAVA_HOME=<span class="variable">$HOME</span>/jdk/java</span><br><span class="line">[ ! -e <span class="string">"<span class="variable">$JAVA_HOME</span>/bin/java"</span> ] &amp;&amp; JAVA_HOME=/usr/java</span><br><span class="line">[ ! -e <span class="string">"<span class="variable">$JAVA_HOME</span>/bin/java"</span> ] &amp;&amp; error_exit <span class="string">"Please set the JAVA_HOME variable in your environment, We need java(x64)!"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME</span><br><span class="line"><span class="built_in">export</span> JAVA=<span class="string">"<span class="variable">$JAVA_HOME</span>/bin/java"</span></span><br><span class="line"><span class="built_in">export</span> BASE_DIR=$(dirname <span class="variable">$0</span>)/..</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$&#123;BASE_DIR&#125;</span>/conf:<span class="variable">$&#123;CLASSPATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#===========================================================================================</span></span><br><span class="line"><span class="comment"># JVM Configuration</span></span><br><span class="line"><span class="comment">#===========================================================================================</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms8g -Xmx8g -Xmn4g"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:-OmitStackTraceInFastThrow"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:+AlwaysPreTouch"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:MaxDirectMemorySize=15g"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:-UseLargePages -XX:-UseBiasedLocking"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -Djava.ext.dirs=<span class="variable">$&#123;BASE_DIR&#125;</span>/lib"</span></span><br><span class="line"><span class="comment">#JAVA_OPT="$&#123;JAVA_OPT&#125; -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> <span class="variable">$&#123;JAVA_OPT_EXT&#125;</span>"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -cp <span class="variable">$&#123;CLASSPATH&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">numactl --interleave=all <span class="built_in">pwd</span> &gt; /dev/null 2&gt;&amp;1</span><br><span class="line"><span class="keyword">if</span> [ $? -eq 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">	<span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$RMQ_NUMA_NODE</span>"</span> ] ; <span class="keyword">then</span></span><br><span class="line">		numactl --interleave=all <span class="variable">$JAVA</span> <span class="variable">$&#123;JAVA_OPT&#125;</span> <span class="variable">$@</span></span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		numactl --cpunodebind=<span class="variable">$RMQ_NUMA_NODE</span> --membind=<span class="variable">$RMQ_NUMA_NODE</span> <span class="variable">$JAVA</span> <span class="variable">$&#123;JAVA_OPT&#125;</span> <span class="variable">$@</span></span><br><span class="line">	<span class="keyword">fi</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	<span class="variable">$JAVA</span> <span class="variable">$&#123;JAVA_OPT&#125;</span> <span class="variable">$@</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>通过这个文件可以获得很多信息：</p>
<ul>
<li>RocketMQ 的 JVM 配置信息<ul>
<li>需求的内存空间达到了 8g，声明的最大堆外内存达到了 15g，这就是电脑变得卡卡的的原因了。</li>
<li>可以在启动时配置 <strong>JAVA_OPT_EXT</strong> 变量来配置额外的参数或者覆盖默认配置。</li>
</ul>
</li>
<li>结合 mqbroker.sh 可以发现，最终使用了 BrokerStartup 来启动 RocketMQ，命令行中的参数同时会被传递。</li>
</ul>
<h3 id="Broker-实例配置"><a href="#Broker-实例配置" class="headerlink" title="Broker 实例配置"></a>Broker 实例配置</h3><p>那么接下来就去 BrokerStartup 查看一下 RocketMQ 的启动过程。由于这个文件实在是太过冗长，这里不再贴出，感兴趣的小伙伴请自行查看。在这个文件中，主要对命令行中几个具体参数进行了解析：</p>
<ul>
<li><code>-m</code>：列出所有的配置项</li>
<li><code>-p</code>：列出所有的配置项以及默认值</li>
<li><code>-c</code>：指定一个 properties 文件，读取其中的内容覆盖默认配置并情动</li>
</ul>
<h4 id="自定义配置"><a href="#自定义配置" class="headerlink" title="自定义配置"></a>自定义配置</h4><p>所以，很多时候的做法是通过 <code>sh mqbroker -p &gt; mqbroker.properties</code> 来获得一份默认配置文件（网上的方案可能不太准确，具体输出是携带 Rocket 的日志信息的，需要 sed 或者 awk 之类加工处理一下），在此基础上进行配置自定义，然后通后通过 <code>sh mqbroker -c mqbroker.properties</code> 来进行定制化的启动。</p>
<h4 id="默认配置方案"><a href="#默认配置方案" class="headerlink" title="默认配置方案"></a>默认配置方案</h4><p>同时在 conf 目录下，官方也给出了几种典型的配置方案供参考：</p>
<ul>
<li>二主二从异步复制：2m-2s-async 文件夹。这是最典型的生产配置，双 master 获得高可用性，同时主从间的数据同步由异步完成。</li>
<li>二主二从同步复制：2m-2s-sync 文件夹。除了双 master 的配置，主从间的数据是同步的，也就是说只有在向 salve 成功同步数据才会向客户段返回成功。这保证了在 master 宕机时候消息仍然可以被实时消费，但是性能收到一定影响。</li>
<li>二主无从：2m-nosalve 文件夹。双主模式仅仅保证了 RocketMQ 的高可用性，然而在一台 master 宕机后，客户端无法消费那批在宕机 master 上持久化的消息，直到宕机 master 恢复正常。当然这个方案节省了硬件资源。</li>
</ul>
<p>三种默认配置方案都是采用了异步刷盘，尽管在刷盘间隙宕机会丢失少量数据，但是效率提升可观。</p>
<h4 id="参考配置类"><a href="#参考配置类" class="headerlink" title="参考配置类"></a>参考配置类</h4><p>Broker 的具体配置分为了具体的四个方面：</p>
<ul>
<li>Broker 实例配置：参考源码 <code>org.apache.rocketmq.common.BrokerConfig</code></li>
<li>Netty 服务端配置：参考源码 <code>org.apache.rocketmq.remoting.netty.NettyServerConfig</code></li>
<li>Netty 客户端配置：参考源码 <code>org.apache.rocketmq.remoting.netty.NettyClientConfig</code></li>
<li>Message 持久化配置：参考源码 <code>org.apache.rocketmq.store.config.MessageStoreConfig</code></li>
</ul>
<p>关于 RocketMQ 的启动和配置，就先告一段落。</p>
]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>实现 MyBatis 插件</title>
    <url>/2018/07/%E5%AE%9E%E7%8E%B0-MyBatis-%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>MyBatis 作为一个目前很常用的持久化框架，有着丰富的拓展。这些拓展功能常常以插件的形式嵌入到 MyBatis 的运作流程之中，而如何制作实现一个插件？MyBatis 已经为大家设计好了，一个 <code>Interceptor</code> 接口，实现它就够了。</p>
<p><code>Interceptor</code> 接口的拦截目标，是 MyBatis 运作流程中的几个核心组件：</p>
<ul>
<li><code>Executor</code>：这是 MyBatis 执行器，控制着所有和数据库交互的操作，也影响着一级缓存。</li>
<li><code>ParameterHandler</code>：参数处理器，在映射参数时候生效。</li>
<li><code>ResultSetHandler</code>：结果集处理器，在处理结果集的时候会用到。</li>
<li><code>StatementHandler</code>：<code>Executor</code> 下层的处理器，同样控制着 SQL 行为，也控制着二级缓存的生效。</li>
</ul>
<a id="more"></a>

<p>这几个组件就简称<em>处理器对象</em>吧，感兴趣的话，可以跟进资料，这里继续来讲插件如何拦截它们以及如何实现一个插件。</p>
<h2 id="Interceptor-接口"><a href="#Interceptor-接口" class="headerlink" title="Interceptor 接口"></a>Interceptor 接口</h2><p><code>Interceptor</code> 接口是插件的核心，看一下它的接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 拦截后的逻辑</span></span><br><span class="line">  <span class="function">Object <span class="title">intercept</span><span class="params">(Invocation invocation)</span> <span class="keyword">throws</span> Throwable</span>;</span><br><span class="line">  <span class="comment">// 将处理器对象包装成代理类</span></span><br><span class="line">  <span class="function">Object <span class="title">plugin</span><span class="params">(Object target)</span></span>;</span><br><span class="line">  <span class="comment">// 初始化属性赋值</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">setProperties</span><span class="params">(Properties properties)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>intercept()</code>：拦截 MyBatis 的执行过程，需要在其中加入定制的逻辑。</li>
<li><code>plugin()</code>：可以理解为插件的构造过程，通常把 MyBatis 的几个 handler 包装成代理用。</li>
<li><code>setProperties()</code>：用于插件初始化时候的属性赋值。如果你有其他的赋值方案，也可以不采用它。</li>
</ul>
<p>我们从第一个方法开始讲起。</p>
<h3 id="Object-intercept-Invocation-invocation"><a href="#Object-intercept-Invocation-invocation" class="headerlink" title="Object intercept(Invocation invocation)"></a>Object intercept(Invocation invocation)</h3><p>入参 <code>Invocation</code> 是一个 MyBatis 封装的对象，包含了运行时的信息：</p>
<ul>
<li>属性<code>Method method</code>：即反射包中的 Method，在这里它是当前运行的方法。</li>
<li>属性<code>Object[] args</code>：方法的参数列表</li>
<li>属性<code>Object target</code>：这里其实是你选择拦截的处理器对象（关于如何选择拦截具体的处理器对象，稍后再述），也就是说，它可以是 <code>Executor</code> / <code>StatementHandler</code> …，需要使用时可以直接强转。</li>
<li>方法 <code>proceed()</code>：让处理器继续流程，或者调用下一个插件，你可以用 <code>Filter.doFilter()</code> 来类比它。</li>
</ul>
<p>MyBatis 插件是通过动态代理实现的，对处理器对象进行代理，由代理对象在方法 <code>invoke()</code> 前完成插件中 <code>interceptor()</code> 方法（即插件逻辑）。同时多个插件又是多层的代理，每个插件都需要在具体方法调用前完成自己的逻辑，<strong>所以在实现 Interceptor 接口的 intercept 方法最后，一定要记得执行 Invocation.proceed()，以完成插件的调用链</strong>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">intercept</span><span class="params">(Invocation invocation)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">  <span class="comment">// 可以通过 invocation 获得处理器对象，进而可以变更参数，埋点，收集信息等</span></span><br><span class="line">  <span class="comment">// do something</span></span><br><span class="line">  <span class="comment">// 最后需要记得完成调用链，否则流程将中段</span></span><br><span class="line">  <span class="keyword">return</span> invocation.proceed();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Object-Plugin-Object"><a href="#Object-Plugin-Object" class="headerlink" title="Object Plugin(Object)"></a>Object Plugin(Object)</h3><p>该方法在处理器对象初始化的时候，由 <code>InterceptorChain.pluginAll()</code> 调用，将处理器对象包装成代理类。可以理解为一个初始化方法。</p>
<p>以 <code>StatementHandler</code> 举例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> StatementHandler <span class="title">newStatementHandler</span><span class="params">(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">  StatementHandler statementHandler = <span class="keyword">new</span> RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql);</span><br><span class="line">  <span class="comment">// 初始时触发代理包装</span></span><br><span class="line">  statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler);</span><br><span class="line">  <span class="keyword">return</span> statementHandler;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">pluginAll</span><span class="params">(Object target)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 迭代完成所有插件代理，最终返回一个包含所有插件逻辑的处理器对象代理</span></span><br><span class="line">  <span class="keyword">for</span> (Interceptor interceptor : interceptors) &#123;</span><br><span class="line">    target = interceptor.plugin(target);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> target;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该方法的本质目的是使得新的代理类在拦截的目标方法以及之前的插件逻辑之前添加上新插件的 <code>intercept()</code> 方法中的内容。所以该方法 Object 类型的入参与出参自然也就是处理器接口对象了。<br>在没有特殊需求的情况下，<strong>推荐使用官方工具类</strong> <code>Plugin.wrap()</code> 方法来完成：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">plugin</span><span class="params">(Object target)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> Plugin.wrap(target, <span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原因嘛…先来看一下 <code>Plugin.wrap()</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">wrap</span><span class="params">(Object target, Interceptor interceptor)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 插件上都通过 @Interceptors 指定了要拦截的处理器，以及要拦截的方法和参数，收集起来</span></span><br><span class="line">  <span class="comment">// 获得这个插件想拦截的类-方法</span></span><br><span class="line">  Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor);</span><br><span class="line">  <span class="comment">// 这个 type 必然是 4 大执行器/处理器 接口实现之一</span></span><br><span class="line">  Class&lt;?&gt; type = target.getClass();</span><br><span class="line">  <span class="comment">// 获得原来的所实现的接口，动态代理的必要步骤</span></span><br><span class="line">  Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap);</span><br><span class="line">  <span class="comment">// 如果该插件没有拦截这个处理器，在上一个方法会返回空数组，这里就不包装了</span></span><br><span class="line">  <span class="keyword">if</span> (interfaces.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> Proxy.newProxyInstance(</span><br><span class="line">        type.getClassLoader(),</span><br><span class="line">        interfaces,</span><br><span class="line">        <span class="keyword">new</span> Plugin(target, interceptor, signatureMap));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> target;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass());</span><br><span class="line">    <span class="keyword">if</span> (methods != <span class="keyword">null</span> &amp;&amp; methods.contains(method)) &#123;</span><br><span class="line">      <span class="keyword">return</span> interceptor.intercept(<span class="keyword">new</span> Invocation(target, method, args));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> method.invoke(target, args);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> ExceptionUtil.unwrapThrowable(e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>好处在于，不在需要开发者手动构建一个动态代理（<code>Plugin</code> 本身就是一个 <code>InvocationHandler</code> 实现类），并且在包装成代理的时候，将四个处理器中不需要拦截的类排除了，这使得运行中减少一层不必要的代理，进而提升效率。</p>
<h2 id="Intercepts-注解"><a href="#Intercepts-注解" class="headerlink" title="@Intercepts 注解"></a>@Intercepts 注解</h2><p>插件的拦截流程都已经明了，回过来梳理一下如何拦截自己想要的指定的处理器和指定的方法呢？</p>
<p>在实现了 <code>Interceptor</code> 接口之后，需要配合 <code>@Intercpts</code> 注解一起使用。这个注解中需要安置一个 <code>Signature</code> 对象，在其中指定你需要指定：</p>
<ul>
<li>type：选择 4 个处理器类之一。</li>
<li>method：选择了处理器之后，你需要选择拦截那些方法。</li>
<li>args：选择拦截的方法的参数列表。因为如 <code>Executor</code> 中 query 方法是有重载的。</li>
</ul>
<p>通过以上三者，插件便确定了拦截哪个处理器的哪个方法。MyBatis 的插件实现是不是很简单呢？</p>
<p>需要注意的是，<code>Exector</code> 和 <code>StatementHandler</code> 在一些功能上类似，但是会影响不同级别的缓存，需要注意。同时由于 <code>sqlSession</code> 中这 4 个处理器对象的功能着实强大，并且可以通过拦截改变整个 SQL 的行为，所以如果需要深入定制插件行为的时候，最好需要对 MyBatis 核心机制由一定的了解。</p>
<h6 id="官方介绍"><a href="#官方介绍" class="headerlink" title="官方介绍"></a>官方介绍</h6><p><a href="http://www.mybatis.org/mybatis-3/zh/configuration.html#plugins" target="_blank" rel="external nofollow noopener noreferrer">http://www.mybatis.org/mybatis-3/zh/configuration.html#plugins</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 挂载与数据存储</title>
    <url>/2018/07/Docker/</url>
    <content><![CDATA[<p>Docker 镜像是层层分离的，分为只读的底层和可读写的当前层。容器在运行时候如果有文件改动，会自动从含有该文件的底层拷贝并更新在当前层。如果容器在 commit 之前被销毁，那么有这个镜像重新生成的容器是不包含改动的内容的。</p>
<a id="more"></a>

<h2 id="需求来源"><a href="#需求来源" class="headerlink" title="需求来源"></a>需求来源</h2><p>所以数据问题是使用 Docker 必然会关注到的，除了如何持久化以外，如何从宿主机访问到容器内的数据？或者将容器内的数据同步到宿主机？又或是多个容器间怎么共享数据？这都是要处理的。</p>
<p>还好 Docker 提供了一套完善而简单的数据挂载机制 Volume。</p>
<h2 id="命名卷"><a href="#命名卷" class="headerlink" title="命名卷"></a>命名卷</h2><p>要控制容器的数据内容，首先从文件的挂载开始。<code>docker volume</code> 提供了一套管理卷（volume）的 API：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Usage:  docker volume COMMAND</span><br><span class="line"></span><br><span class="line">Manage volumes</span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line">  create      Create a volume</span><br><span class="line">  inspect     Display detailed information on one or more volumes</span><br><span class="line">  ls          List volumes</span><br><span class="line">  prune       Remove all unused local volumes</span><br><span class="line">  rm          Remove one or more volumes</span><br></pre></td></tr></table></figure>

<p>先创建一个 named volume：<code>docker volume create vol</code><br>使用 <code>docker volume ls</code> 可以看到当前存在的所有的 volume。<br>使用 <code>docker volume rm</code> 删除指定的 volume。<br>使用 <code>docker volume inspect vol</code> 可以看到它的详情，包括创建时间和宿主机上的真正挂载位置等：</p>
<pre><code>[
    {
        &quot;CreatedAt&quot;: &quot;2018-07-09T14:53:05Z&quot;,
        &quot;Driver&quot;: &quot;local&quot;,
        &quot;Labels&quot;: {},
        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/vol/_data&quot;,
        &quot;Name&quot;: &quot;vol&quot;,
        &quot;Options&quot;: {},
        &quot;Scope&quot;: &quot;local&quot;
    }
]</code></pre><p>可以看到这个新建的 vol 保存在 <code>/var/lib/docker/volumes/vol/_data</code> 下，其中 <code>/var/lib/docker/volumes</code> 目录保存了所有的 Docker volume。</p>
<h2 id="运行时挂载"><a href="#运行时挂载" class="headerlink" title="运行时挂载"></a>运行时挂载</h2><h3 id="使用命名卷"><a href="#使用命名卷" class="headerlink" title="使用命名卷"></a>使用命名卷</h3><p>有了 volume 之后，我们便可以使用刚才创建的 vol 来挂载容器中的某个目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -v vol:/data --name temp-redis redis</span><br></pre></td></tr></table></figure>

<p>如此一来，在 temp-redis 容器中 <code>/data</code> 下的改动，都会同步反映在宿主机的 <code>/var/lib/docker/volumes/vol/_data</code> 下；而宿主机的改动亦然。</p>
<h3 id="使用绝对路径"><a href="#使用绝对路径" class="headerlink" title="使用绝对路径"></a>使用绝对路径</h3><p>使用命名的 volume 通常是为了数据共享，很多时候我们只是想指定一个挂载的目录便于记忆和管理，这个时候可以使用绝对路径，如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -v /data/docker_volume/temp_redis/data:/data --name temp-redis redis</span><br></pre></td></tr></table></figure>

<h3 id="自动挂载"><a href="#自动挂载" class="headerlink" title="自动挂载"></a>自动挂载</h3><p>有时候你甚至不想关心任何 volume 的形式，你只是想把某个目录持久化而已，可以这么做：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -v /data --name temp-redis redis</span><br></pre></td></tr></table></figure>

<p>Docker 会自动生成一个匿名的 volume。想要知道具体的宿主机目录可以使用：<code>docker inspect</code> 来查看。这种情况通常在构建纯数据容器时使用。</p>
<h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h3><p>在 volume 创建时和创建之后仍然需要关注他们，下面是一些典型的问题。</p>
<h4 id="volume-自动创建"><a href="#volume-自动创建" class="headerlink" title="volume 自动创建"></a>volume 自动创建</h4><p>事实上在 <code>-v vol:/data</code> 时候，vol volume 甚至不需要提前使用 <code>docker volume create vol</code> 创建，使用 <code>docker run -v vol:/data</code> 命令时便会自动创建。<br><strong>同时地，也意味着 <code>-v</code> 选项不支持相对路径的使用</strong>。</p>
<h4 id="volume-的删除"><a href="#volume-的删除" class="headerlink" title="volume 的删除"></a>volume 的删除</h4><p>在一个 volume 被创建之后，想删除可没那么容易，即使使用了 <code>docker rm CONTAINER</code> 删除了容器，volume 依然保留着。除非：</p>
<ul>
<li>使用 <code>docker run --rm</code> 启动的容器停止时。它除了会删除容器本身还会删除挂载的<strong>匿名</strong> volume。</li>
<li>使用 <code>docker rm -v</code> v 参数可以删除容器和创建容器时关联的<strong>匿名</strong> volume。</li>
</ul>
<p>那么我们在使用了 named volume 或者删除容器时忘记了 <code>-v</code>，那么那些在 <code>/var/lib/docker/volumes</code> 下的一些文件就成了<strong>僵尸文件</strong>。怎么删除呢？</p>
<ul>
<li>使用 <code>docker volume rm VOLUME</code> 来删除。</li>
<li>使用 <code>docker volume prune</code> 删除所有不再被使用的 volume。</li>
</ul>
<h4 id="volume-的只读控制"><a href="#volume-的只读控制" class="headerlink" title="volume 的只读控制"></a>volume 的只读控制</h4><p>一些场合下，我们提供只是需要容器内的程序去读取一些内容而非修改。我们可以严格的控制 volume，增加只读选项 <code>ro</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name=nginxtest \</span><br><span class="line">  -v nginx-vol:/usr/share/nginx/html:ro \</span><br><span class="line">  nginx:latest</span><br></pre></td></tr></table></figure>

<h2 id="通过-Dockerfile-挂载"><a href="#通过-Dockerfile-挂载" class="headerlink" title="通过 Dockerfile 挂载"></a>通过 Dockerfile 挂载</h2><p>可以通过 Dockerfile 在构建镜像的时候便指定需要的 volume，这对于很多应用都是必要的，尤其是一些数据类应用。<br>Dockerfile 中使用 VOLUME 表明挂载目录，如：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">VOLUME</span><span class="bash"> [<span class="string">"/data1"</span>, <span class="string">"/data2"</span>]</span></span><br></pre></td></tr></table></figure>

<p>任何通过该镜像构建的容器都会将 <code>/data1</code>，<code>/data2</code> 两个目录进行挂载。但是 Dockerfile 形式的弱势是<strong>无法进行 named volume 或者绝对路径的挂载</strong>。</p>
<h2 id="数据共享与存储"><a href="#数据共享与存储" class="headerlink" title="数据共享与存储"></a>数据共享与存储</h2><h3 id="共享-volume"><a href="#共享-volume" class="headerlink" title="共享 volume"></a>共享 volume</h3><p>既然数据可以在宿主机和容器间同步，那么可以使多个容器间同步吗？当然可以！</p>
<ol>
<li><h4 id="–volumes-from"><a href="#–volumes-from" class="headerlink" title="–volumes-from"></a>–volumes-from</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先创建一个容器，并挂载 /data</span></span><br><span class="line">docker run -d -v /data --name ng1 nginx</span><br><span class="line"><span class="comment"># 创建第二个容器，共享前者的 volume</span></span><br><span class="line">docker run -d --volumes-from ng1 --name gn2 nginx</span><br></pre></td></tr></table></figure></li>
<li><h4 id="named-volume"><a href="#named-volume" class="headerlink" title="named volume"></a>named volume</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先创建一个容器，并创建命名卷 share 来挂载 /data</span></span><br><span class="line">docker run -d -v share:/data --name ng1 nginx</span><br><span class="line"><span class="comment"># 创建第二个容器，使用同样的 /data</span></span><br><span class="line">docker run -d -v share:/data --name ng2 nginx</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>两种方式都能达到数据共享的目的，但是由于通过命名卷的方式对多个容器的依赖进行了解耦，所以推荐第二种。</strong></p>
<h3 id="数据容器"><a href="#数据容器" class="headerlink" title="数据容器"></a>数据容器</h3><p>这个话题事实上和数据共享紧密相关，由于在 Docker1.9 之前，大家广泛使用使用 <code>--volumes-from</code> 的形式来共享卷，导致必须要一个底层的没有依赖的容器来保存数据。</p>
<ul>
<li>通常使用和应用容器一样的镜像来构建数据容器</li>
<li>数据容器<strong>不需要也不应该启动</strong>，仅仅是利用 volume 机制来保持数据而已</li>
</ul>
<p>然而现在有了命名卷，完全不需要数据容器的存在了，使用 named volume 可以更直接更方便的管理共享数据。</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Dockerfile 中三个运行指令的差异</title>
    <url>/2018/07/Dockerfile-%E4%B8%AD%E4%B8%89%E4%B8%AA%E8%BF%90%E8%A1%8C%E6%8C%87%E4%BB%A4%E7%9A%84%E5%B7%AE%E5%BC%82/</url>
    <content><![CDATA[<p>在描述 Dockerfile 的时候，对于 <code>RUN</code>，<code>CMD</code>，<code>ENTRYPOINT</code> 三个命令，用法十分相似，功能也差不多，容易让人混用。其实一般来说，三个命令都能完成需要的操作，而差异点常常被一些使用者忽略。这里简单说一下，三个命令的不同之处。</p>
<a id="more"></a>

<h2 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h2><p>首先看一下 Dockerfile 中如何执行命令。<br>在 Dockerfile 中，命令（instruction）一般有两种写法，分别是：</p>
<ul>
<li><strong>Shell</strong> 格式：<code>INSTRUCTION &lt;command&gt; &lt;option&gt; &lt;param&gt;</code></li>
<li><strong>Exec</strong> 格式：<code>INSTRUCTION [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;]</code></li>
</ul>
<p>两个格式基本没有差异，除了可读性之外，对于 Shell 格式的命令，Docker 会自动使用 /bin/bash -c 来进行解析，可以是解析命令中的变量比如 <code>$JAVA_HOME</code>。而如果使用 Exec 格式执行时需要解析环境变量，需要进行修改，比如：<code>CMD [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo&quot;, &quot;java home is $JAVA_HOME&quot;]</code>。<br>对于 <code>RUN</code>，<code>CMD</code>，<code>ENTRYPOINT</code> 三者同样遵守此规则。</p>
<h2 id="RUN-命令"><a href="#RUN-命令" class="headerlink" title="RUN 命令"></a>RUN 命令</h2><p><code>RUN</code> 命令在 Dockerfile 中<strong>可以多次使用</strong>，所以通常被用来在构建容器时执行一些必须的前置命令，比如安装软件等。它的出现频率远高于其他两个执行命令。格式：</p>
<ul>
<li><code>RUN &lt;command&gt; &lt;option&gt; &lt;param&gt;</code></li>
<li><code>RUN [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;]</code></li>
</ul>
<p>带来一个 Shell 风格的安装 Git 的例子：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install -y git</span></span><br></pre></td></tr></table></figure>

<p>这里使用 <strong>&amp;&amp;</strong> 可以使得在同一层镜像层上更新 apt 并下载 git。</p>
<h2 id="CMD-命令"><a href="#CMD-命令" class="headerlink" title="CMD 命令"></a>CMD 命令</h2><p><code>CMD</code> 命令的格式有三种，前两者都是用来<strong>定义容器的默认行为</strong>，后者用来给 <code>ENTRYPOINT</code> 命令提供<strong>额外的可替换参数</strong>。</p>
<ol>
<li><code>CMD &lt;command&gt; &lt;option&gt; &lt;param&gt;</code></li>
<li><code>CMD [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;]</code></li>
<li><code>CMD [&quot;param&quot;...]</code></li>
</ol>
<p>先说前两者用作执行默认命令的情况，以一个官方 Nginx 的 Dockerfile 为例：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 前置步骤忽略</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"nginx"</span>, <span class="string">"-g"</span>, <span class="string">"daemon off;"</span>]</span></span><br></pre></td></tr></table></figure>

<p>该命令使得以该 Nginx 镜像构建的容器，在启动时候默认地自动运行 Nginx。但是既然是定义<strong>默认</strong>行为，那么它是可以在运行容器的时候被更改的，比如像下面这样：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo docker run -p 80:80 nginx <span class="built_in">echo</span> hello-world</span><br></pre></td></tr></table></figure>
<p>那么这个时候容器并不会启动一个 Nginx 服务，而是打印了 hello-world。并且这个容器会随着打印命令的结束而停止。</p>
<p>需要注意的是，既然 <code>CMD</code> 定义<strong>默认</strong>行为，那么它在 Dockerfile 中只能存在一个（如果定义了多个 <code>CMD</code>，那个最后一个有效）</p>
<p>那么如何使用 <code>CMD</code> 为 <code>ENTRYPOINT</code> 提供额外参数呢？先看一下 <code>ENTRYPOINT</code> 的用法。</p>
<h2 id="ENTRYPOINT-命令"><a href="#ENTRYPOINT-命令" class="headerlink" title="ENTRYPOINT 命令"></a>ENTRYPOINT 命令</h2><p><code>ENTRYPOINT</code> 通常用来<strong>定义容器启动时候的行为</strong>，有点类似于 <code>CMD</code>，但是它不会被启动命令中的参数覆盖。<br>上一节中 Nginx 的例子，如果将 <code>CMD</code> 改成 <code>ENTRYPOINT</code>，那么我们的 hello-world 方案便行不通了。</p>
<p><code>ENTRYPOINT</code> 同样支持两种格式的写法，并且是存在差异的（后文描述）：</p>
<ol>
<li><code>ENTRYPOINT &lt;command&gt; &lt;option&gt; &lt;param&gt;</code></li>
<li><code>ENTRYPOINT [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;]</code></li>
</ol>
<p>使用 Exec 风格的写法支持使用 <code>CMD</code> 拓展<strong>可变参数</strong>和<strong>动态替换</strong>参数，而使用 Shell 风格时<strong>不支持</strong>。假如我们在 Dockerfile 中：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 前置步骤忽略</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> redis-cli -h 127.0.0.1</span></span><br></pre></td></tr></table></figure>

<p>那么这个由此构建的容器在运行时<strong>只能</strong>将 redi 连接到容器本身的 redis-server 上。<br>修改这个 Dockerfile：</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 前置步骤忽略</span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"redis-cli"</span>]</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"-h"</span>, <span class="string">"127.0.0.1"</span>]</span></span><br></pre></td></tr></table></figure>
<p>这时候，如果按默认的启动方式，容器的 redis-cli 会自动连接 127.0.0.1，即以下命令此时是等价的：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run my-redis-image</span><br><span class="line">docker run my-redis-image -h 127.0.0.1</span><br></pre></td></tr></table></figure>

<p>但是由于 Dockfile 中使用了 Exec 格式的 <code>ENTRYPOINT</code>，我们已经可以修改它的目标地址了，甚至可以增加额外的参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run my-redis-image -h server.address -a redis_password</span><br></pre></td></tr></table></figure>

<p>其中 <code>-h server.address</code> 替换了 <code>CMD [&quot;-h&quot;, &quot;127.0.0.1&quot;]</code>，而 <code>-a redis_password</code> 则是由于使用了 Exec 格式可以增加参数。</p>
<hr>
<p>关于 <code>RUN</code>，<code>CMD</code>，<code>ENTRYPOINT</code> 的差异已经描述完了，有没有都牢记于心呢~</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>文字处理-sed</title>
    <url>/2018/07/%E6%96%87%E5%AD%97%E5%A4%84%E7%90%86-sed/</url>
    <content><![CDATA[<p>sed 是非常常用的流式处理编辑工具，配合正则表达式可以进行十分效率的文字处理。它通过逐行地将文字读取，暂存进模式空间，通过指定的命令进行处理后，输出至标准输出，直到文件或者说输入的结束。原理十分简单，来学习一下吧。</p>
<a id="more"></a>

<h2 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h2><p>sed [选项及参数]… ‘操作命令’ 文件…</p>
<h2 id="常用选项"><a href="#常用选项" class="headerlink" title="常用选项"></a>常用选项</h2><ul>
<li>-n <strong>静默模式</strong> 取消 sed 默认的输出</li>
<li>-e <strong>多重编辑</strong> 可以多次使用，携带 sed 命令作为该选项的参数，对于缓冲区的每一行按命令顺序进行处理</li>
<li>-f 使用 sed 操作的<strong>脚本处理</strong>，跟上脚本文件名做参数。sed 脚本可以保存多条 sed 命令，一行一条，依次执行。</li>
<li>-r 使用<strong>拓展正则</strong>，类似 grep -e 或者 egrep 的增强，让人少些一点转义符</li>
<li>-i <strong>原地修改</strong>，该选项会使得 sed 命令直接修改原文件，可以紧跟一个后缀如 -i.bk，同时生成备份</li>
</ul>
<h2 id="命令组成"><a href="#命令组成" class="headerlink" title="命令组成"></a>命令组成</h2><p>sed 命令的组成通常是 ‘行选择具体操作’。sed 在读入行内容之后，如果匹配定址要求就会进行命令操作。我们来两部分分开一看~</p>
<h3 id="行选择"><a href="#行选择" class="headerlink" title="行选择"></a>行选择</h3><ul>
<li><strong>num</strong>             选择第 num 行。</li>
<li><strong>start,end</strong>       选择第 start 行至第 end 行。</li>
<li><strong>start~step</strong>      从 start 行开始，以 step 为步长选择行。</li>
<li><strong>/pattern/</strong>       选择含有该正则的内容的行。</li>
<li><strong>start,/pattern/</strong> 从 start 行开始直到首次成功匹配表达式的一行将被选定，注意 sed 的处理机制，如果表达式最终无法有任何匹配行，将会对 start 行之后的所有行进行选定。</li>
<li><strong>/pattern/,end</strong>   从首次成功匹配表达式的一行至 end 行将被选定，如果在第 end 行之前如果没有成功匹配将会不有行被选中。</li>
<li><strong>!</strong>               置于行选择末尾，进行反选，如 <code>10,20!</code> 将排除 10 至 20 行。</li>
</ul>
<h3 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h3><ul>
<li><strong>p</strong> 打印缓冲内容，通常配合 -n 选项测试指令正确性。</li>
<li><strong>q</strong> 提前退出 sed，当到达匹配行或者指定行就退出 sed。</li>
<li><strong>i\[content]</strong> 行前追加内容，如在第 1 行至第 5 行，每行之后插入‘===’：<code>&#39;1,5i\===&#39;</code>。</li>
<li><strong>a\[content]</strong> 行后追加内容。</li>
<li><strong>c\[content]</strong> 替换内容，如果是批量选择，并不是对每行内容进行替换，而是对整体替换成相应内容。</li>
<li><strong>d</strong> 删除。</li>
<li><strong>s/pattern/new_chars/[g]</strong> 对选定的行中首次匹配表达式的内容替换成目标字符串，如果末尾使用‘g’，可以对行中所有匹配内容替换。</li>
<li><strong>y/old-char-set/new-char-set</strong> 对选定行中所有 old-char-set 内的字符替换成相应的新的字符。</li>
<li><strong>n</strong> 提前读取下一输入行至缓冲区。</li>
<li><strong>r [file-name]</strong> 行后追加指定文件内容。</li>
<li><strong>w [file-name]</strong> 将选定行输入至指定文件。</li>
<li><strong>h</strong> 复制匹配行进入暂存空间。</li>
<li><strong>G</strong> 配合 h 命令，取出暂存空间内的行，插入至模式空间的末尾。</li>
<li><strong>x</strong> 配合 h 命令，交换当前匹配行的暂存空间内的行。</li>
</ul>
<h3 id="命令叠加"><a href="#命令叠加" class="headerlink" title="命令叠加"></a>命令叠加</h3><p>需要多次使用 sed 操作的时候，可以有这么些办法：</p>
<ol>
<li>通过 <code>{命令1;命令2...}</code> 可以使用‘{}’将多个命令整合一块儿，中间使用‘;’分割，类似代码块的表达。其中如果如果多个命令的行定位条件一致，可以将该部分提出，如：<code>&#39;{10p;10p}&#39;</code> 等于 <code>&#39;10{p;p}&#39;</code>。</li>
<li>通过 -e 选项多次输入 sed 命令。</li>
<li>将多个 sed 命令逐行写入文件，使用 -f 选项执行 sed。</li>
</ol>
<h3 id="额外技巧"><a href="#额外技巧" class="headerlink" title="额外技巧"></a>额外技巧</h3><p>sed 命令其实和正则表达式通常配合使用，所以这一些小技巧其实和正则有很密切的关系。比如对于一个简单的替换操作，如 <code>s/abc/xyz/</code> 是十分简单的，但是 sed 支持更复杂的操作，可以用一些特殊意义的操作符号:</p>
<ul>
<li>&amp; 表示正则匹配成功的原字符串内容，如想要替换所有数字为它的百倍，可以使用 ‘s/[[:digit:]]\+/&amp;00/g’</li>
<li>\num 获取缓存的匹配中缓存的字符串，num 指定位置（这取决于表达式中使用了多少次小括号‘()’）。<ul>
<li>如去除数字并字母大写，’s/([[:digit:]]\+\)\|\([[:alpha:]]\+\)/\U\2/gp’</li>
<li>获取包含一段 ip 的文本中 ip 的前两段地址 ‘s/\([0-9]\+\):\([0-9]\+\):[0-9]\+:[0-9]+/\1 \2/p’</li>
</ul>
</li>
<li>\u 将后方的表达式结果进行首字母大写处理</li>
<li>\U 将后方的表达式结果进行大写处理</li>
<li>\l 将后方的表达式结果进行首字母小写处理</li>
<li>\L 将后方的表达式结果进行小写处理</li>
</ul>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Regex</tag>
      </tags>
  </entry>
  <entry>
    <title>AQS 浅析</title>
    <url>/2018/07/AQS-%E6%B5%85%E6%9E%90/</url>
    <content><![CDATA[<p><code>java.util.concurrent</code> 包中提供了许多易用而有效的工具类，诸如 <strong>ReentrantLock</strong>，<strong>CountDownLatch</strong>，<strong>Semaphore</strong> 等等，给日常的并发编程带来了许多便利。他们都使用了同样的框架来完成基本的同步过程：<strong><em>AbstractQueuedSynchronizer</em></strong> （AQS）来实现基本功能，比如获取资源和释放的步骤。</p>
<a id="more"></a>

<h2 id="简单了解"><a href="#简单了解" class="headerlink" title="简单了解"></a>简单了解</h2><p>戳开 AQS 一览其结构，其实它本身维护了两个概念：</p>
<ul>
<li>state：（volatile int）该属性维护了资源的状态，或者是数量。</li>
<li>CLH queue：一个先进先出的线程等待队列。这并不是一个具体对象，而是通过内部类 Node 来维护的。</li>
</ul>
<p>AQS 对于 state 支持两种模式的资源共享形式：</p>
<ul>
<li>Exclusive-排他式：进程独占形式，如 ReentrantLock，Mutex 的应用。</li>
<li>Share-共享式：支持多线程访问，典型的应用式 CountDownLatch / Semaphore。</li>
</ul>
<p>子类实现 AQS 时候只需要实现关于 state 的获取（acquire）和释放（release）方案即可，包括队列的维护，线程的唤醒等工作，大部分都在 AQS 维护了。举个栗子，在使用 CountDownLatch 的时候，我们会初始化一个计数值 n 用于对应 n 个子线程，这个 n 同时也对应了 state 值，每一次 <code>countDown()</code> 的时候，会使得 state CAS 地减 1。在 state 归零的时候会使用 <code>unpark()</code>，主线程 从 <code>await()</code> 函数返回。</p>
<h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>AQS 的 API 同一般的同步工具 API 一样，除了对于资源的 <code>acquire</code> / <code>release</code> 操作，还提供的了 <code>tryAcquire</code> / <code>tryRelease</code> 的非阻塞操作。同时 <code>acquireInterruptibly</code> 支持线程中断。如果需要使用共享式的操作，需要实现对应的 Share 操作方法。</p>
<h3 id="资源获取"><a href="#资源获取" class="headerlink" title="资源获取"></a>资源获取</h3><p>首先看 <code>acquire</code> 方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg))</span><br><span class="line">        selfInterrupt();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>tryAcquire(int)</code>：尝试获取资源</li>
<li><code>addWaiter(Node)</code>：使线程（Node 对象维护这线程对象）进入等待队列，对于 acquire 方法使用 EXCLUSICE-排他模式。</li>
<li><code>acquireQueued(Node, int)</code>：在这一步骤中线程会等待，而在线程唤醒后会尝试在该方法内获取资源。</li>
<li><code>selfInterrupt</code>：由于线程在等待过程中无法响应中断，所以在获取资源并退出队列后补充一个中断。</li>
</ul>
<p><code>tryAcquire(int)</code> 方法默认会抛出操作不支持的异常，需要子类的具体实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">tryAcquire</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>addWaiter(Node, int)</code> 方法会自旋使用 CAS 方式将一个 Node 加入队尾。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">addWaiter</span><span class="params">(Node mode)</span> </span>&#123;</span><br><span class="line">    Node node = <span class="keyword">new</span> Node(Thread.currentThread(), mode);</span><br><span class="line">    <span class="comment">// Try the fast path of enq; backup to full enq on failure</span></span><br><span class="line">    Node pred = tail;</span><br><span class="line">    <span class="keyword">if</span> (pred != <span class="keyword">null</span>) &#123;</span><br><span class="line">        node.prev = pred;</span><br><span class="line">        <span class="keyword">if</span> (compareAndSetTail(pred, node)) &#123;</span><br><span class="line">            pred.next = node;</span><br><span class="line">            <span class="keyword">return</span> node;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    enq(node);</span><br><span class="line">    <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">enq</span><span class="params">(<span class="keyword">final</span> Node node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        Node t = tail;</span><br><span class="line">        <span class="keyword">if</span> (t == <span class="keyword">null</span>) &#123; <span class="comment">// Must initialize</span></span><br><span class="line">            <span class="keyword">if</span> (compareAndSetHead(<span class="keyword">new</span> Node()))</span><br><span class="line">                tail = head;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            node.prev = t;</span><br><span class="line">            <span class="keyword">if</span> (compareAndSetTail(t, node)) &#123;</span><br><span class="line">                t.next = node;</span><br><span class="line">                <span class="keyword">return</span> t;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上面两个方法可以看出位于队列头部的 Node 其实只是一个标记，在队列第二位置的时候，线程已经可以获取资源并进行相关任务了。</p>
<p><code>acquireQueued(Node, int)</code> 更关键的一步，在获取资源失败， Node 已经被加入队尾之后，线程需要进入等待状态等待被唤醒。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">acquireQueued</span><span class="params">(<span class="keyword">final</span> Node node, <span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> failed = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">boolean</span> interrupted = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            <span class="keyword">final</span> Node p = node.predecessor();</span><br><span class="line">            <span class="keyword">if</span> (p == head &amp;&amp; tryAcquire(arg)) &#123;</span><br><span class="line">                setHead(node);</span><br><span class="line">                p.next = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">                failed = <span class="keyword">false</span>;</span><br><span class="line">                <span class="keyword">return</span> interrupted;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp;</span><br><span class="line">                parkAndCheckInterrupt())</span><br><span class="line">                interrupted = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (failed)</span><br><span class="line">            cancelAcquire(node);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>shouldParkAfterFailedAcquire(Node, Node) 每个节点是否需要等待需要阻塞取决于前驱节点的状态。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">shouldParkAfterFailedAcquire</span><span class="params">(Node pred, Node node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ws = pred.waitStatus;</span><br><span class="line">    <span class="keyword">if</span> (ws == Node.SIGNAL)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">if</span> (ws &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            node.prev = pred = pred.prev;</span><br><span class="line">        &#125; <span class="keyword">while</span> (pred.waitStatus &gt; <span class="number">0</span>);</span><br><span class="line">        pred.next = node;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>前驱节点最后会通过该状态值来判断是否需要 unpark 下个线程。在这里，如果前驱节点标识为 SIGNAL，则进入等待；标识为 CANCAL 需要追溯更前的节点状态；如果为其他正常值，则更新为 SIGNAL。</p>
<p><code>parkAndCheckInterrupt()</code> 使线程进入 WATING，等待 unpark（在 release 中触发，马上就来） 或者 interrupt，被唤醒后回到 <code>acquireQueued</code> 触发中断或者继续检查是否可以获取资源。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">parkAndCheckInterrupt</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    LockSupport.park(<span class="keyword">this</span>);</span><br><span class="line">    <span class="keyword">return</span> Thread.interrupted();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="释放资源并唤醒后置线程"><a href="#释放资源并唤醒后置线程" class="headerlink" title="释放资源并唤醒后置线程"></a>释放资源并唤醒后置线程</h3><p>这是 <code>acquire</code> 方法的反操作，用于资源的释放，当资源成功释放时，唤醒下一个线程（位于头节点之后）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">release</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (tryRelease(arg)) &#123;</span><br><span class="line">        Node h = head;</span><br><span class="line">        <span class="keyword">if</span> (h != <span class="keyword">null</span> &amp;&amp; h.waitStatus != <span class="number">0</span>)</span><br><span class="line">            unparkSuccessor(h);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过 <code>tryRelease(int)</code> 方法判断资源是否释放，这个方法同样需要被实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">tryRelease</span><span class="params">(<span class="keyword">int</span> arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而 <code>unparkSuccessor(Node)</code> 方法用来真正唤醒 node.next 中的线程：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">unparkSuccessor</span><span class="params">(Node node)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ws = node.waitStatus;</span><br><span class="line">    <span class="keyword">if</span> (ws &lt; <span class="number">0</span>)</span><br><span class="line">        compareAndSetWaitStatus(node, ws, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    Node s = node.next;</span><br><span class="line">    <span class="keyword">if</span> (s == <span class="keyword">null</span> || s.waitStatus &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        s = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">for</span> (Node t = tail; t != <span class="keyword">null</span> &amp;&amp; t != node; t = t.prev)</span><br><span class="line">            <span class="keyword">if</span> (t.waitStatus &lt;= <span class="number">0</span>)</span><br><span class="line">                s = t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (s != <span class="keyword">null</span>)</span><br><span class="line">        LockSupport.unpark(s.thread);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看到这就能了解整个 AQS 的运作流程了。在 parkAndCheckInterrupt 中进入 WAITING 的线程，在这里被唤醒，它会继续进入 <code>acquireQueued</code> 中的自旋，如果 <code>tryAcquire</code> 顺利获得资源，则将本线程的节点设置为 head 并返回 acquire 方法。so, go on.</p>
<p>AQS 本身并不复杂，使用时只需要手动实现 <code>tryAcquire</code> 和 <code>tryRealeas</code> 方法。</p>
<p>而对于 Share-共享式的 acquire / release 流程，区别并不太大，有兴趣的小伙伴可以自行翻阅源码一探究竟。</p>
<h6 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h6><ol>
<li><a href="https://mp.weixin.qq.com/s/eyZyzk8ZzjwzZYN4a4H5YA" target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/eyZyzk8ZzjwzZYN4a4H5YA</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>Ribbon 摘要</title>
    <url>/2018/07/Ribbon/</url>
    <content><![CDATA[<h2 id="主要构成"><a href="#主要构成" class="headerlink" title="主要构成"></a>主要构成</h2><p>Ribbon 是由 netflix 开源的一个客户端负载均衡组件。从客户端的角度取维护服务间请求的负载均衡，并进行一定的容错处理。<br>自然的它的核心接口就是：<code>com.netflix.loadbalancer.ILoadBalancer</code>。</p>
<p>在配置 Ribbon 之前，了解一下 Ribbon 完成负载均衡的几个重要组成部分：</p>
<ul>
<li><strong><code>IRule</code></strong>：负载均衡的策略。</li>
<li><strong><code>IPing</code></strong>：检测服务存活的策略。</li>
<li><strong><code>ServerList&lt;T&gt;</code></strong>：拉取服务实例列表的策略。</li>
<li><strong><code>ServerListUpdater</code></strong>：更新服务列表的触发策略。</li>
<li><strong><code>ServerListFilter&lt;T&gt;</code></strong>：服务过滤方案。</li>
</ul>
<a id="more"></a>
<p>参考下面的类关系图，可以有一个更好的印象：</p>
<p><img src="/images/ILoadBalancer.png" alt="ILoadBalancer"></p>
<h3 id="IRule"><a href="#IRule" class="headerlink" title="IRule"></a>IRule</h3><p>负载均衡策略接口，可能最常需要配置的就是它了，配置也没什么特殊的，就以 Spring 常用的方式即可。通常情况下 Ribbon 原生的几个负载均衡策略应该可以满足生产要求（当然你也可以自定义），来了解一下：</p>
<p><img src="/images/IRule.png" alt="IRule"></p>
<ul>
<li><strong><code>AbstractLoadBalancerRule</code></strong> 顶级的抽象类，给予了获得 LoadBalancer 的方法，可以让子类获得负载均衡器的一些信息，定制更具体的算法。</li>
<li><strong><code>RandomRule</code></strong> 通过 LoadBalancer 获取可用的服务实例，并<strong>随机</strong>挑选。（一直无可实例时有无限循环 bug）</li>
<li><strong><code>RoundRobinRule</code></strong> 通过 LoadBalancer 获取可用的服务实例，并<strong>轮询</strong>选择。（超过 <em>10</em> 次失败时，打印机警告并返回 null）</li>
<li><strong><code>RetryRule</code></strong> 默认有一个 RoundRobinRule 的子规则，和 <em>500</em> 毫秒的阈值。<strong>使用子规则</strong>选择实例，执行时间若超过阈值则返回 null。</li>
<li><strong><code>WeightedResponseTimeRule</code></strong> 继承自 RoundRobinRule。在构造时会启动一个定时任务，默认每 <em>30</em> 秒执行一次，来计算服务实例的权重。在默认的算法下，<strong>响应速度</strong>越快的服务实例权重越大，越容易被选择。</li>
<li><strong><code>ClientConfigEnabledRoundRobinRule</code></strong> 本身定义了一个 RoundRobinRule 的子规则。本且默认的 choose 方法也是执行 RoundRobinRule 的实现。本身没有特殊用处，这个默认会实现是在其子类的算法无法实现时采用，通常会选择该类作父类继承，实现自定义的规则，以<strong>保证拥有一个默认的轮询规则</strong>。</li>
<li><strong><code>BestAvaliableRule</code></strong> 通过 LoadBalancerStats 选择<strong>并发请求最小</strong>的实例。</li>
<li><strong><code>PredicateBasedRule</code></strong> 利用<strong>子类</strong>的 Predicate <strong>过滤</strong>部分服务实例后通过轮询选择。</li>
<li><strong><code>AvailabilityFilteringRule</code></strong> <strong>轮询</strong>选择一个服务实例，判断是否故障（断路器断开），并发请求是否大于阈值（默认2^32-1，可通过<code>&lt;clientName&gt;.&lt;nameSpace&gt;.ActiveConnectionsLimit</code> 修改）。允许则返回，不允许则再次选择，失败 <em>10</em> 次后执行父类方案。</li>
<li><strong><code>ZoneAvoidanceRule</code></strong> 使用组合过滤条件执行<strong>过滤</strong>，每次过滤后会判断实例数是否小于最小实例数（默认1），是否大于过滤百分比（默认0），不再过滤后使用<strong>轮询</strong>选择。</li>
</ul>
<h2 id="具体配置"><a href="#具体配置" class="headerlink" title="具体配置"></a>具体配置</h2><p>在项目中是可以配置多个 Ribbon 客户端的，通常来说每个客户端用来访问不同的服务。比如为访问 A 服务的 Ribbon 客户端配置为 A-Client，B 服务为 B-Client。</p>
<h3 id="通过代码配置"><a href="#通过代码配置" class="headerlink" title="通过代码配置"></a>通过代码配置</h3><p>首先来介绍通过注解配置的方法，像简单的 Sring Bean 配置一样，不过不需要使用 <code>@Configuration</code> 注解了。在配置类上启用 <code>@RibbonClient</code>，给定客户端的名称和配置类，使用 <code>@Bean</code> 来配置具体的组件如 IRule 等。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RibbonClient</span>(name = <span class="string">"A-Client"</span>,configuration = ARibbonConfig<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">class</span> <span class="title">ARibbonConfig</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 服务实例的地址</span></span><br><span class="line">    String listOfServers = <span class="string">"http://127.0.0.1:8081,http://127.0.0.1:8082"</span>;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ServerList&lt;Server&gt; <span class="title">ribbonServerList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        List&lt;Server&gt; list = Lists.newArrayList();</span><br><span class="line">        <span class="keyword">if</span> (!Strings.isNullOrEmpty(listOfServers)) &#123;</span><br><span class="line">            <span class="keyword">for</span> (String s: listOfServers.split(<span class="string">","</span>)) &#123;</span><br><span class="line">                list.add(<span class="keyword">new</span> Server(s.trim()));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> StaticServerList&lt;Server&gt;(list);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>官方文档上提示了一个<strong><em>坑</em></strong>，不能把加了配置注解的具体的配置类放在 <code>@ComponentScan</code> 路径下，否则先扫描到的一个具体的客户端配置会成为 Ribbon 的全局配置。</p>
<p>这怎么能忍？当然得有更优雅的解决方式：全局配置的方案。<br>使用 @RibbonClients 注解，一次可以描述多个客户端配置类的位置，同时也可以指定默认配置类，如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringCloudApplication</span></span><br><span class="line"><span class="meta">@RibbonClients</span>(value = &#123;</span><br><span class="line">    <span class="meta">@RibbonClient</span>(name = <span class="string">"A-Client"</span>,configuration = ARibbonConfig<span class="class">.<span class="keyword">class</span>),</span></span><br><span class="line"><span class="class">    @<span class="title">RibbonClient</span>(<span class="title">name</span> </span>= <span class="string">"B-Client"</span>,configuration = BRibbonConfig<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">&#125;, <span class="title">defaultConfiguration</span> </span>= DefaultConfig<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">class</span> <span class="title">DemoServiceApplication</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(DemoServiceApplication<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样配置可以不需要再在配置类上加上注解了，也可以不需要将配置类移出包扫描路径。</p>
<h3 id="通过配置文件指定"><a href="#通过配置文件指定" class="headerlink" title="通过配置文件指定"></a>通过配置文件指定</h3><p>但是以上这样的代码配置还是稍显复杂，在目前的 SpringCloud 中 Ribbon 的配置可以直接 SpringBoot 的配置文件中写入，使用如下的方式指定要配置的参数：</p>
<pre><code>&lt;nameSpace&gt;.&lt;key&gt;=&lt;value&gt; </code></pre><p>默认的命名空间是 ribbon，例如定义连接超时时间可以：</p>
<pre><code>ribbon.connectTimeout=120</code></pre><p>而当需要为具体的客户端配置时，可以使用：</p>
<pre><code>&lt;client&gt;.&lt;nameSpace&gt;.&lt;key&gt;=&lt;value&gt;</code></pre><p>比如：</p>
<pre><code>user-service.ribbon.listOfServers=localhost:8001,localhost:8002</code></pre><p>关于 ribbon 所有的参数名称，可以参看 <code>com.netfix.client.config.CommonClientConfigKey&lt;T&gt;</code>。</p>
<h3 id="与-Eureka-整合后的配置"><a href="#与-Eureka-整合后的配置" class="headerlink" title="与 Eureka 整合后的配置"></a>与 Eureka 整合后的配置</h3><p>在使用 Eureka 的时候，会改变 Ribbon 一些组件的默认实现，如：</p>
<ul>
<li><code>ServerList</code> -&gt; <code>DiscoveryEnabledNIWSServerList</code>：由 Eureka 来维护服务列表</li>
<li><code>IPing</code> -&gt; <code>NIWSDiscoveryPing</code>：由 Eureka 测试服务存活（原配的 <code>DummyPing</code> 并不会 ping，而是始终返回 true）</li>
</ul>
<p>而且针对不同服务不需要显示地配置不一样的客户端名称了，只需要使用</p>
<pre><code>&lt;serviceName&gt;.&lt;nameSpace&gt;.&lt;key&gt;=&lt;value&gt;</code></pre><p>如 user-service：</p>
<pre><code>user-service.ribbon.ReadTimeout=120</code></pre><p>同时由于 SpringCloud Ribbon 默认实现区域亲和策略，zone 的配置也十分简单，只需要加入元数据集中即可，如：</p>
<pre><code>eureka.instance.metadataMap.zone=huzhou</code></pre><p>如果不需要 Eureka 辅助 Ribbon 的自动配置（这不太可能吧），则可以使用：</p>
<pre><code>ribbon.eureka.enable=false</code></pre><p>这时候，记得自己得手动配置 listOfServers 等参数了。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title>正则笔记</title>
    <url>/2018/06/%E6%AD%A3%E5%88%99%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>日常开发中，经常需要进行一些文本处理，这通常是十分繁琐而无趣的。学会并利用正则表达式可以快速解决这类文本处理问题，无论是在 Java，Python 等代码中抑或是 shell 环境下。<br>正则中存在很多细小的知识点，十分容易遗忘，着手记录，知识整理还是有所必要。</p>
<a id="more"></a>

<p>本文以拓展正则进行描述，部分特殊字符和定址方式在标准正则下无效。如需在 shell 环境下使用，需要额外使用‘\’符号，或开启拓展正则的支持，如 grep -e，sed -r 等。</p>
<h2 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h2><p>正则表达式的规则可以简单理解为：<strong>在给定的范围内，给定的字符重复给定的次数</strong>。</p>
<h3 id="指定需要匹配的字符"><a href="#指定需要匹配的字符" class="headerlink" title="指定需要匹配的字符"></a>指定需要匹配的字符</h3><p>绝大部分的字符，包括数字字母汉字等，都可以直接输入来描述。</p>
<h4 id="转义后特殊字符"><a href="#转义后特殊字符" class="headerlink" title="转义后特殊字符"></a>转义后特殊字符</h4><p>以下几个字符由转义符‘\’和某个字符组成，可以表述成新字符，他们有着特殊的含义。</p>
<ul>
<li><strong><code>\n</code></strong>  这是一个换行符。</li>
<li><strong><code>\t</code></strong>  制表符，Tab 键的缩进。</li>
<li><strong><code>\v</code></strong>  垂直制表符。</li>
<li><strong><code>\f</code></strong>  分页符，产生一个新页。</li>
<li><strong><code>\r</code></strong>  这是回车符</li>
<li><strong><code>\s</code></strong>  这个表达可以表述所有的空白字符，即以上五种字符或者空格。</li>
<li><strong><code>\cx</code></strong>  当 x 取值英文字符时，这个整体就有了特殊意义，会映射成一个控制字符，如 <code>\cM</code> 等价于 <code>\r</code> 即回车符号。</li>
<li><strong><code>\ux</code></strong>  可以匹配 Unicode 字符，如 \u00CD。</li>
<li><strong><code>\nx</code></strong>  在 x 值合法的情况下，可以匹配八进制专一值（在没有顺利取得缓存引用时）</li>
<li><strong><code>\b</code></strong>  表示字符边界，可以理解为打断单词或着汉字连续的空格/符号之类（其实它并不能匹配到某个字符，仅仅是匹配到了边界）</li>
<li><strong><code>\d</code></strong>  表示数字，同 <code>[0-9]</code>。</li>
<li><strong><code>\w</code></strong>  表示任意字类字符，即数字字母和下划线，通常还支持汉字。</li>
<li><strong><code>\&lt;</code></strong>  匹配单词首，比如 <code>\&lt;wo</code> 可以匹配 wood，word 等。</li>
<li><strong><code>\&gt;</code></strong>  同理匹配单词尾部。</li>
</ul>
<h4 id="原生特殊字符"><a href="#原生特殊字符" class="headerlink" title="原生特殊字符"></a>原生特殊字符</h4><p>以下的字符并不需要转移符‘\’，天然的拥有特殊含义（以拓展正则为准）。</p>
<ul>
<li><strong><code>$</code></strong>  尾部，表示字符串结尾位置。</li>
<li><strong><code>^</code></strong>  头部，字符串的开头位置，<strong>但在 <code>[ ]</code> 内使用时表示取反</strong></li>
<li><strong><code>[ ]</code></strong>  左右中括号，用来表达匹配单个字符时候的可选范围</li>
<li><strong><code>{ }</code></strong>  左右花括号，用来表述前一表达式的可重复区间</li>
<li><strong><code>( )</code></strong>  左右小括号，类似数学中的概念，可以描述一个表达式并提高计算优先级，同时会缓存匹配结果。</li>
<li><strong><code>·</code></strong>  点号，可以用了匹配任意的一个字符，除了 <code>\n</code> 吧。</li>
<li><strong><code>*</code></strong>  星号，可以匹配前面表达式任意次数。</li>
<li><strong><code>+</code></strong>  加号，匹配前面表达式一至任意次数.</li>
<li><strong><code>?</code></strong>  问号，匹配前面表达式 0 ~ 1 次。</li>
<li><strong><code>\</code></strong>  转移符本身，用来转移其他字符，需要匹配它本身的时候自然需要 <code>\\</code> 的形式。</li>
<li><strong><code>|</code></strong>  或运算符号，任意匹配前后表达式之一。</li>
<li><strong><code>[:digit:]</code></strong>  所有数字</li>
<li><strong><code>[:lower:]</code></strong>  所有小写字母</li>
<li><strong><code>[:upper:]</code></strong>  所有大写字母</li>
<li><strong><code>[:alpha:]</code></strong>  所有字母</li>
<li><strong><code>[:alnum:]</code></strong>  所有字母及数字</li>
<li><strong><code>[:space:]</code></strong>  所有空白符</li>
<li><strong><code>[:punct:]</code></strong>  所有标点符号</li>
</ul>
<h3 id="指定匹配字符的候选范围"><a href="#指定匹配字符的候选范围" class="headerlink" title="指定匹配字符的候选范围"></a>指定匹配字符的候选范围</h3><p>匹配一个单字符很简单，但是通常我们需要匹配几个字符中的任意一个，这个时候就需要一个候选范围的描述。<br>除了使用 <code>\w</code> 表示字类字符，<code>\s</code> 来表示空白符。也可以使用 <code>[ ]</code> 方括号来描述范围，来看几个例子：</p>
<ul>
<li><code>[abc]</code>  它可以是匹配 a，也可以是 b，也可以是 c。</li>
<li><code>5[48]k</code>  它可以是 54k，也可以是 58k。</li>
<li><code>[0-9]\w</code>  它可以使是 0a，3b，33 等等。</li>
</ul>
<p>这样一看是不是很容易？来看一些进阶技巧：</p>
<ol>
<li>取反。表述范围的符号可以通过大写来表示取反，<code>\S</code> 表示非空白字符，<code>\B</code> 表示非字符边界，<code>\W</code> 表示非字类字符。对于使用 <code>[ ]</code> 的场合，使用 <code>[^ ]</code> 来完成取反。</li>
<li><code>[ ]</code> 方括号中间不再能使用上述特殊的字符，比如 <code>[x*]</code>，* 不再匹配任意次 x，这个表达式只能匹配 * 或 x；同理比如：<code>[\s]</code> 表示 \ 或者 s。</li>
<li><code>[ ]</code> 中可以使用一些特定的范围，比如 0-9，a-z，A-Z。比如式子 [0-9A-Z] 也是合理的，会匹配数字或者大写字母，如需要匹配‘-’，尽量写在最后。</li>
</ol>
<h3 id="指定表达式的重复次数"><a href="#指定表达式的重复次数" class="headerlink" title="指定表达式的重复次数"></a>指定表达式的重复次数</h3><p>在需要重复一个特定的正则表达式的时候，我们可以使用限定符描述重复次数来简化它。</p>
<ul>
<li><strong><code>{n}</code></strong>  匹配 n 次，如 <code>C{3}</code> 即 CCC。</li>
<li><strong><code>{n,}</code></strong>  匹配大于等于 n 次。如 <code>C{1,}</code> 等同于 C+</li>
<li><strong><code>{n,m}</code></strong>  匹配大于等于 n 次，小于等于 m 次，闭区间。</li>
<li><strong><code>*</code></strong>  等同于 <code>{0,}</code></li>
<li><strong><code>+</code></strong>  等同于 <code>{1,}</code></li>
<li><strong><code>?</code></strong>  等同于 <code>{0,1}</code></li>
</ul>
<h2 id="利用正则匹配的缓存"><a href="#利用正则匹配的缓存" class="headerlink" title="利用正则匹配的缓存"></a>利用正则匹配的缓存</h2><ul>
<li><strong><code>\num</code></strong>  使用 <code>( )</code> 之后会进行匹配值的缓存，可以紧跟着 <code>\num</code> 指定匹配的子项，比如 <code>(.)\1</code> 可以匹配任意两个相同的字符。或者在 sed，vim 等工具使用替换操作时，可以在新字符串上使用 <code>\num</code> 以期达到精确的匹配但是局部替换的效果。</li>
<li><strong><code>(?:pattern)</code></strong>  使用该符号会取消匹配值的缓存</li>
<li><strong><code>(?=pattern)</code></strong>  正向肯定预查，使用该符号会取消匹配值的缓存，同时预查也是不消耗字符的。</li>
<li><strong><code>(?!pattern)</code></strong>  反向预查，相反于前者</li>
</ul>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Regex</tag>
      </tags>
  </entry>
  <entry>
    <title>虚拟机中的锁膨胀</title>
    <url>/2018/06/%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E7%9A%84%E9%94%81%E8%86%A8%E8%83%80/</url>
    <content><![CDATA[<p>尽管当下几乎所有的服务器环境都以集群为主，在考虑并发问题的时候通常会使用分布式技术,如 redis 等中间件来维护全局的资源和锁。但是对于一些实例层面上的资源，依旧需要使用传统的锁来维护。所以我觉得，理解 JVM 对锁的处理还是有价值的。</p>
<p>JVM上针对锁的处理（这里只描述内部锁，即 <code>synchronized</code> 的处理情况），除了有<strong>自旋锁</strong>，<strong>锁粗化</strong>，<strong>锁消除</strong>等简单的自动优化机制（不探讨啦），还可以从锁的维护的角度去看，可以分为<strong>偏向锁</strong>，<strong>轻量级锁</strong>，<strong>重量级锁</strong>。<br><em>三者的开销是递增的，演变顺序也是递增的，而且不可逆。</em><br>如轻型的锁可以膨胀升级至重型锁，但是不可以从重型的锁降级。</p>
<a id="more"></a>

<p>之所以有不同程度的锁的处理方式，可以看一下这一个场景：如果在逻辑上某一时间基本只有一个线程，会访问由某个锁对象控制的同步块，很多时候不存在资源征用的问题。那么在这个时候，很多时候上锁解锁的开销就显得繁琐而低效了。以重量级锁（也是 <code>synchronized</code> 的最终形态）为例，取锁过程需要操作系统的介入，使线程从用户态进入核心态，开销还是挺大的。所以一开始 JVM 会对锁做偏向锁处理，在一些条件下升至轻量级锁乃至重量级锁。</p>
<h3 id="前置概念"><a href="#前置概念" class="headerlink" title="前置概念"></a>前置概念</h3><p>在阐述锁膨胀之前，先插入几个内容点，<strong>对象头</strong>和<strong>自旋锁</strong>。</p>
<h4 id="对象头"><a href="#对象头" class="headerlink" title="对象头"></a>对象头</h4><p>在 HotSpot 虚拟机中，对象在内存中存储的布局可以分为三块区域：<strong>对象头</strong>（Header）、<strong>实例数据</strong>（Instance Data）和<strong>对齐填充</strong>（Padding）。 </p>
<p>实例数据内容和对齐填充不在赘述，说说对象头，这就类似一个对象的元信息，其中也分为三部分组成：<strong>标记字段</strong> Mark Word，<strong>类型指针</strong> Class Pointer，<strong>数组长度</strong> Array Length（如果该对象是数组，则记录了数组长度），三组数据分别用一个字长来存储（32位机上为32bit，64位机位64bit）。</p>
<ul>
<li><strong><em>类型指针</em></strong>：<br>在虚拟机加载类的时候，除了会在元空间/方法区存储类信息，也会在堆区生成一个 Class 对象。类型指针，便是为一个实例对象指向 Class 对象的指针。</li>
<li><strong><em>标记字段</em></strong>：<br>在这一个字的区域内，描述了很多信息。通常一个对象会有其哈希码，年代标记（经历 GC 次数），锁标识等。但是如果该对象充当了一个上锁对象，情况会有所不同，下文详述。</li>
</ul>
<p><img src="/images/%E5%AF%B9%E8%B1%A1%E5%A4%B4.jpg" alt="对象头示意图"></p>
<h4 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h4><p>通常来说，取锁时候如果未能获得锁，线程会进入<em>阻塞状态</em>（Blocking），同时会让线程进入等待队列/同步块的入口集中，并导致一个<em>上下文切换</em>，出让 CPU 资源。<br>我们可以实现一个忙轮询的机制来尝试获得锁。比如使用一个状态对象来代替锁，使用一个循环来判断状态是否未可用，如下是代码层面的实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">boolean</span> flag = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span>(flag) &#123;</span><br><span class="line">	<span class="comment">// do something</span></span><br><span class="line">	<span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这可以避免在首次取得锁失败的时候直接线程切出，在同步逻辑处理量较少的时候可以带来明显的效率提升，但是如果如果说“同步块”的处理时间很长，或者在“同步块”内的线程发生异常未能更改状态量，将严重损失性能乃至发生更严重的死锁。</p>
<p><strong>所以自旋锁适合同步逻辑的处理时间很短的场合</strong>（几个循环内能拿到锁）</p>
<h3 id="锁膨胀过程中的三个阶段"><a href="#锁膨胀过程中的三个阶段" class="headerlink" title="锁膨胀过程中的三个阶段"></a>锁膨胀过程中的三个阶段</h3><p>现在已经了解了对象在堆中的存储形式，以及依靠自旋可以在短时间内减少加锁开销。继续深入 JVM 中不同并发程度下锁的不同的机制。</p>
<h4 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h4><p>偏向锁是在 JDK 1.5？1.6 之后对锁进行的优化。先来看一个图：</p>
<p><img src="/images/%E5%81%8F%E5%90%91%E9%94%81%E7%9A%84%E8%8E%B7%E5%BE%97%E5%92%8C%E6%92%A4%E9%94%80.png" alt="偏向锁示意图"></p>
<p>前文提到过，如果一个线程经常获得锁，且资源争用不严重，那么可以尽量减少取锁的开销。JDK 是这么做的：<br>在一个线程获得锁的时候，会在栈帧记录中以及锁对象的标记字段中写入线程 id，在该线程进入/离开同步块的时候不需要额外的锁开销，这里甚至不需要 CAS 操作，因为只需要比较标记字段中的线程 id 与自身是否一致。如果在尝试获得锁的时候发现标记字段中的线程 id 与自身不一致，会尝试利用 CAS 操作来争抢这个偏向锁。</p>
<p>补充：偏向锁是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用 JVM 参数来关闭延迟 <code>-XX:BiasedLockingStartupDelay=0</code>。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，甚至可以通过 JVM 参数关闭偏向锁 <code>-XX:-UseBiasedLocking=false</code>，那么所有的内部锁都会直接进入轻量级锁状态。</p>
<h4 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h4><p>线程在执行同步块之前，JVM 会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的标记字段复制到锁记录中。然后线程尝试使用 CAS 将对象头中的标记字段替换为指向锁记录的指针。如果成功，当前线程获得锁；如果失败，则进行自旋来获取锁，当自旋获取锁仍然失败时，表示竞争严重（两条或两条以上的线程竞争同一个锁），则轻量级锁会膨胀成重量级锁。</p>
<p><img src="/images/%E8%BD%BB%E9%87%8F%E7%BA%A7%E9%94%81%E8%86%A8%E8%83%80.png" alt="轻量级锁膨胀示意图"></p>
<h4 id="重量级锁"><a href="#重量级锁" class="headerlink" title="重量级锁"></a>重量级锁</h4><p>重量级锁其实才是通常涉及的锁概念，这时候它已经是一个彻底的<em>悲观锁</em>了。在 JVM 中又叫<strong>对象监视器</strong>，它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。</p>
<p><img src="/images/%E9%94%81%E5%85%B3%E7%B3%BB.png" alt="锁关系示意图"></p>
<h6 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h6><ol>
<li>《Java多线程编程实战指南》 黄文海</li>
<li>《深入理解Java虚拟机》 周志明</li>
<li><a href="https://www.cnblogs.com/wade-luffy/p/5969418.html" target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/wade-luffy/p/5969418.html</a></li>
<li><a href="https://blog.csdn.net/wolegequdidiao/article/details/45116141" target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/wolegequdidiao/article/details/45116141</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
</search>

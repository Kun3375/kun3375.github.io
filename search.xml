<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RocketMQ 服务端消息过滤]]></title>
    <url>%2F2018%2F08%2FRocketMQ-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B6%88%E6%81%AF%E8%BF%87%E6%BB%A4%2F</url>
    <content type="text"><![CDATA[在服务端进行消息过滤，可以减少不必要的流量，提高带宽利用度和吞吐量。RocketMQ 支持多种方式来进行服务端的消息过滤 消息使用 Tag 标签作为一条 Message，它有着特定的 Topic，同时也可以指定唯一的 Tag 标记子分类。消费方在订阅消息时候，Broker 可以在指定 Topic 的 ConsumeQueue 下按 Tag 进行过滤，只从 CommitLog 中取出 Tag 命中的消息。使用 Tag 进行过滤是高效的，因为消息在 MessageQueue 的存储格式如下： CommitLog Offset：顾名思义，保存着在 CommitLog 中的偏移量，占用 8 个字节 Size：使用 4 个字节来记录消息的大小 Message Tag HashCode：记录对应消息的 Tag 的哈希 在获取消息时候，通过 Tag HashCode 的对比，从 CommitLog 读取对应消息。由于哈希冲突实际上是不可避免的，消息在从 CommitLog 中拉取之后被消费之前，仍然会进行 Tag 的完整对比，以消除潜在哈希冲突问题 携带 MessageKey 来发送和查询其实这部分内容并不属于服务端消息过滤的功能，但是也为我们提供了一种较精确的查询指定消息的功能。在发送消息之前可以为消息设定指定的 Key，通常这个 Key 是在业务层面是唯一的：12Message msg = new Message("Topic", "Tag", "Content".getBytes());msg.setKey(uniqueKey); 尽管 Broker 不会对消息进行 Key 相关的过滤，但是会为消息定制相应的索引。看一下索引格式： Key HashCode：4 个字节的 Key 的哈希，用来快速检索 CommitLog Offset：8 个字节来保存 CommitLog 中的偏移量 Timestamp：使用 4 个字节记录消息存储时间和产生时间的时间差 Next Index Offset：使用 4 个字节来记录下一索引的偏移量在存储 Key 相应的索引时候，其实分了多个哈希桶来（Slot）存储，也就是相对 Key 进行了两次散列。怎么解决哈希冲突？因为索引结构中保存了 Key 的哈希，所以对于哈希值不同而模数相同的 Key 在查询时候可以直接区分开来。对于哈希值相等但是 Key 本身不相等的情况，客户端继续做一次 Key 比较来进行筛选。一般应用中进行消息过滤使用 Tag，而使用命令行工具 mqadmin 做运维时查询特定 Key 的消息，用法：1mqadmin queryMsgByKey -k &lt;Key&gt; -n &lt;NamesrvAddr&gt; -t &lt;Topic&gt; -f &lt;endTime&gt; 使用 MessageId 来查询消息每次消息成功发送后，都会生产一个 MsgId 和 OffsetMsgId，来标识这条消息：123456Message msg = new Message("Topic", "Tag", "Content".getBytes());SendResult result = producer.send(msg);// producer 产生的 idString msgId = result.getMsgId();// broker 产生的 idString offsetMsgId = result.getOffsetMsgId(); 对于 MsgId，由 producer ip + pid + MessageClientIDSetter.class.getClassLoader().hashCode() + time + counter 组成 而对于 OffsetMsgId，由 broker ip + CommitLog Offset 组成，可以精确地定位消息存储的位置 同时我们可以使用运维工具 mqadmin 针对 OffsetMsgId 进行检索1mqadmin queryMsgById -n &lt;NamesrvAddr&gt; -I &lt;OffsetMsgId&gt; 使用自定义属性和类 SQL 过滤在发送消息前，我们可以为消息设置自定义的属性：123Message msg = new Message("Topic", "Tag", "Content".getBytes());msg.putUserProperty("p1", "v1");msg.putUserProperty("p2", "v2"); 在服务端进行消费时候，可以针对自定义属性，利用类 SQL 的表达式来进行消息的进一步筛选：1consumer.subscribe("Topic", MessageSelector.bySql("p1 = v1"); 使用这样的方式进行过滤，需要 Broker 先从 CommitLog 中取出消息，得到消息中的自定义属性进行对应的计算。理所当然的，功能很强大，但是效率没有使用 Tag 的过滤方式高。 对于表达式的语法支持如下： 对比操作： 数字：&gt;, &lt;, &lt;=, &gt;=, =, BETWEEN 字符串：=, &lt;&gt;, IN 空值判断：IS NULL, IS NOT NULL 逻辑判断：AND, OR, NOT 数据类型： 数字：123，456 字符串：’abc’, ‘def’, 必须使用单引号 空值：NULL 布尔：TRUE，FALSE 使用自定义代码和 Filter Server对于 Filter Server，事实上实在 Broker 所在服务器启动了多个类似中转代理的进程，这几个进程负责充当 Consumer 从 Broker 上拉取代码，使用用户上传的 Java 代码进行过滤，最后传送给消费者。这个中转代理会和 Broker 本身争抢 CPU 资源，需要按需求谨慎使用；同时用于过滤的代码需要严格的审查，避免可能影响 Broker 宕机的风险操作。这个过滤操作只支持 PushConsumer使用流程： 启动 Broker 时指定 filterServerNums=&lt;n&gt;，当然使用配置文件也可以。n 的数量就是中转代理 FilterServer 的进程数 实现 org.apache.rocketmq.common.filter.MessageFilter 接口，定制过滤逻辑 接收消息：PushConsumer.subscribe(final String topic, final String fullClassName, final String filterClassSource) filterClassSource 是前一步 MessageFilter 接口实现的源码，必须使用 utf-8 编码。这会在 Consumer 启动时将过滤逻辑上传至 Broker 参考： MessageId 生成解读 https://www.cnblogs.com/linlinismine/p/9184917.html]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 日志设置]]></title>
    <url>%2F2018%2F08%2FRocketMQ-%E6%97%A5%E5%BF%97%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[日志配置文件位置RocketMQ 日志基于 slf4j 实现，支持 Logback、Log4j。如果需要指定日志的配置文件的位置有三种方式： 环境变量：ROCKETMQ_CLIENT_LOG_CONFIGFILE=&lt;custom-file&gt; 启动参数：rocketmq.client.log.configFile=&lt;customer-file&gt;，作为 JVM 变量，启动时时需要增加 -D 标识，优先级也比环境变量更高 作为 Java 实现，日志位置信息是通过 System.getProperty() 或者 System,getenv() 得到的，所以可以在程序入口 System.setProperty(“rocketmq.client.log.configFile”, customer_file) 来配置 日志相关系统变量 rocketmq.client.log.loadconfig默认 true，是否加载指定配置文件，当设置为 false 时，RocketMQ 客户端会会使用应用本身的日志配置。这可能反而是最简单的日志配置方式 rocketmq.client.log4j.resource.fileName、rocketmq.client.logback.resource.fileName、 rocketmq.client.log4j2.resource.fileName三种日志框架的的配置文件名，默认值分别为 log4j_rocketmq_client.xml、logback_rocketmq_client.xml、log4j2_rocketmq_client.xml rocketmq.client.log.configFile日志配置文件路径，上述。如果使用了自定义的日志配置文件，通常你不再需要设置以下的变量了 rocketmq.client.logRootRocketMQ 日志信息默认存放日志为：$USER_HOME/Logs/rocketmqLogs，通过改变此变量可以变更日志路径 rocketmq.client.logLevel日志输出级别，默认 INFO rocketmq.client.logFileMaxIndex滚动窗口的索引最大值，默认 10]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ Producer 摘要]]></title>
    <url>%2F2018%2F08%2FRocketMQ-Producer-%E6%91%98%E8%A6%81%2F</url>
    <content type="text"><![CDATA[上一篇介绍完了 RocketMQ 消费者的默认实现，现在来瞅一瞅生产者的用法。 设置必要的属性同样的，是 DefaultMQProducer，新建实例之后，在使用生产者发送消息之前，需要初始化几个属性： InstanceName 实例名称这是为了当一个 JVM 上启动了多个生产者时，区分不同的生产者实例，系统默认名称为 DEFAULT RetryTimesWhenSendFailed 重试次数当消息投递失败时，有可能是因为网络原因，可以设置多投递几次减少丢消息的情况。很多实用者在使用时，为了避免重复的消息设置不重试是不正确的做法：因为 RocketMQ 本身并不保证消息的不重复，作为客户端对消息进行幂等处理是必要的。而在次前提下，对发送失败的场景拒绝重发，不仅对避免重复消息没有任何意义，同时也增加了消息的丢失的可能。 NamesrvAddr需要 NameServer 的地址，写法和 Consumer 一致 消息发送方式和投递结果发送方式 同步发送：Producer.send(Message message) 异步发送：Producer.send(Message message, SendCallback callback) 发送结果对于消息发送的结果，存在四中可能返回的状态。而且在不同的配置方式下，意义可能有所不同 SEND_OK发送成功，标志着消息已经成功被发送到 Broker。（这时候不一定意味着主从复制完成或者刷盘完成） FLUSH_DISK_TIMEOUT刷盘时间超时，只有在刷盘策略为 SYNC_FLUSH 时才可能出现 FLUSH_SLAVE_TIMEOUT主从同步时间超时，只有在主备形式下使用 SYNC_MASTER 才可能出现 SLAVE_NOT_AVAILABLE从机缺失，只有在主备形式下使用 SYNC_MASTER 才可能出现，类似于 FLUSH_SLAVE_TIMEOUT对于不同的业务场景具体需求，如何处理消息发送的结果是程序质量的一个重要考量点 特殊的消息延迟消息RocketMQ 支持延迟消息，Broker 收到消息后并不会立即投递，而是等待一段时间后再讲消息送出去。 使用方式：在消息发送前执行 Message.setDelayTimeLevel(int level) 延迟等级：默认 1s/5s/10s/30s/1m/2m/3m/4m/5m/6m/7m/8m/9m/10m/20m/30m/1h/2h，索引 1 开始尽管 RocketMQ 的延迟消息不支持任意精度，但是各等级的延迟是可以预设的，更改配置文件即可 队列选择对于一个 Topic 通常有多个 MessageQueue 来接收消息，默认情况下 Producer 轮流向各个 MessageQueue 发送消息，而 Consumer 根据默认的负载策略进行消费，所以无法明确对应 Producer 的消息是哪个 Consumer 消费。在需要指定特定 MessageQueue 来投递消息时，可以实现 MessageQueueSelector 接口，定制选择逻辑；发送时选择带有选择器的重载方法即可 事务消息介绍事务消息是必要的，但是并不推荐使用。因为事务消息会造成磁盘脏页，影响磁盘性能，在 4.x 版本中已经移除，需要使用时需要手动根据顶层接口实现。简单的说，RocketMQ 的事务消息流程如下： 向 Broker 发送消息（消息状态为未确认状态） Broker 对收到的消息完成持久化，返回成功状态。发送的第一阶段结束 执行本地逻辑 事务消息的结束 本地逻辑结束，客户端向 Broker 确认消息 commit：提交，该消息将会被 Broker 进行投递 rollback：回滚，Broker 会删除之前接收到的消息 超过一定时间，服务端对客户端发起回查请求Producer 对回查请求返回 commit 或者 rollback 的响应。如果此时发送消息的 Producer 无法访问，回查请求会发送给同一 ProducerGroup 内的其他 Producer 参考 RocketMQ on GitHub 《RocketMQ 实战与原理解析》机械工业出版社 杨开元]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ Consumer 摘要]]></title>
    <url>%2F2018%2F08%2FRocketMQ-Consumer-%E6%91%98%E8%A6%81%2F</url>
    <content type="text"><![CDATA[结束了对 RocketMQ 组件的初步理解以及配置的简单设定，可以对 RocketMQ 仔细研究一番了。先来看看 RocketMQ 的消费者实现，以及服务端是如何处理消费者客户端的请求，把消息送出去的。 RocketMQ 对于消费者客户端，支持推模型和拉模型。对于推模型，由消息服务端作为主动方，向客户端推送消息（尽管其本质是一个长轮询式的拉模型实现）；而拉模型由客户端主动拉取消息。 PushConsumer客户端的实现：DefaultMQPushConsumerImpl 是客户端的一个默认实现，可以从 pullMessage() 方法切入，观察它的实现。 基本要素：以下几个属性，不仅仅是推模型的重要配置，同时也称得上是每个客户端的标配。 NameServerAddr指定 NameServer 地址是必要的，可以通过客户端 API 设置（使用 ; 分割多个地址），或者使用环境变量 NAMESRV_ADDR ConsumerGroup将多个消费者组织一起，提高并发，需要配合 MessageModel 属性一起使用 MessageModel消息模式分为两种，集群模式：Clustering；广播模式：Broadcasting Clustering：集群模式，所订阅 Topic 下的消息，每一条只会被同一 ConsumerGroup 下的一个消费者所消费，达到负载均衡的目的 Broadcasting：广播模式，同一 ConsumerGroup 下的每一个 Consumer 都会消费到所订阅 Topic 下的全部消息。 Topic消息类型主题，作为不同消息的标识，决定了消费者订阅哪些消息。Topic 默认是可以由客户端创建的，生产环境下通常改权限被关闭，需要使用 mqadmin 工具来初始化可用的 Topic TagTag 可以进一步过滤消费需要订阅的消息，在 Java 客户端 API 下，使用 null 或者 * 来消费所有 Tag 类型，需要具体指定时可以使用 || 来分割多个 Tag 服务端推送方式：消费者的推模型是通过长轮询实现的，因为完全的推模型方式会使得服务端增加许多压力，明显的降低效率，同时也会因为各客户端消费能力不足的问题造成隐患。Broker 服务端在处理客户端请求时如果发现没有消息，会休眠一小会-短轮询间隔（shortPollingTimeMills），重复循环，直到超过最大等待时间（brokerSuspendMaxTimeMills），在此期间内的收到消息会立即发送给客户端，达到“推”的效果 客户端流量控制：客户端维护了一个线程池来接受服务端“推”来的消息，针对每个 MessageQueue 都有使用一个 ProcessQueue 来保存快照状态和处理逻辑。ProcessQueue 主要由一个 TreeMap 和读写锁组成 ProcessQueue.lockTreeMap 保存了所有获取后还没有被消费的消息 Key：MessageQueue‘s offset Value：消息内容引用 DefaultMQPushConsumerImpl.pullMessage() 会检查以下每个属性，任意属性超过阈值会暂缓拉取动作。由于通过 ProcessQueue 的信息来比较，检查域是每个 Queue cachedMessageCount检查当前缓存的但是未消费的消息数量是否大于设定值（pullThresholdForQueue，默认 1000） cachedMessageSizeInMiB同上，检查队列中消息缓存的大小（pullThresholdSizeForQueue，默认 100MiB） maxSpan检查 ProcessQueue 中未消费消息的 offset 跨度（consumeConcurrentlyMaxSpan，默认 200），在顺序消费时不检查 PullConsumer客户端的实现：初次接触，可以从这几个方法了解 PullConsumer 的消息拉取思路，并从官方的几个例子中了解一些常用的处理方式。 前置操作 DefaultMQPullConsumerImpl.fetchSubscribeMessageQueues() DefaultMQPullConsumerImpl.fetchConsumerOffset() DefaultMQPullConsumerImpl.fetchMessageQueuesInBalance() 拉取动作 DefaultMQPullConsumerImpl.pull() DefaultMQPullConsumerImpl.pullBlockIfNotFound() 客户端额外操作：在使用 PullConsumer 时候，通常使用需要额外关心 MessageQueue 和 offset 等一些要素，灵活的封装可以带来更多的自主性。以 fetchSubscribeMessageQueues() 和 pull() 方法说明几个要素： MessageQueue一个 Topic 下通常会使用多个 MessageQueue，如果需要获取全部消息，需要遍历返回的所有队列。特殊情况下可以针对特定队列消费 Offsetstore使用者需要手动记录和操作消息偏移量，随着消息消费而改变它，需要额外注意他的持久化，正确的偏移量是准确消费的前提 PullStatus针对某队列的拉取动作结束，会返回相应状态，使用者需要针对不同状态采取不同的动作 FOUND NO_MATCHED_MSG NO_NEW_MSG OFFSET_ILLEGAL shutDown()关闭操作会进行保存 offset 的操作，在 NameServer 注销客户端的操作等。对于保存的 offset 可以通过 OffsetStore 对象获取，启动时加载。 参考 RocketMQ on GitHub 《RocketMQ 实战与原理解析》机械工业出版社 杨开元]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RokcetMQ 配置项]]></title>
    <url>%2F2018%2F08%2FRocketMQ-%E9%85%8D%E7%BD%AE%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[RocketMQ 的配置分为两部分，一者是 JVM 的配合，另一者则是对 Broker 应用本身的参数配置。在初次接触时候，除了 RocketMQ 本身的一些特性，同时也难免会被一些配置给迷惑或者踩坑，这里来看一下通常的配置点。 Broker JVM 配置JVM 的配置默认不需要修改，只需要根据硬件情况调整相应的堆栈内存和对外内存的占用量即可。附上启动时的 JVM 配置脚本片段：123456789101112JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC"JAVA_OPT="$&#123;JAVA_OPT&#125; -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-OmitStackTraceInFastThrow"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+AlwaysPreTouch"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:MaxDirectMemorySize=15g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-UseLargePages -XX:-UseBiasedLocking"JAVA_OPT="$&#123;JAVA_OPT&#125; -Djava.ext.dirs=$&#123;BASE_DIR&#125;/lib"#JAVA_OPT="$&#123;JAVA_OPT&#125; -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"JAVA_OPT="$&#123;JAVA_OPT&#125; $&#123;JAVA_OPT_EXT&#125;"JAVA_OPT="$&#123;JAVA_OPT&#125; -cp $&#123;CLASSPATH&#125;" 需要额外关注的点在于： -Xms8g -Xmx8g -Xmn4g 默认 Broker 需要 8g 的堆内存，不要轻易在自己的笔记本上运行哦 😂 -XX:MaxDirectMemorySize=15g 默认的最大堆外内存为 15g，nio 通过内存映射文件所提高 IO 效率而用。 JAVA_OPT_EXT 该环境变量可以追加和替换原有的配置 Broker 应用配置自定义配置启动启动 Broker 时可以自定义配置：sh bin/mqbroker -c CONFIG.properties 配置可选项 获取可配置项的列表：sh bin/mqbroker -m 获取配置项以及默认值：sh bin/mqbroker -p 源码中配置类：BrokerConfig / NettyServerConfig / NettyClientConfig / MessageStoreConfig 配置参数介绍介绍几个常用的，或者说通常需要配置的选项。 namesrvAddr=IP:PORT;IP:PORT配置 NameServer 的地址，多个地址间使用 ; 隔开，该选项没有默认值，可以启动时通过 -n 参数设置 brokerClusterName=DefaultCluster配置 RocketMQ 集群的名称，默认为 DefaultCluster brokerName=broker-aBroker 的名称，在同一 NameServer 群下，只有使用相同的 brokerName 的 Broker 实例才可以组成主从关系 brokerId=0在一个 Broker 群下（都使用了同样的 brokerName），所有实例通过 brokerId 来区分主从，主机只有一个：brokerId=0（默认） fileReservedTime=48消息数据在磁盘上保存的时间，单位：小时，默认：48 deleteWhen=04在指定的时间删除那些超过了保存期限的消息，标识小时数，默认：凌晨 4 时 brokerRole=SYNC_MASTER有三种选项，前两者主要描述 Broker 实例间的同步机制 SYNC_MASTERBroker Master 的选项，消息同步给 Slave 之后才返回发送成功状态 ASYNC_MASTERBroker Master 的选项，主从间消息同步异步处理 SLAVEBroker Slave 的选项（没得选） flushDiskType=ASYNC_FLUSH有两种选项，分别同步或异步的刷盘策略 SYNC_FLUSH消息只有在真正写入磁盘之后才会返回成功状态，牺牲性能，但可以确保不丢失消息 ASYNC_FLUSH异步刷盘，消息写入 page_cache 后即返回成功 brokerIP1=127.0.0.1设置 Broker 对外暴露的 IP，通常 Broker 启动时会自动探测，但是由于容器环境或者多网卡的影响，通常需要手动设置。需要多个暴露 IP 时，可以使用 brokerIP2/3/4/... 的方式配置 listenPort=10911Broker 实例监听的端口号 storePathRootDir=/home/rocketmq/store-a存储消息和一些配置的根目录 参考 RocketMQ on GitHub 《RocketMQ 实战与原理解析》机械工业出版社 杨开元]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 配置探索]]></title>
    <url>%2F2018%2F07%2FRocketMQ-%E9%85%8D%E7%BD%AE%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[目前被广泛使用的 MQ 有很多，包括 ActiveMQ，Kafka，RabbitMQ，RocketMQ 等等，它们各有长短。而近期所在项目选择了 RocketMQ 作为消息中间件，此前并未系统地了解研究，所以趁此机会整理了一些笔记和想法。 优势简单地说一下在这么多消息中间件中的选型优势。作为阿里的开源项目，想必还是可靠的，尤其是经受过双十一的考验令人信服。 支持严格的消息顺序； 支持 Topic 与 Queue 两种模式； 亿级消息堆积能力； 比较友好的分布式特性； 同时支持 Push 与 Pull 方式消费消息； 基本概念 Producer：消息生产者，生产消息。 Consumer：消息消费者，消费消息。 Pull Consumer：消费者拉模型的实现。通过与 Broker 建立长连接，从中主动拉取消息。 Push Consumer：消费者推模型的实现。本质仍然是建立长连接，但是通过注册监听器，在收到消息时回调监听方法。 Producer Group：生产者集合，通常包含发送逻辑一致的消费者，影响事务消息的流程。 Consumer Group：消费者集合，通常包含消费逻辑一致的消费者，影响着负载均衡和集群消息。 Name Server：注册服务器，可以由一到多个近乎无状态的节点构成，扮演者类似 Zookeeper 的角色。Broker 向其中注册，而 Producer 和 Consumer 向其中拉取 Broker 地址。 Broker：核心组件，保存和转发消息。 拓扑结构如下： 初次使用下载RocketMQ 是纯 Java 语言的实现，你可以从 Github 上下载源码并使用 Maven 进行编译，当然也可以从官网入口下载。 启动第一次启动，简单地测试一下效果，进入 bin 目录，使用 nohup 启动一下 NameService： nohup ./mqnamesrv -n 127.0.0.1:9876 &amp; 然后启动一下 Broker： nohup ./mqbroker -n 127.0.0.1:9876 &amp; 还有一个 mqadmin 也是常用的工具，包含的管理员常用的功能，包含查看集群列表，查看、删除主题等，可以直接通过 ./mqadmin 获得帮助。 测试在 RocketMQ 顺利启动之后，进行一下测试吧，快速的体验一把。从 MavenRepository 找到对应的 RocketMQ 客户端：123456&lt;!-- https://mvnrepository.com/artifact/org.apache.rocketmq/rocketmq-client --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt; 或者打开刚才从 Github 上下载的源码，example 模块下提供了许多测试用例，附上略微改动的生产者和消费者代码： 生产者 123456789101112131415161718192021222324252627282930public static void main(String[] args) throws MQClientException, InterruptedException &#123; DefaultMQProducer producer = new DefaultMQProducer("ProducerGroupName"); producer.setNamesrvAddr("127.0.0.1:9876"); producer.setInstanceName("p001"); // 可以设定失败重试次数 producer.setRetryTimesWhenSendFailed(3); producer.start(); for (int i = 0; i &lt; 1; i++) &#123; try &#123; Message msg = new Message( "TopicTest1", "TagA", "key113", "Hello world".getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg); System.out.printf("%s%n", sendResult); QueryResult queryMessage = producer.queryMessage("TopicTest1", "key113", 10, 0, System.currentTimeMillis()); for (MessageExt m : queryMessage.getMessageList()) &#123; System.out.printf("%s%n", m); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; producer.shutdown();&#125; 消费者 1234567891011121314151617181920212223242526public static void main(String[] args) throws InterruptedException, MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("ConsumerGroupName"); // 指定 NameServer 的地址，多个 NameServer 使用 ; 隔开 consumer.setNamesrvAddr("127.0.0.1:9876"); consumer.setInstanceName("c001"); // 指定订阅的 Topic 以及 Tag，多个 Tag 使用 || 分开，* 代表全部 Tag consumer.subscribe("TopicATest1", "TagA"); // 可以设定开始消费的位置，仅针对 Push Consumer consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); // 可以设定批量消费数量，默认 1，不保证每次的数量，近针对 Push Consumer consumer.setConsumeMessageBatchMaxSize(1); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; for (MessageExt msg : msgs) &#123; System.out.println(new String(msg.getBody())); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); System.out.println("Consumer Started.");&#125; 动手运行一下吧。 关于配置事实上，大多数小伙伴在 RocketMQ 启动时都明显能感觉电脑卡卡的，是因为 RocketMQ 默认需求的内存太大了。那么，如何查看和修订所需要的配置呢？之前我们通过 ./mqbroker 启动了 Broker，那么来看一下 mqbroker 的脚本，注意脚本末尾的命令：12# 省略 ROCKETMQ_HOME 的配置sh $&#123;ROCKETMQ_HOME&#125;/bin/runbroker.sh org.apache.rocketmq.broker.BrokerStartup $@ 这里将启动命令转移给了 runbroker.sh 进行执行。 JVM 参数配置既然如此，继续查看一下 runbroker.sh：12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/sh#===========================================================================================# Java Environment Setting#===========================================================================================error_exit ()&#123; echo "ERROR: $1 !!" exit 1&#125;[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=$HOME/jdk/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; JAVA_HOME=/usr/java[ ! -e "$JAVA_HOME/bin/java" ] &amp;&amp; error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!"export JAVA_HOMEexport JAVA="$JAVA_HOME/bin/java"export BASE_DIR=$(dirname $0)/..export CLASSPATH=.:$&#123;BASE_DIR&#125;/conf:$&#123;CLASSPATH&#125;#===========================================================================================# JVM Configuration#===========================================================================================JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -XX:SurvivorRatio=8 -XX:+DisableExplicitGC"JAVA_OPT="$&#123;JAVA_OPT&#125; -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-OmitStackTraceInFastThrow"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+AlwaysPreTouch"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:MaxDirectMemorySize=15g"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:-UseLargePages -XX:-UseBiasedLocking"JAVA_OPT="$&#123;JAVA_OPT&#125; -Djava.ext.dirs=$&#123;BASE_DIR&#125;/lib"#JAVA_OPT="$&#123;JAVA_OPT&#125; -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n"JAVA_OPT="$&#123;JAVA_OPT&#125; $&#123;JAVA_OPT_EXT&#125;"JAVA_OPT="$&#123;JAVA_OPT&#125; -cp $&#123;CLASSPATH&#125;"numactl --interleave=all pwd &gt; /dev/null 2&gt;&amp;1if [ $? -eq 0 ]then if [ -z "$RMQ_NUMA_NODE" ] ; then numactl --interleave=all $JAVA $&#123;JAVA_OPT&#125; $@ else numactl --cpunodebind=$RMQ_NUMA_NODE --membind=$RMQ_NUMA_NODE $JAVA $&#123;JAVA_OPT&#125; $@ fielse $JAVA $&#123;JAVA_OPT&#125; $@fi 通过这个文件可以获得很多信息： RocketMQ 的 JVM 配置信息 需求的内存空间达到了 8g，声明的最大堆外内存达到了 15g，这就是电脑变得卡卡的的原因了。 可以在启动时配置 JAVA_OPT_EXT 变量来配置额外的参数或者覆盖默认配置。 结合 mqbroker.sh 可以发现，最终使用了 BrokerStartup 来启动 RocketMQ，命令行中的参数同时会被传递。 Broker 实例配置那么接下来就去 BrokerStartup 查看一下 RocketMQ 的启动过程。由于这个文件实在是太过冗长，这里不再贴出，感兴趣的小伙伴请自行查看。在这个文件中，主要对命令行中几个具体参数进行了解析： -m：列出所有的配置项 -p：列出所有的配置项以及默认值 -c：指定一个 properties 文件，读取其中的内容覆盖默认配置并情动 自定义配置所以，很多时候的做法是通过 sh mqbroker -p &gt; mqbroker.properties 来获得一份默认配置文件（网上的方案可能不太准确，具体输出是携带 Rocket 的日志信息的，需要 sed 或者 awk 之类加工处理一下），在此基础上进行配置自定义，然后通后通过 sh mqbroker -c mqbroker.properties 来进行定制化的启动。 默认配置方案同时在 conf 目录下，官方也给出了几种典型的配置方案供参考： 二主二从异步复制：2m-2s-async 文件夹。这是最典型的生产配置，双 master 获得高可用性，同时主从间的数据同步由异步完成。 二主二从同步复制：2m-2s-sync 文件夹。除了双 master 的配置，主从间的数据是同步的，也就是说只有在向 salve 成功同步数据才会向客户段返回成功。这保证了在 master 宕机时候消息仍然可以被实时消费，但是性能收到一定影响。 二主无从：2m-nosalve 文件夹。双主模式仅仅保证了 RocketMQ 的高可用性，然而在一台 master 宕机后，客户端无法消费那批在宕机 master 上持久化的消息，直到宕机 master 恢复正常。当然这个方案节省了硬件资源。 三种默认配置方案都是采用了异步刷盘，尽管在刷盘间隙宕机会丢失少量数据，但是效率提升可观。 参考配置类Broker 的具体配置分为了具体的四个方面： Broker 实例配置：参考源码 org.apache.rocketmq.common.BrokerConfig Netty 服务端配置：参考源码 org.apache.rocketmq.remoting.netty.NettyServerConfig Netty 客户端配置：参考源码 org.apache.rocketmq.remoting.netty.NettyClientConfig Message 持久化配置：参考源码 org.apache.rocketmq.store.config.MessageStoreConfig 关于 RocketMQ 的启动和配置，就先告一段落。]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
        <tag>RocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现 MyBatis 插件]]></title>
    <url>%2F2018%2F07%2F%E5%AE%9E%E7%8E%B0-MyBatis-%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[MyBatis 作为一个目前很常用的持久化框架，有着丰富的拓展。这些拓展功能常常以插件的形式嵌入到 MyBatis 的运作流程之中，而如何制作实现一个插件？MyBatis 已经为大家设计好了，一个 Interceptor 接口，实现它就够了。 Interceptor 接口的拦截目标，是 MyBatis 运作流程中的几个核心组件： Executor：这是 MyBatis 执行器，控制着所有和数据库交互的操作，也影响着一级缓存。 ParameterHandler：参数处理器，在映射参数时候生效。 ResultSetHandler：结果集处理器，在处理结果集的时候会用到。 StatementHandler：Executor 下层的处理器，同样控制着 SQL 行为，也控制着二级缓存的生效。 这几个组件就简称处理器对象吧，感兴趣的话，可以跟进资料，这里继续来讲插件如何拦截它们以及如何实现一个插件。 Interceptor 接口Interceptor 接口是插件的核心，看一下它的接口：12345678public interface Interceptor &#123; // 拦截后的逻辑 Object intercept(Invocation invocation) throws Throwable; // 将处理器对象包装成代理类 Object plugin(Object target); // 初始化属性赋值 void setProperties(Properties properties);&#125; intercept()：拦截 MyBatis 的执行过程，需要在其中加入定制的逻辑。 plugin()：可以理解为插件的构造过程，通常把 MyBatis 的几个 handler 包装成代理用。 setProperties()：用于插件初始化时候的属性赋值。如果你有其他的赋值方案，也可以不采用它。 我们从第一个方法开始讲起。 Object intercept(Invocation invocation)入参 Invocation 是一个 MyBatis 封装的对象，包含了运行时的信息： 属性Method method：即反射包中的 Method，在这里它是当前运行的方法。 属性Object[] args：方法的参数列表 属性Object target：这里其实是你选择拦截的处理器对象（关于如何选择拦截具体的处理器对象，稍后再述），也就是说，它可以是 Executor / StatementHandler …，需要使用时可以直接强转。 方法 proceed()：让处理器继续流程，或者调用下一个插件，你可以用 Filter.doFilter() 来类比它。 MyBatis 插件是通过动态代理实现的，对处理器对象进行代理，由代理对象在方法 invoke() 前完成插件中 interceptor() 方法（即插件逻辑）。同时多个插件又是多层的代理，每个插件都需要在具体方法调用前完成自己的逻辑，所以在实现 Interceptor 接口的 intercept 方法最后，一定要记得执行 Invocation.proceed()，以完成插件的调用链：1234567@Overridepublic Object intercept(Invocation invocation) throws Throwable &#123; // 可以通过 invocation 获得处理器对象，进而可以变更参数，埋点，收集信息等 // do something // 最后需要记得完成调用链，否则流程将中段 return invocation.proceed();&#125; Object Plugin(Object)该方法在处理器对象初始化的时候，由 InterceptorChain.pluginAll() 调用，将处理器对象包装成代理类。可以理解为一个初始化方法。 以 StatementHandler 举例：1234567891011121314public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); // 初始时触发代理包装 statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125;public Object pluginAll(Object target) &#123; // 迭代完成所有插件代理，最终返回一个包含所有插件逻辑的处理器对象代理 for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target;&#125; 该方法的本质目的是使得新的代理类在拦截的目标方法以及之前的插件逻辑之前添加上新插件的 intercept() 方法中的内容。所以该方法 Object 类型的入参与出参自然也就是处理器接口对象了。在没有特殊需求的情况下，推荐使用官方工具类 Plugin.wrap() 方法来完成：1234@Overridepublic Object plugin(Object target) &#123; return Plugin.wrap(target, this);&#125; 原因嘛…先来看一下 Plugin.wrap()：123456789101112131415161718192021222324252627282930public static Object wrap(Object target, Interceptor interceptor) &#123; // 插件上都通过 @Interceptors 指定了要拦截的处理器，以及要拦截的方法和参数，收集起来 // 获得这个插件想拦截的类-方法 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); // 这个 type 必然是 4 大执行器/处理器 接口实现之一 Class&lt;?&gt; type = target.getClass(); // 获得原来的所实现的接口，动态代理的必要步骤 Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); // 如果该插件没有拦截这个处理器，在上一个方法会返回空数组，这里就不包装了 if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target;&#125;@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &#123; return interceptor.intercept(new Invocation(target, method, args)); &#125; return method.invoke(target, args); &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125;&#125; 好处在于，不在需要开发者手动构建一个动态代理（Plugin 本身就是一个 InvocationHandler 实现类），并且在包装成代理的时候，将四个处理器中不需要拦截的类排除了，这使得运行中减少一层不必要的代理，进而提升效率。 @Intercepts 注解插件的拦截流程都已经明了，回过来梳理一下如何拦截自己想要的指定的处理器和指定的方法呢？ 在实现了 Interceptor 接口之后，需要配合 @Intercpts 注解一起使用。这个注解中需要安置一个 Signature 对象，在其中指定你需要指定： type：选择 4 个处理器类之一。 method：选择了处理器之后，你需要选择拦截那些方法。 args：选择拦截的方法的参数列表。因为如 Executor 中 query 方法是有重载的。 通过以上三者，插件便确定了拦截哪个处理器的哪个方法。MyBatis 的插件实现是不是很简单呢？ 需要注意的是，Exector 和 StatementHandler 在一些功能上类似，但是会影响不同级别的缓存，需要注意。同时由于 sqlSession 中这 4 个处理器对象的功能着实强大，并且可以通过拦截改变整个 SQL 的行为，所以如果需要深入定制插件行为的时候，最好需要对 MyBatis 核心机制由一定的了解。 官方介绍http://www.mybatis.org/mybatis-3/zh/configuration.html#plugins]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 挂载与数据存储]]></title>
    <url>%2F2018%2F07%2FDocker%2F</url>
    <content type="text"><![CDATA[Docker 镜像是层层分离的，分为只读的底层和可读写的当前层。容器在运行时候如果有文件改动，会自动从含有该文件的底层拷贝并更新在当前层。如果容器在 commit 之前被销毁，那么有这个镜像重新生成的容器是不包含改动的内容的。 需求来源所以数据问题是使用 Docker 必然会关注到的，除了如何持久化以外，如何从宿主机访问到容器内的数据？或者将容器内的数据同步到宿主机？又或是多个容器间怎么共享数据？这都是要处理的。 还好 Docker 提供了一套完善而简单的数据挂载机制 Volume。 命名卷要控制容器的数据内容，首先从文件的挂载开始。docker volume 提供了一套管理卷（volume）的 API：12345678910Usage: docker volume COMMANDManage volumesCommands: create Create a volume inspect Display detailed information on one or more volumes ls List volumes prune Remove all unused local volumes rm Remove one or more volumes 先创建一个 named volume：docker volume create vol使用 docker volume ls 可以看到当前存在的所有的 volume。使用 docker volume rm 删除指定的 volume。使用 docker volume inspect vol 可以看到它的详情，包括创建时间和宿主机上的真正挂载位置等： [ { &quot;CreatedAt&quot;: &quot;2018-07-09T14:53:05Z&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: {}, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/vol/_data&quot;, &quot;Name&quot;: &quot;vol&quot;, &quot;Options&quot;: {}, &quot;Scope&quot;: &quot;local&quot; } ] 可以看到这个新建的 vol 保存在 /var/lib/docker/volumes/vol/_data 下，其中 /var/lib/docker/volumes 目录保存了所有的 Docker volume。 运行时挂载使用命名卷有了 volume 之后，我们便可以使用刚才创建的 vol 来挂载容器中的某个目录：1docker run -d -v vol:/data --name temp-redis redis 如此一来，在 temp-redis 容器中 /data 下的改动，都会同步反映在宿主机的 /var/lib/docker/volumes/vol/_data 下；而宿主机的改动亦然。 使用绝对路径使用命名的 volume 通常是为了数据共享，很多时候我们只是想指定一个挂载的目录便于记忆和管理，这个时候可以使用绝对路径，如：1docker run -d -v /data/docker_volume/temp_redis/data:/data --name temp-redis redis 自动挂载有时候你甚至不想关心任何 volume 的形式，你只是想把某个目录持久化而已，可以这么做：1docker run -d -v /data --name temp-redis redis Docker 会自动生成一个匿名的 volume。想要知道具体的宿主机目录可以使用：docker inspect 来查看。这种情况通常在构建纯数据容器时使用。 注意点在 volume 创建时和创建之后仍然需要关注他们，下面是一些典型的问题。 volume 自动创建事实上在 -v vol:/data 时候，vol volume 甚至不需要提前使用 docker volume create vol 创建，使用 docker run -v vol:/data 命令时便会自动创建。同时地，也意味着 -v 选项不支持相对路径的使用。 volume 的删除在一个 volume 被创建之后，想删除可没那么容易，即使使用了 docker rm CONTAINER 删除了容器，volume 依然保留着。除非： 使用 docker run --rm 启动的容器停止时。它除了会删除容器本身还会删除挂载的匿名 volume。 使用 docker rm -v v 参数可以删除容器和创建容器时关联的匿名 volume。 那么我们在使用了 named volume 或者删除容器时忘记了 -v，那么那些在 /var/lib/docker/volumes 下的一些文件就成了僵尸文件。怎么删除呢？ 使用 docker volume rm VOLUME 来删除。 使用 docker volume prune 删除所有不再被使用的 volume。 volume 的只读控制一些场合下，我们提供只是需要容器内的程序去读取一些内容而非修改。我们可以严格的控制 volume，增加只读选项 ro：1234docker run -d \ --name=nginxtest \ -v nginx-vol:/usr/share/nginx/html:ro \ nginx:latest 通过 Dockerfile 挂载可以通过 Dockerfile 在构建镜像的时候便指定需要的 volume，这对于很多应用都是必要的，尤其是一些数据类应用。Dockerfile 中使用 VOLUME 表明挂载目录，如：1VOLUME ["/data1", "/data2"] 任何通过该镜像构建的容器都会将 /data1，/data2 两个目录进行挂载。但是 Dockerfile 形式的弱势是无法进行 named volume 或者绝对路径的挂载。 数据共享与存储共享 volume既然数据可以在宿主机和容器间同步，那么可以使多个容器间同步吗？当然可以！ –volumes-from1234# 首先创建一个容器，并挂载 /datadocker run -d -v /data --name ng1 nginx# 创建第二个容器，共享前者的 volumedocker run -d --volumes-from ng1 --name gn2 nginx named volume1234# 首先创建一个容器，并创建命名卷 share 来挂载 /datadocker run -d -v share:/data --name ng1 nginx# 创建第二个容器，使用同样的 /datadocker run -d -v share:/data --name ng2 nginx 两种方式都能达到数据共享的目的，但是由于通过命名卷的方式对多个容器的依赖进行了解耦，所以推荐第二种。 数据容器这个话题事实上和数据共享紧密相关，由于在 Docker1.9 之前，大家广泛使用使用 --volumes-from 的形式来共享卷，导致必须要一个底层的没有依赖的容器来保存数据。 通常使用和应用容器一样的镜像来构建数据容器 数据容器不需要也不应该启动，仅仅是利用 volume 机制来保持数据而已 然而现在有了命名卷，完全不需要数据容器的存在了，使用 named volume 可以更直接更方便的管理共享数据。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile 中三个运行指令的差异]]></title>
    <url>%2F2018%2F07%2FDockerfile-%E4%B8%AD%E4%B8%89%E4%B8%AA%E8%BF%90%E8%A1%8C%E6%8C%87%E4%BB%A4%E7%9A%84%E5%B7%AE%E5%BC%82%2F</url>
    <content type="text"><![CDATA[在描述 Dockerfile 的时候，对于 RUN，CMD，ENTRYPOINT 三个命令，用法十分相似，功能也差不多，容易让人混用。其实一般来说，三个命令都能完成需要的操作，而差异点常常被一些使用者忽略。这里简单说一下，三个命令的不同之处。 命令格式首先看一下 Dockerfile 中如何执行命令。在 Dockerfile 中，命令（instruction）一般有两种写法，分别是： Shell 格式：INSTRUCTION &lt;command&gt; &lt;option&gt; &lt;param&gt; Exec 格式：INSTRUCTION [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;] 两个格式基本没有差异，除了可读性之外，对于 Shell 格式的命令，Docker 会自动使用 /bin/bash -c 来进行解析，可以是解析命令中的变量比如 $JAVA_HOME。而如果使用 Exec 格式执行时需要解析环境变量，需要进行修改，比如：CMD [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo&quot;, &quot;java home is $JAVA_HOME&quot;]。对于 RUN，CMD，ENTRYPOINT 三者同样遵守此规则。 RUN 命令RUN 命令在 Dockerfile 中可以多次使用，所以通常被用来在构建容器时执行一些必须的前置命令，比如安装软件等。它的出现频率远高于其他两个执行命令。格式： RUN &lt;command&gt; &lt;option&gt; &lt;param&gt; RUN [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;] 带来一个 Shell 风格的安装 Git 的例子：1RUN apt-get update &amp;&amp; apt-get install -y git 这里使用 &amp;&amp; 可以使得在同一层镜像层上更新 apt 并下载 git。 CMD 命令CMD 命令的格式有三种，前两者都是用来定义容器的默认行为，后者用来给 ENTRYPOINT 命令提供额外的可替换参数。 CMD &lt;command&gt; &lt;option&gt; &lt;param&gt; CMD [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;] CMD [&quot;param&quot;...] 先说前两者用作执行默认命令的情况，以一个官方 Nginx 的 Dockerfile 为例：12# 前置步骤忽略CMD ["nginx", "-g", "daemon off;"] 该命令使得以该 Nginx 镜像构建的容器，在启动时候默认地自动运行 Nginx。但是既然是定义默认行为，那么它是可以在运行容器的时候被更改的，比如像下面这样：1sudo docker run -p 80:80 nginx echo hello-world 那么这个时候容器并不会启动一个 Nginx 服务，而是打印了 hello-world。并且这个容器会随着打印命令的结束而停止。 需要注意的是，既然 CMD 定义默认行为，那么它在 Dockerfile 中只能存在一个（如果定义了多个 CMD，那个最后一个有效） 那么如何使用 CMD 为 ENTRYPOINT 提供额外参数呢？先看一下 ENTRYPOINT 的用法。 ENTRYPOINT 命令ENTRYPOINT 通常用来定义容器启动时候的行为，有点类似于 CMD，但是它不会被启动命令中的参数覆盖。上一节中 Nginx 的例子，如果将 CMD 改成 ENTRYPOINT，那么我们的 hello-world 方案便行不通了。 ENTRYPOINT 同样支持两种格式的写法，并且是存在差异的（后文描述）： ENTRYPOINT &lt;command&gt; &lt;option&gt; &lt;param&gt; ENTRYPOINT [&quot;command&quot;, &quot;option&quot;, &quot;param&quot;] 使用 Exec 风格的写法支持使用 CMD 拓展可变参数和动态替换参数，而使用 Shell 风格时不支持。假如我们在 Dockerfile 中：12# 前置步骤忽略ENTRYPOINT redis-cli -h 127.0.0.1 那么这个由此构建的容器在运行时只能将 redi 连接到容器本身的 redis-server 上。修改这个 Dockerfile：123# 前置步骤忽略ENTRYPOINT ["redis-cli"]CMD ["-h", "127.0.0.1"] 这时候，如果按默认的启动方式，容器的 redis-cli 会自动连接 127.0.0.1，即以下命令此时是等价的：12docker run my-redis-imagedocker run my-redis-image -h 127.0.0.1 但是由于 Dockfile 中使用了 Exec 格式的 ENTRYPOINT，我们已经可以修改它的目标地址了，甚至可以增加额外的参数：1docker run my-redis-image -h server.address -a redis_password 其中 -h server.address 替换了 CMD [&quot;-h&quot;, &quot;127.0.0.1&quot;]，而 -a redis_password 则是由于使用了 Exec 格式可以增加参数。 关于 RUN，CMD，ENTRYPOINT 的差异已经描述完了，有没有都牢记于心呢~]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文字处理-sed]]></title>
    <url>%2F2018%2F07%2F%E6%96%87%E5%AD%97%E5%A4%84%E7%90%86-sed%2F</url>
    <content type="text"><![CDATA[sed 是非常常用的流式处理编辑工具，配合正则表达式可以进行十分效率的文字处理。它通过逐行地将文字读取，暂存进模式空间，通过指定的命令进行处理后，输出至标准输出，直到文件或者说输入的结束。原理十分简单，来学习一下吧。 命令格式sed [选项及参数]… ‘操作命令’ 文件… 常用选项 -n 静默模式 取消 sed 默认的输出 -e 多重编辑 可以多次使用，携带 sed 命令作为该选项的参数，对于缓冲区的每一行按命令顺序进行处理 -f 使用 sed 操作的脚本处理，跟上脚本文件名做参数。sed 脚本可以保存多条 sed 命令，一行一条，依次执行。 -r 使用拓展正则，类似 grep -e 或者 egrep 的增强，让人少些一点转义符 -i 原地修改，该选项会使得 sed 命令直接修改原文件，可以紧跟一个后缀如 -i.bk，同时生成备份 命令组成sed 命令的组成通常是 ‘行选择具体操作’。sed 在读入行内容之后，如果匹配定址要求就会进行命令操作。我们来两部分分开一看~ 行选择 num 选择第 num 行。 start,end 选择第 start 行至第 end 行。 start~step 从 start 行开始，以 step 为步长选择行。 /pattern/ 选择含有该正则的内容的行。 start,/pattern/ 从 start 行开始直到首次成功匹配表达式的一行将被选定，注意 sed 的处理机制，如果表达式最终无法有任何匹配行，将会对 start 行之后的所有行进行选定。 /pattern/,end 从首次成功匹配表达式的一行至 end 行将被选定，如果在第 end 行之前如果没有成功匹配将会不有行被选中。 ! 置于行选择末尾，进行反选，如 10,20! 将排除 10 至 20 行。 具体操作 p 打印缓冲内容，通常配合 -n 选项测试指令正确性。 q 提前退出 sed，当到达匹配行或者指定行就退出 sed。 i\[content] 行前追加内容，如在第 1 行至第 5 行，每行之后插入‘===’：&#39;1,5i\===&#39;。 a\[content] 行后追加内容。 c\[content] 替换内容，如果是批量选择，并不是对每行内容进行替换，而是对整体替换成相应内容。 d 删除。 s/pattern/new_chars/[g] 对选定的行中首次匹配表达式的内容替换成目标字符串，如果末尾使用‘g’，可以对行中所有匹配内容替换。 y/old-char-set/new-char-set 对选定行中所有 old-char-set 内的字符替换成相应的新的字符。 n 提前读取下一输入行至缓冲区。 r [file-name] 行后追加指定文件内容。 w [file-name] 将选定行输入至指定文件。 h 复制匹配行进入暂存空间。 G 配合 h 命令，取出暂存空间内的行，插入至模式空间的末尾。 x 配合 h 命令，交换当前匹配行的暂存空间内的行。 命令叠加需要多次使用 sed 操作的时候，可以有这么些办法： 通过 {命令1;命令2...} 可以使用‘{}’将多个命令整合一块儿，中间使用‘;’分割，类似代码块的表达。其中如果如果多个命令的行定位条件一致，可以将该部分提出，如：&#39;{10p;10p}&#39; 等于 &#39;10{p;p}&#39;。 通过 -e 选项多次输入 sed 命令。 将多个 sed 命令逐行写入文件，使用 -f 选项执行 sed。 额外技巧sed 命令其实和正则表达式通常配合使用，所以这一些小技巧其实和正则有很密切的关系。比如对于一个简单的替换操作，如 s/abc/xyz/ 是十分简单的，但是 sed 支持更复杂的操作，可以用一些特殊意义的操作符号: &amp; 表示正则匹配成功的原字符串内容，如想要替换所有数字为它的百倍，可以使用 ‘s/[[:digit:]]\+/&amp;00/g’ \num 获取缓存的匹配中缓存的字符串，num 指定位置（这取决于表达式中使用了多少次小括号‘()’）。 如去除数字并字母大写，’s/([[:digit:]]\+\)\|\([[:alpha:]]\+\)/\U\2/gp’ 获取包含一段 ip 的文本中 ip 的前两段地址 ‘s/\([0-9]\+\):\([0-9]\+\):[0-9]\+:[0-9]+/\1 \2/p’ \u 将后方的表达式结果进行首字母大写处理 \U 将后方的表达式结果进行大写处理 \l 将后方的表达式结果进行首字母小写处理 \L 将后方的表达式结果进行小写处理]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Regex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS 浅析]]></title>
    <url>%2F2018%2F07%2FAQS-%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[java.util.concurrent 包中提供了许多易用而有效的工具类，诸如 ReentrantLock，CountDownLatch，Semaphore 等等，给日常的并发编程带来了许多便利。他们都使用了同样的框架来完成基本的同步过程：AbstractQueuedSynchronizer （AQS）来实现基本功能，比如获取资源和释放的步骤。 简单了解戳开 AQS 一览其结构，其实它本身维护了两个概念： state：（volatile int）该属性维护了资源的状态，或者是数量。 CLH queue：一个先进先出的线程等待队列。这并不是一个具体对象，而是通过内部类 Node 来维护的。 AQS 对于 state 支持两种模式的资源共享形式： Exclusive-排他式：进程独占形式，如 ReentrantLock，Mutex 的应用。 Share-共享式：支持多线程访问，典型的应用式 CountDownLatch / Semaphore。 子类实现 AQS 时候只需要实现关于 state 的获取（acquire）和释放（release）方案即可，包括队列的维护，线程的唤醒等工作，大部分都在 AQS 维护了。举个栗子，在使用 CountDownLatch 的时候，我们会初始化一个计数值 n 用于对应 n 个子线程，这个 n 同时也对应了 state 值，每一次 countDown() 的时候，会使得 state CAS 地减 1。在 state 归零的时候会使用 unpark()，主线程 从 await() 函数返回。 工作流程AQS 的 API 同一般的同步工具 API 一样，除了对于资源的 acquire / release 操作，还提供的了 tryAcquire / tryRelease 的非阻塞操作。同时 acquireInterruptibly 支持线程中断。如果需要使用共享式的操作，需要实现对应的 Share 操作方法。 资源获取首先看 acquire 方法：1234public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire(int)：尝试获取资源 addWaiter(Node)：使线程（Node 对象维护这线程对象）进入等待队列，对于 acquire 方法使用 EXCLUSICE-排他模式。 acquireQueued(Node, int)：在这一步骤中线程会等待，而在线程唤醒后会尝试在该方法内获取资源。 selfInterrupt：由于线程在等待过程中无法响应中断，所以在获取资源并退出队列后补充一个中断。 tryAcquire(int) 方法默认会抛出操作不支持的异常，需要子类的具体实现。 123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; addWaiter(Node, int) 方法会自旋使用 CAS 方式将一个 Node 加入队尾。 1234567891011121314151617181920212223242526272829private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 从上面两个方法可以看出位于队列头部的 Node 其实只是一个标记，在队列第二位置的时候，线程已经可以获取资源并进行相关任务了。 acquireQueued(Node, int) 更关键的一步，在获取资源失败， Node 已经被加入队尾之后，线程需要进入等待状态等待被唤醒。 123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire(Node, Node) 每个节点是否需要等待需要阻塞取决于前驱节点的状态。 1234567891011121314private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 前驱节点最后会通过该状态值来判断是否需要 unpark 下个线程。在这里，如果前驱节点标识为 SIGNAL，则进入等待；标识为 CANCAL 需要追溯更前的节点状态；如果为其他正常值，则更新为 SIGNAL。 parkAndCheckInterrupt() 使线程进入 WATING，等待 unpark（在 release 中触发，马上就来） 或者 interrupt，被唤醒后回到 acquireQueued 触发中断或者继续检查是否可以获取资源。 1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 释放资源并唤醒后置线程这是 acquire 方法的反操作，用于资源的释放，当资源成功释放时，唤醒下一个线程（位于头节点之后）。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 通过 tryRelease(int) 方法判断资源是否释放，这个方法同样需要被实现： 123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 而 unparkSuccessor(Node) 方法用来真正唤醒 node.next 中的线程： 123456789101112131415private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 看到这就能了解整个 AQS 的运作流程了。在 parkAndCheckInterrupt 中进入 WAITING 的线程，在这里被唤醒，它会继续进入 acquireQueued 中的自旋，如果 tryAcquire 顺利获得资源，则将本线程的节点设置为 head 并返回 acquire 方法。so, go on. AQS 本身并不复杂，使用时只需要手动实现 tryAcquire 和 tryRealeas 方法。 而对于 Share-共享式的 acquire / release 流程，区别并不太大，有兴趣的小伙伴可以自行翻阅源码一探究竟。 参考 https://mp.weixin.qq.com/s/eyZyzk8ZzjwzZYN4a4H5YA]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ribbon 摘要]]></title>
    <url>%2F2018%2F07%2FRibbon%2F</url>
    <content type="text"><![CDATA[主要构成Ribbon 是由 netflix 开源的一个客户端负载均衡组件。从客户端的角度取维护服务间请求的负载均衡，并进行一定的容错处理。自然的它的核心接口就是：com.netflix.loadbalancer.ILoadBalancer。 在配置 Ribbon 之前，了解一下 Ribbon 完成负载均衡的几个重要组成部分： IRule：负载均衡的策略。 IPing：检测服务存活的策略。 ServerList&lt;T&gt;：拉取服务实例列表的策略。 ServerListUpdater：更新服务列表的触发策略。 ServerListFilter&lt;T&gt;：服务过滤方案。 参考下面的类关系图，可以有一个更好的印象： IRule负载均衡策略接口，可能最常需要配置的就是它了，配置也没什么特殊的，就以 Spring 常用的方式即可。通常情况下 Ribbon 原生的几个负载均衡策略应该可以满足生产要求（当然你也可以自定义），来了解一下： AbstractLoadBalancerRule 顶级的抽象类，给予了获得 LoadBalancer 的方法，可以让子类获得负载均衡器的一些信息，定制更具体的算法。 RandomRule 通过 LoadBalancer 获取可用的服务实例，并随机挑选。（一直无可实例时有无限循环 bug） RoundRobinRule 通过 LoadBalancer 获取可用的服务实例，并轮询选择。（超过 10 次失败时，打印机警告并返回 null） RetryRule 默认有一个 RoundRobinRule 的子规则，和 500 毫秒的阈值。使用子规则选择实例，执行时间若超过阈值则返回 null。 WeightedResponseTimeRule 继承自 RoundRobinRule。在构造时会启动一个定时任务，默认每 30 秒执行一次，来计算服务实例的权重。在默认的算法下，响应速度越快的服务实例权重越大，越容易被选择。 ClientConfigEnabledRoundRobinRule 本身定义了一个 RoundRobinRule 的子规则。本且默认的 choose 方法也是执行 RoundRobinRule 的实现。本身没有特殊用处，这个默认会实现是在其子类的算法无法实现时采用，通常会选择该类作父类继承，实现自定义的规则，以保证拥有一个默认的轮询规则。 BestAvaliableRule 通过 LoadBalancerStats 选择并发请求最小的实例。 PredicateBasedRule 利用子类的 Predicate 过滤部分服务实例后通过轮询选择。 AvailabilityFilteringRule 轮询选择一个服务实例，判断是否故障（断路器断开），并发请求是否大于阈值（默认2^32-1，可通过&lt;clientName&gt;.&lt;nameSpace&gt;.ActiveConnectionsLimit 修改）。允许则返回，不允许则再次选择，失败 10 次后执行父类方案。 ZoneAvoidanceRule 使用组合过滤条件执行过滤，每次过滤后会判断实例数是否小于最小实例数（默认1），是否大于过滤百分比（默认0），不再过滤后使用轮询选择。 具体配置在项目中是可以配置多个 Ribbon 客户端的，通常来说每个客户端用来访问不同的服务。比如为访问 A 服务的 Ribbon 客户端配置为 A-Client，B 服务为 B-Client。 通过代码配置首先来介绍通过注解配置的方法，像简单的 Sring Bean 配置一样，不过不需要使用 @Configuration 注解了。在配置类上启用 @RibbonClient，给定客户端的名称和配置类，使用 @Bean 来配置具体的组件如 IRule 等。 123456789101112131415@RibbonClient(name = "A-Client",configuration = ARibbonConfig.class)public class ARibbonConfig &#123; // 服务实例的地址 String listOfServers = "http://127.0.0.1:8081,http://127.0.0.1:8082"; @Bean public ServerList&lt;Server&gt; ribbonServerList() &#123; List&lt;Server&gt; list = Lists.newArrayList(); if (!Strings.isNullOrEmpty(listOfServers)) &#123; for (String s: listOfServers.split(",")) &#123; list.add(new Server(s.trim())); &#125; &#125; return new StaticServerList&lt;Server&gt;(list); &#125;&#125; 官方文档上提示了一个坑，不能把加了配置注解的具体的配置类放在 @ComponentScan 路径下，否则先扫描到的一个具体的客户端配置会成为 Ribbon 的全局配置。 这怎么能忍？当然得有更优雅的解决方式：全局配置的方案。使用 @RibbonClients 注解，一次可以描述多个客户端配置类的位置，同时也可以指定默认配置类，如： 12345678910@SpringCloudApplication@RibbonClients(value = &#123; @RibbonClient(name = "A-Client",configuration = ARibbonConfig.class), @RibbonClient(name = "B-Client",configuration = BRibbonConfig.class)&#125;, defaultConfiguration = DefaultConfig.class)public class DemoServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoServiceApplication.class, args); &#125;&#125; 这样配置可以不需要再在配置类上加上注解了，也可以不需要将配置类移出包扫描路径。 通过配置文件指定但是以上这样的代码配置还是稍显复杂，在目前的 SpringCloud 中 Ribbon 的配置可以直接 SpringBoot 的配置文件中写入，使用如下的方式指定要配置的参数： &lt;nameSpace&gt;.&lt;key&gt;=&lt;value&gt; 默认的命名空间是 ribbon，例如定义连接超时时间可以： ribbon.connectTimeout=120 而当需要为具体的客户端配置时，可以使用： &lt;client&gt;.&lt;nameSpace&gt;.&lt;key&gt;=&lt;value&gt; 比如： user-service.ribbon.listOfServers=localhost:8001,localhost:8002 关于 ribbon 所有的参数名称，可以参看 com.netfix.client.config.CommonClientConfigKey&lt;T&gt;。 与 Eureka 整合后的配置在使用 Eureka 的时候，会改变 Ribbon 一些组件的默认实现，如： ServerList -&gt; DiscoveryEnabledNIWSServerList：由 Eureka 来维护服务列表 IPing -&gt; NIWSDiscoveryPing：由 Eureka 测试服务存活（原配的 DummyPing 并不会 ping，而是始终返回 true） 而且针对不同服务不需要显示地配置不一样的客户端名称了，只需要使用 &lt;serviceName&gt;.&lt;nameSpace&gt;.&lt;key&gt;=&lt;value&gt; 如 user-service： user-service.ribbon.ReadTimeout=120 同时由于 SpringCloud Ribbon 默认实现区域亲和策略，zone 的配置也十分简单，只需要加入元数据集中即可，如： eureka.instance.metadataMap.zone=huzhou 如果不需要 Eureka 辅助 Ribbon 的自动配置（这不太可能吧），则可以使用： ribbon.eureka.enable=false 这时候，记得自己得手动配置 listOfServers 等参数了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则笔记]]></title>
    <url>%2F2018%2F06%2F%E6%AD%A3%E5%88%99%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[日常开发中，经常需要进行一些文本处理，这通常是十分繁琐而无趣的。学会并利用正则表达式可以快速解决这类文本处理问题，无论是在 Java，Python 等代码中抑或是 shell 环境下。正则中存在很多细小的知识点，十分容易遗忘，着手记录，知识整理还是有所必要。 本文以拓展正则进行描述，部分特殊字符和定址方式在标准正则下无效。如需在 shell 环境下使用，需要额外使用‘\’符号，或开启拓展正则的支持，如 grep -e，sed -r 等。 规则正则表达式的规则可以简单理解为：在给定的范围内，给定的字符重复给定的次数。 指定需要匹配的字符绝大部分的字符，包括数字字母汉字等，都可以直接输入来描述。 转义后特殊字符以下几个字符由转义符‘\’和某个字符组成，可以表述成新字符，他们有着特殊的含义。 \n 这是一个换行符。 \t 制表符，Tab 键的缩进。 \v 垂直制表符。 \f 分页符，产生一个新页。 \r 这是回车符 \s 这个表达可以表述所有的空白字符，即以上五种字符或者空格。 \cx 当 x 取值英文字符时，这个整体就有了特殊意义，会映射成一个控制字符，如 \cM 等价于 \r 即回车符号。 \ux 可以匹配 Unicode 字符，如 \u00CD。 \nx 在 x 值合法的情况下，可以匹配八进制专一值（在没有顺利取得缓存引用时） \b 表示字符边界，可以理解为打断单词或着汉字连续的空格/符号之类（其实它并不能匹配到某个字符，仅仅是匹配到了边界） \d 表示数字，同 [0-9]。 \w 表示任意字类字符，即数字字母和下划线，通常还支持汉字。 \&lt; 匹配单词首，比如 \&lt;wo 可以匹配 wood，word 等。 \&gt; 同理匹配单词尾部。 原生特殊字符以下的字符并不需要转移符‘\’，天然的拥有特殊含义（以拓展正则为准）。 $ 尾部，表示字符串结尾位置。 ^ 头部，字符串的开头位置，但在 [ ] 内使用时表示取反 [ ] 左右中括号，用来表达匹配单个字符时候的可选范围 { } 左右花括号，用来表述前一表达式的可重复区间 ( ) 左右小括号，类似数学中的概念，可以描述一个表达式并提高计算优先级，同时会缓存匹配结果。 · 点号，可以用了匹配任意的一个字符，除了 \n 吧。 * 星号，可以匹配前面表达式任意次数。 + 加号，匹配前面表达式一至任意次数. ? 问号，匹配前面表达式 0 ~ 1 次。 \ 转移符本身，用来转移其他字符，需要匹配它本身的时候自然需要 \\ 的形式。 | 或运算符号，任意匹配前后表达式之一。 [:digit:] 所有数字 [:lower:] 所有小写字母 [:upper:] 所有大写字母 [:alpha:] 所有字母 [:alnum:] 所有字母及数字 [:space:] 所有空白符 [:punct:] 所有标点符号 指定匹配字符的候选范围匹配一个单字符很简单，但是通常我们需要匹配几个字符中的任意一个，这个时候就需要一个候选范围的描述。除了使用 \w 表示字类字符，\s 来表示空白符。也可以使用 [ ] 方括号来描述范围，来看几个例子： [abc] 它可以是匹配 a，也可以是 b，也可以是 c。 5[48]k 它可以是 54k，也可以是 58k。 [0-9]\w 它可以使是 0a，3b，33 等等。 这样一看是不是很容易？来看一些进阶技巧： 取反。表述范围的符号可以通过大写来表示取反，\S 表示非空白字符，\B 表示非字符边界，\W 表示非字类字符。对于使用 [ ] 的场合，使用 [^ ] 来完成取反。 [ ] 方括号中间不再能使用上述特殊的字符，比如 [x*]，* 不再匹配任意次 x，这个表达式只能匹配 * 或 x；同理比如：[\s] 表示 \ 或者 s。 [ ] 中可以使用一些特定的范围，比如 0-9，a-z，A-Z。比如式子 [0-9A-Z] 也是合理的，会匹配数字或者大写字母，如需要匹配‘-’，尽量写在最后。 指定表达式的重复次数在需要重复一个特定的正则表达式的时候，我们可以使用限定符描述重复次数来简化它。 {n} 匹配 n 次，如 C{3} 即 CCC。 {n,} 匹配大于等于 n 次。如 C{1,} 等同于 C+ {n,m} 匹配大于等于 n 次，小于等于 m 次，闭区间。 * 等同于 {0,} + 等同于 {1,} ? 等同于 {0,1} 利用正则匹配的缓存 \num 使用 ( ) 之后会进行匹配值的缓存，可以紧跟着 \num 指定匹配的子项，比如 (.)\1 可以匹配任意两个相同的字符。或者在 sed，vim 等工具使用替换操作时，可以在新字符串上使用 \num 以期达到精确的匹配但是局部替换的效果。 (?:pattern) 使用该符号会取消匹配值的缓存 (?=pattern) 正向肯定预查，使用该符号会取消匹配值的缓存，同时预查也是不消耗字符的。 (?!pattern) 反向预查，相反于前者]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Regex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机中的锁膨胀]]></title>
    <url>%2F2018%2F06%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E7%9A%84%E9%94%81%E8%86%A8%E8%83%80%2F</url>
    <content type="text"><![CDATA[尽管当下几乎所有的服务器环境都以集群为主，在考虑并发问题的时候通常会使用分布式技术,如 redis 等中间件来维护全局的资源和锁。但是对于一些实例层面上的资源，依旧需要使用传统的锁来维护。所以我觉得，理解 JVM 对锁的处理还是有价值的。 JVM上针对锁的处理（这里只描述内部锁，即 synchronized 的处理情况），除了有自旋锁，锁粗化，锁消除等简单的自动优化机制（不探讨啦），还可以从锁的维护的角度去看，可以分为偏向锁，轻量级锁，重量级锁。三者的开销是递增的，演变顺序也是递增的，而且不可逆。如轻型的锁可以膨胀升级至重型锁，但是不可以从重型的锁降级。 之所以有不同程度的锁的处理方式，可以看一下这一个场景：如果在逻辑上某一时间基本只有一个线程，会访问由某个锁对象控制的同步块，很多时候不存在资源征用的问题。那么在这个时候，很多时候上锁解锁的开销就显得繁琐而低效了。以重量级锁（也是 synchronized 的最终形态）为例，取锁过程需要操作系统的介入，使线程从用户态进入核心态，开销还是挺大的。所以一开始 JVM 会对锁做偏向锁处理，在一些条件下升至轻量级锁乃至重量级锁。 前置概念在阐述锁膨胀之前，先插入几个内容点，对象头和自旋锁。 对象头在 HotSpot 虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 实例数据内容和对齐填充不在赘述，说说对象头，这就类似一个对象的元信息，其中也分为三部分组成：标记字段 Mark Word，类型指针 Class Pointer，数组长度 Array Length（如果该对象是数组，则记录了数组长度），三组数据分别用一个字长来存储（32位机上为32bit，64位机位64bit）。 类型指针：在虚拟机加载类的时候，除了会在元空间/方法区存储类信息，也会在堆区生成一个 Class 对象。类型指针，便是为一个实例对象指向 Class 对象的指针。 标记字段：在这一个字的区域内，描述了很多信息。通常一个对象会有其哈希码，年代标记（经历 GC 次数），锁标识等。但是如果该对象充当了一个上锁对象，情况会有所不同，下文详述。 自旋锁通常来说，取锁时候如果未能获得锁，线程会进入阻塞状态（Blocking），同时会让线程进入等待队列/同步块的入口集中，并导致一个上下文切换，出让 CPU 资源。我们可以实现一个忙轮询的机制来尝试获得锁。比如使用一个状态对象来代替锁，使用一个循环来判断状态是否未可用，如下是代码层面的实现。1234567volatile boolean flag = false;while(true) &#123; if(flag) &#123; // do something break; &#125;&#125; 这可以避免在首次取得锁失败的时候直接线程切出，在同步逻辑处理量较少的时候可以带来明显的效率提升，但是如果如果说“同步块”的处理时间很长，或者在“同步块”内的线程发生异常未能更改状态量，将严重损失性能乃至发生更严重的死锁。 所以自旋锁适合同步逻辑的处理时间很短的场合（几个循环内能拿到锁） 锁膨胀过程中的三个阶段现在已经了解了对象在堆中的存储形式，以及依靠自旋可以在短时间内减少加锁开销。继续深入 JVM 中不同并发程度下锁的不同的机制。 偏向锁偏向锁是在 JDK 1.5？1.6 之后对锁进行的优化。先来看一个图： 前文提到过，如果一个线程经常获得锁，且资源争用不严重，那么可以尽量减少取锁的开销。JDK 是这么做的：在一个线程获得锁的时候，会在栈帧记录中以及锁对象的标记字段中写入线程 id，在该线程进入/离开同步块的时候不需要额外的锁开销，这里甚至不需要 CAS 操作，因为只需要比较标记字段中的线程 id 与自身是否一致。如果在尝试获得锁的时候发现标记字段中的线程 id 与自身不一致，会尝试利用 CAS 操作来争抢这个偏向锁。 补充：偏向锁是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用 JVM 参数来关闭延迟 -XX:BiasedLockingStartupDelay=0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，甚至可以通过 JVM 参数关闭偏向锁 -XX:-UseBiasedLocking=false，那么所有的内部锁都会直接进入轻量级锁状态。 轻量级锁线程在执行同步块之前，JVM 会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的标记字段复制到锁记录中。然后线程尝试使用 CAS 将对象头中的标记字段替换为指向锁记录的指针。如果成功，当前线程获得锁；如果失败，则进行自旋来获取锁，当自旋获取锁仍然失败时，表示竞争严重（两条或两条以上的线程竞争同一个锁），则轻量级锁会膨胀成重量级锁。 重量级锁重量级锁其实才是通常涉及的锁概念，这时候它已经是一个彻底的悲观锁了。在 JVM 中又叫对象监视器，它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。 参考 《Java多线程编程实战指南》 黄文海 《深入理解Java虚拟机》 周志明 https://www.cnblogs.com/wade-luffy/p/5969418.html https://blog.csdn.net/wolegequdidiao/article/details/45116141]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
</search>
